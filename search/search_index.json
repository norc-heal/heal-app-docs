{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HEAL Data Packaging Tool \u00b6 This document walks through the process for creating and completing a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers: About the Tool and the Trackers \u00b6 Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas Downloading and Navigating the Tool \u00b6 Downloading the Tool for Windows and Mac Navigating the Tool","title":""},{"location":"#heal-data-packaging-tool","text":"This document walks through the process for creating and completing a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers:","title":"HEAL Data Packaging Tool"},{"location":"#about-the-tool-and-the-trackers","text":"Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas","title":"About the Tool and the Trackers"},{"location":"#downloading-and-navigating-the-tool","text":"Downloading the Tool for Windows and Mac Navigating the Tool","title":"Downloading and Navigating the Tool"},{"location":"about/","text":"HEAL Data Packaging Tool \u00b6 This document walks through the process for creating and completing a a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers: About the Tool and the Trackers \u00b6 Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas Downloading and Navigating the Tool \u00b6 Downloading the Tool for Windows and Mac Navigating the Tool","title":"HEAL Data Packaging Tool"},{"location":"about/#heal-data-packaging-tool","text":"This document walks through the process for creating and completing a a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers:","title":"HEAL Data Packaging Tool"},{"location":"about/#about-the-tool-and-the-trackers","text":"Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas","title":"About the Tool and the Trackers"},{"location":"about/#downloading-and-navigating-the-tool","text":"Downloading the Tool for Windows and Mac Navigating the Tool","title":"Downloading and Navigating the Tool"},{"location":"about/nav/","text":"Using the Tool \u00b6 Note When you open the tool, the window (console) below will pop up and begin running. Do not close it. Once it executes, the tool will open. You will need to leave this window open when you are using the tool. Note: The screenshot above shows the Windows console. The Mac console will look slightly different. When the tool loads, it will look like this (Windows): Tabs \u00b6 The tabs within the tool are organized sequentially to walk through the steps of data packaging: Data Package, Experiment Tracker, Resource Tracker, Results Tracker, and Data Dictionary. Within each of these tabs, there are 2-3 sub-tabs. Each has an \"Info\" tab, which provides information on what the app will create within the selected step. Depending on which domain you are viewing, the additional tabs will vary. Each individual tab will provide the necessary forms and guidance to execute the steps for that domain. App Messages and Guidance \u00b6 Working Data Package Directory \u00b6 The Working Data Package Directory will always be displayed at the top of the tool's main window. Each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session. User Status Message Box \u00b6 Within each tab, there is a User Status Message Box: The User Status Message Box will print out messages when you make certain selections or save changes to files (e.g., adding a result to a Results Tracker). The box will provide information on the status of changes and any errors that may occur. It will also provide helpful tips on next steps. This is another tool meant to help you through the process, so we advise you to review the messages and use the tips provided. Guide to Text Colors \u00b6 Color Form Fields User Status Message Box Blue Required, but can be filled in by an automatic process Information on next steps Green Required Successful process message Black Not required, but useful to include Process message Red N/A Error message","title":"Navigating the Tool"},{"location":"about/nav/#using-the-tool","text":"Note When you open the tool, the window (console) below will pop up and begin running. Do not close it. Once it executes, the tool will open. You will need to leave this window open when you are using the tool. Note: The screenshot above shows the Windows console. The Mac console will look slightly different. When the tool loads, it will look like this (Windows):","title":"Using the Tool"},{"location":"about/nav/#tabs","text":"The tabs within the tool are organized sequentially to walk through the steps of data packaging: Data Package, Experiment Tracker, Resource Tracker, Results Tracker, and Data Dictionary. Within each of these tabs, there are 2-3 sub-tabs. Each has an \"Info\" tab, which provides information on what the app will create within the selected step. Depending on which domain you are viewing, the additional tabs will vary. Each individual tab will provide the necessary forms and guidance to execute the steps for that domain.","title":"Tabs"},{"location":"about/nav/#app-messages-and-guidance","text":"","title":"App Messages and Guidance"},{"location":"about/nav/#working-data-package-directory","text":"The Working Data Package Directory will always be displayed at the top of the tool's main window. Each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session.","title":"Working Data Package Directory"},{"location":"about/nav/#user-status-message-box","text":"Within each tab, there is a User Status Message Box: The User Status Message Box will print out messages when you make certain selections or save changes to files (e.g., adding a result to a Results Tracker). The box will provide information on the status of changes and any errors that may occur. It will also provide helpful tips on next steps. This is another tool meant to help you through the process, so we advise you to review the messages and use the tips provided.","title":"User Status Message Box"},{"location":"about/nav/#guide-to-text-colors","text":"Color Form Fields User Status Message Box Blue Required, but can be filled in by an automatic process Information on next steps Green Required Successful process message Black Not required, but useful to include Process message Red N/A Error message","title":"Guide to Text Colors"},{"location":"about/purpose/","text":"Purpose of the HEAL Data Packaging Tool \u00b6 Compiling and accurately documenting the aspects of your study's data and supporting documents in a way that will be understandable and usable for future researchers can be a difficult task. This tool was developed to help ease the burden of understanding and effectively fulfilling HEAL data sharing requirements. This tool provides you with easy-to-fill-out forms and step-by-step guidance that will help you to document and annotate your study's experiments, results, and resources to maximize your study's findability and replicability by future researchers. When you fill out these forms, the tool will package up the information into different trackers, which you will then deposit into the repository you choose, along with your other data package components, as supporting documentation. The tool and the resulting trackers will provide systematic annotation of your data package. For more information on the data packaging process, such as how to prepare your data and supporting documents before starting your package and how to determine your annotation approach, refer to the HEAL data packaging guidance documentation .","title":"Purpose"},{"location":"about/purpose/#purpose-of-the-heal-data-packaging-tool","text":"Compiling and accurately documenting the aspects of your study's data and supporting documents in a way that will be understandable and usable for future researchers can be a difficult task. This tool was developed to help ease the burden of understanding and effectively fulfilling HEAL data sharing requirements. This tool provides you with easy-to-fill-out forms and step-by-step guidance that will help you to document and annotate your study's experiments, results, and resources to maximize your study's findability and replicability by future researchers. When you fill out these forms, the tool will package up the information into different trackers, which you will then deposit into the repository you choose, along with your other data package components, as supporting documentation. The tool and the resulting trackers will provide systematic annotation of your data package. For more information on the data packaging process, such as how to prepare your data and supporting documents before starting your package and how to determine your annotation approach, refer to the HEAL data packaging guidance documentation .","title":"Purpose of the HEAL Data Packaging Tool"},{"location":"about/trackers/","text":"The Trackers \u00b6 The tool builds three different trackers that provide a standardized way to supply supporting annotation (metadata) in conjunction with your shared data: an experiment tracker, a resource tracker, and a results tracker. Information on the purpose and general content of each tracker is in the table below. Tracker Purpose Content Experiment Tracker Provides contextual information on the experiments involved in the project Details each experiment, including research questions, approach, and hypotheses Resource Tracker Provides inventory and annotated information for all data and supporting files List of data and non-data/supporting files, including description, path, and dependencies Results Tracker Provides detailed information on all multi-result files List of each result, including type and description; there should be one results tracker per multi-result file The Data Packaging tool will provide you with easy-to-understand forms that feed into these trackers. You will not need to complete them manually within the tracker. For more information on the fields within each tracker, please refer to the metadata schemas .","title":"The Trackers"},{"location":"about/trackers/#the-trackers","text":"The tool builds three different trackers that provide a standardized way to supply supporting annotation (metadata) in conjunction with your shared data: an experiment tracker, a resource tracker, and a results tracker. Information on the purpose and general content of each tracker is in the table below. Tracker Purpose Content Experiment Tracker Provides contextual information on the experiments involved in the project Details each experiment, including research questions, approach, and hypotheses Resource Tracker Provides inventory and annotated information for all data and supporting files List of data and non-data/supporting files, including description, path, and dependencies Results Tracker Provides detailed information on all multi-result files List of each result, including type and description; there should be one results tracker per multi-result file The Data Packaging tool will provide you with easy-to-understand forms that feed into these trackers. You will not need to complete them manually within the tracker. For more information on the fields within each tracker, please refer to the metadata schemas .","title":"The Trackers"},{"location":"about/download/start-mac/","text":"Downloading the Desktop Application Tool for Mac \u00b6 Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-mac.zip\" to download the tool. The folder should automatically unzip to Downloads. Right click on the dsc-pkg-tool icon. Warning If you double click on the dsc-pkg-tool icon, you will receive a warning that the tool \"cannot be opened because it is from an unidentified developer.\" You can bypass this error by opening via right-click. You will receive a pop-up asking you to confirm that you want to open. Select \"Open.\" The tool should open:","title":"Mac"},{"location":"about/download/start-mac/#downloading-the-desktop-application-tool-for-mac","text":"Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-mac.zip\" to download the tool. The folder should automatically unzip to Downloads. Right click on the dsc-pkg-tool icon. Warning If you double click on the dsc-pkg-tool icon, you will receive a warning that the tool \"cannot be opened because it is from an unidentified developer.\" You can bypass this error by opening via right-click. You will receive a pop-up asking you to confirm that you want to open. Select \"Open.\" The tool should open:","title":"Downloading the Desktop Application Tool for Mac"},{"location":"about/download/start-win/","text":"Downloading the Desktop Application Tool for Windows \u00b6 What to Do First Delete previous version(s) of the tool: If you have downloaded a previous version of the tool, delete the previous version of the tool (dsc-pkg-tool) prior to downloading and unzipping the current version of the tool, as you will be unable to save two files with the same name within the same folder. DO NOT delete your dsc-pkg folder or contents: If you have already used the tool to create/initialize your data package (i.e. created your dsc-pkg folder within your study folder), DO NOT delete your dsc-pkg folder or any of its contents (i.e. standard data package metadata files such as experiment, resource, and results trackers and data dictionaries) Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-windows.zip\" to download the tool. Unzip the files. You can unzip the files to your downloads folder or to another folder that you prefer. Tip If you did not delete your previous version of the dsc_pkg_tool before unzipping to the same folder, you can overwrite the old version of the tool with this new version by selecting \"Replace the file in the destination folder\" in the pop-up window. Once you have unzipped the files, the dsc_pkg_tool file will appear. Double-click the file to open the tool.","title":"Windows"},{"location":"about/download/start-win/#downloading-the-desktop-application-tool-for-windows","text":"What to Do First Delete previous version(s) of the tool: If you have downloaded a previous version of the tool, delete the previous version of the tool (dsc-pkg-tool) prior to downloading and unzipping the current version of the tool, as you will be unable to save two files with the same name within the same folder. DO NOT delete your dsc-pkg folder or contents: If you have already used the tool to create/initialize your data package (i.e. created your dsc-pkg folder within your study folder), DO NOT delete your dsc-pkg folder or any of its contents (i.e. standard data package metadata files such as experiment, resource, and results trackers and data dictionaries) Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-windows.zip\" to download the tool. Unzip the files. You can unzip the files to your downloads folder or to another folder that you prefer. Tip If you did not delete your previous version of the dsc_pkg_tool before unzipping to the same folder, you can overwrite the old version of the tool with this new version by selecting \"Replace the file in the destination folder\" in the pop-up window. Once you have unzipped the files, the dsc_pkg_tool file will appear. Double-click the file to open the tool.","title":"Downloading the Desktop Application Tool for Windows"},{"location":"datadict/","text":"About the Data Dictionary Tab \u00b6 This tab creates HEAL-compliant data dictionaries, which provide metadata, including variable labels and values, for tabular or tabular-like data files in your data package. You should create a data dictionary for each tabular or tabular-like data file you collect/share as part of your study. The HEAL data dictionary converter can take data files and data dictionary files as inputs. Data files accepted include CSV files, Excel files with multiple tabs, SPSS .sav files, Stata .dta files, SAS .sas7bdat files. Data dictionary files accepted include REDCap CSV data dictionary files and minimal CSV data dictionary files. Before attempting to convert your tabular data file into a HEAL-compliant data dictionary, you may have to complete a few specific steps based on the file type (e.g., for REDCap data dictionaries, you must download from REDCap in the correct format). In order to ensure your input file is in the correct format, review the instructions here . Tips and Best Practices for Data Dictionaries We recommend that you save all of your HEAL-compliant data dictionaries in the same folder. The tool will automatically do this for you. Any data dictionary you create with the tool will be output into your dsc-pkg folder. You should apply a consistent naming convention to your data dictionaries. The tool will do this for you. Any data dictionary you create will be output with the same file name with \"heal-csv-dd\" appended at the beginning.","title":"About the Data Dictionary Tab"},{"location":"datadict/#about-the-data-dictionary-tab","text":"This tab creates HEAL-compliant data dictionaries, which provide metadata, including variable labels and values, for tabular or tabular-like data files in your data package. You should create a data dictionary for each tabular or tabular-like data file you collect/share as part of your study. The HEAL data dictionary converter can take data files and data dictionary files as inputs. Data files accepted include CSV files, Excel files with multiple tabs, SPSS .sav files, Stata .dta files, SAS .sas7bdat files. Data dictionary files accepted include REDCap CSV data dictionary files and minimal CSV data dictionary files. Before attempting to convert your tabular data file into a HEAL-compliant data dictionary, you may have to complete a few specific steps based on the file type (e.g., for REDCap data dictionaries, you must download from REDCap in the correct format). In order to ensure your input file is in the correct format, review the instructions here . Tips and Best Practices for Data Dictionaries We recommend that you save all of your HEAL-compliant data dictionaries in the same folder. The tool will automatically do this for you. Any data dictionary you create with the tool will be output into your dsc-pkg folder. You should apply a consistent naming convention to your data dictionaries. The tool will do this for you. Any data dictionary you create will be output with the same file name with \"heal-csv-dd\" appended at the beginning.","title":"About the Data Dictionary Tab"},{"location":"datadict/create/","text":"Create a New Data Dictionary \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to create a data dictionary. If you have not set your working data package directory before attempting to use the data dictionary converter, the tool will not be able to save your output data dictionary to your data package folder. You will receive the error message below. Creating a new data dictionary \u00b6 When you would like to create a new data dictionary, go to the \"Create\" tab. You will be able to start either with a data file or a data dictionary file, if you have one. Special considerations for certain files To ensure that your files are able to be read into the tool and converted correctly, certain file types may require some additional considerations/preparation. Multi-tab Excel files SAS files Minimal CSV Data Dictionaries REDCap Data Dictionaries Select the data dictionary conversion that you would like to complete and select the corresponding file in File Explorer. If the conversion is successful, then the User Status Message Box will print a successful message: Some input file types contain more metadata than others, so depending on the input file, you may need to take additional steps to ensure you have a valid HEAL-compliant data dictionary. Ensuring that you have a valid HEAL data dictionary \u00b6 Once you have output your data dictionary, you may have to take additional steps, depending on your original input file type, to ensure that your data dictionary is \"valid.\" A valid HEAL-compliant data dictionary will contain at least a name and description for each variable. If you started with an input file that was rich in metadata, this metadata will be extracted by the tool. You can expect that the data dictionary output by the tool will be fairly complete and likely will be valid. Metadata-rich files include SPSS and Stata files, and SAS files (if a sas7bcat file is included). Similarly, if you input a REDCap CSV data dictionary, your output HEAL CSV data dictionary should be fairly complete and valid. Example of the data dictionary output based on a metadata-rich file: If you started with a CSV or Excel file, however, the output data dictionary will be a \"minimal data dictionary.\" Unlike metadata-rich files (SPSS, Stata, SAS), which contain information about variable names, labels, and encodings within the file, CSV and Excel files do not contain this metadata. Therefore, the output data dictionary will contain the variable names and types, but not descriptions. The tool will also attempt to infer whether variables are categorical, and if so, what those categories are. However, if there are categories not included in the data, those will not be able to be inferred and included. Example of the data dictionary output based on a CSV or Excel file: If you start with a non-metatadata-rich file, you will need to edit your data dictionary after it has been output. For the data dictionary to be considered valid, each variable must have a name and description. You may also want to add in additional constraints that the tool did not infer such as variable encodings. For more information on the additional columns within the HEAL-compliant data dictionary output by the tool as well as guidance on which fields may be most useful to prioritize filling out, refer to the Data Dictionary metadata schema . Special considerations for specific file types \u00b6 Certain data files and data dictionaries may require additional steps and preparation. See below for information on these specific circumstances for certain data files. Excel Data File with multiple tabs SAS File Minimal CSV Data Dictionary REDCap Data Dictionary Excel Data File with multiple tabs \u00b6 In order for the tool to successfully produce a data dictionary from an Excel file with multiple tabs, each tab within that Excel must first be a clean dataset that follows a standard tabular format: the top row should list all variables across the columns and the columns should contain the data. Once you have a clean dataset in each tab, there are two options for output for Excel data files with multiple tabs. Excel Data File >> HEAL CSV Data Dictionary (one per tab) This will take a multi-tab Excel file and output one data dictionary for each tab in the Excel. The naming convention of the file will be 'heal-csv-dd-filename-tabname.' Each data dictionary will include a row for every variable within that specific tab. Excel Data File >> HEAL CSV Data Dictionary (one across tabs) This will take a multi-tab Excel file and output a single data dictionary with structure 'heal-csv-dd-filename.' This single data dictionary will include a row for every variable across all tabs. If you use this method, it is important that you ensure that variable names across sheets are consistent. This works particularly well if your data is structured such that the same variables are used across sheets. However, if you are using the same variable name in multiple different sheets, but it does not have the same meaning in each sheet, you should either vary the name of variables across sheets or you should use the one per tab option. SAS File \u00b6 For tabular files saved in SAS (sas7bdat), you will want to have an accompanying catalog file (sas7bcat). Although the sas7bdat contains variable metadata information (variable names and variable labels/descriptions), the sas7bcat contains information about the formats and encoding of the variables, which are important for producing a complete data dictionary. Creating a sas7bdat and sas7bcat file \u00b6 Many SAS users build formats and labels into their data processing and analysis scripts. In this section, we provide syntax that can be easily copy-pasted into these existing workflows to create sas7bdat and sas7bcat files to input into the vlmd tool. This script template can be run separately or inserted directly at the end of a SAS user's workflow. Note If inserted directly, remember to delete the lines with %INCLUDE ) Template template.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SECOND SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file. If you already have an out directory assigned, skip this step and replace \u201cout\u201d with your out directory libname in the flow*/ libname out \"<INSERT THE DESIRED LOCATION (FILE PATH) TO YOUR SAS7BCAT AND SAS7BDAT FILES HERE>\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) */ data out . yourdata; set < INSERT THE NAME OF YOUR FINAL SAS DATASET HERE> ; run; The below SAS syntax is an example of how to use the template within your SAS workflow. The below sample script creates all of our variable and value labels. Your workflow may include multiple SAS scripts with multiple format statements and may include analyses and other PROC calls for data exploration, but for demonstration purposes, this example only uses one script and focuses on defining the variable and value labels. Example my_existing_sas_workflow.sas /*1. Read in input data */ proc import datafile= \"myprojectfolder/input/mydata.csv\" out =raw dbms=csv replace ; getnames=yes ; run; /*2. Set up proc format and apply formats and variable labels in data step */ /*Create encodings (value labels)*/ proc format; VALUE YESNO 0 = \"No\" 1 = \"Yes\" VALUE PUBLIC 1 = 'State mental health authority (SMHA)' 2 = 'Other state government agency or department' 3 = 'Regional/district authority or county, local, or municipal government' 4 = 'Tribal government' 5 = 'Indian Health Service' 6 = 'Department of Veterans Affairs' 7 = 'Other' VALUE FOCUS 1 = 'Mental health treatment' 2 = 'Substance abuse treatment' 3 = 'Mix of mental health and substance abuse treatment (neither is primary)' 4 = 'General health care' 5 = 'Other service focus' ; **Apply formats to dataset; data processed; set raw; /*Assign formats*/ format YOUNGADULTS TREATPSYCHOTHRPY TREATTRAUMATHRPY YESNO. FOCUS FOCUS. PUBLIC PUBLIC.; /*Add variable labels*/ label YOUNGADULTS= \"Accepts young adults (aged 18-25 years old) for Tx\" TREATPSYCHOTHRPY= \"Facility offers individual psychotherapy\" TREATTRAUMATHRPY= \"Facility offers trauma therapy\" FOCUS= \"Primary treatment focus of facility\" PUBLIC= \"Public agency or department that operates facility\" ; run; This second script called my_output.sas is the filled out template. Note the %INCLUDE function that calls my_existing_sas_workflow.sas my_output.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ */ %INCLUDE \"myprojectfolder/my_existing_workflow.sas\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file.*/ libname out \"myprojectfolder/output\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) to your output folder*/ data out . yourdata; set processed ; run; Running through the tool \u00b6 After creating the necessary sas7bdat and sas7bcat files, you are ready to convert to a HEAL-compliant data dictionary using the data packaging tool. Before you begin, ensure that your sas7bdat and sas7bcat files are saved in the same folder. The tool will only ask you to select your sas7bdat file. If the sas7bcat file is located in the same directory, the tool will automatically detect it, as well. If not detected, the tool will run without the sas7bcat catalog file and the encodings (i.e., value labels) will not be extracted from the catalog file and will not appear in your data dictionary. The output will be a minimal HEAL-compliant data dictionary. Minimal CSV Data Dictionary \u00b6 If you have already created a data dictionary in CSV format, you can also use that to generate a HEAL-compliant data dictionary. The only requirements for a \"minimal CSV data dictionary\" to be ingested by the tool and converted into a HEAL-compliant data dictionary are two columns: name and description. With these two columns included, the data dictionary output will be a valid data dictionary (although it will be a fairly minimal data dictionary). However, this does not mean that you must only include these two columns. You may already have additional columns in your existing data dictionary, or you may want to add columns beyond name and description to better describe your dataset. For information on which additional columns it may be most helpful to include within your minimal data dictionary, and how to create, label, and format them to be successfully ingested and output by the data dictionary converter tool, refer to the HEAL Data Dictionary metadata schema . REDCap Data Dictionary \u00b6 If you collected data in a REDCap data management system, HEAL-compliant data dictionaries can be generated directly from an exported REDCap data dictionary. The REDCap data dictionary export serves the purpose of providing variable-level metadata in a standardized, tabular format and is generally easy to export. Export your REDCap data dictionary \u00b6 To download a REDCap CSV export, do the following*: After logging in to your REDCap project page, locate the Data dictionary page. A link to this page may be available on the project side bar (see image below) or in the Project Setup tab at the top of your page. After arriving at the Data dictionary page, click on Download the current data dictionary to export the dictionary (see below). *there may be slight differences depending on your specific REDCap instance and version","title":"Create a Data Dictionary"},{"location":"datadict/create/#create-a-new-data-dictionary","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to create a data dictionary. If you have not set your working data package directory before attempting to use the data dictionary converter, the tool will not be able to save your output data dictionary to your data package folder. You will receive the error message below.","title":"Create a New Data Dictionary"},{"location":"datadict/create/#creating-a-new-data-dictionary","text":"When you would like to create a new data dictionary, go to the \"Create\" tab. You will be able to start either with a data file or a data dictionary file, if you have one. Special considerations for certain files To ensure that your files are able to be read into the tool and converted correctly, certain file types may require some additional considerations/preparation. Multi-tab Excel files SAS files Minimal CSV Data Dictionaries REDCap Data Dictionaries Select the data dictionary conversion that you would like to complete and select the corresponding file in File Explorer. If the conversion is successful, then the User Status Message Box will print a successful message: Some input file types contain more metadata than others, so depending on the input file, you may need to take additional steps to ensure you have a valid HEAL-compliant data dictionary.","title":"Creating a new data dictionary"},{"location":"datadict/create/#ensuring-that-you-have-a-valid-heal-data-dictionary","text":"Once you have output your data dictionary, you may have to take additional steps, depending on your original input file type, to ensure that your data dictionary is \"valid.\" A valid HEAL-compliant data dictionary will contain at least a name and description for each variable. If you started with an input file that was rich in metadata, this metadata will be extracted by the tool. You can expect that the data dictionary output by the tool will be fairly complete and likely will be valid. Metadata-rich files include SPSS and Stata files, and SAS files (if a sas7bcat file is included). Similarly, if you input a REDCap CSV data dictionary, your output HEAL CSV data dictionary should be fairly complete and valid. Example of the data dictionary output based on a metadata-rich file: If you started with a CSV or Excel file, however, the output data dictionary will be a \"minimal data dictionary.\" Unlike metadata-rich files (SPSS, Stata, SAS), which contain information about variable names, labels, and encodings within the file, CSV and Excel files do not contain this metadata. Therefore, the output data dictionary will contain the variable names and types, but not descriptions. The tool will also attempt to infer whether variables are categorical, and if so, what those categories are. However, if there are categories not included in the data, those will not be able to be inferred and included. Example of the data dictionary output based on a CSV or Excel file: If you start with a non-metatadata-rich file, you will need to edit your data dictionary after it has been output. For the data dictionary to be considered valid, each variable must have a name and description. You may also want to add in additional constraints that the tool did not infer such as variable encodings. For more information on the additional columns within the HEAL-compliant data dictionary output by the tool as well as guidance on which fields may be most useful to prioritize filling out, refer to the Data Dictionary metadata schema .","title":"Ensuring that you have a valid HEAL data dictionary"},{"location":"datadict/create/#special-considerations-for-specific-file-types","text":"Certain data files and data dictionaries may require additional steps and preparation. See below for information on these specific circumstances for certain data files. Excel Data File with multiple tabs SAS File Minimal CSV Data Dictionary REDCap Data Dictionary","title":"Special considerations for specific file types"},{"location":"datadict/create/#excel-data-file-with-multiple-tabs","text":"In order for the tool to successfully produce a data dictionary from an Excel file with multiple tabs, each tab within that Excel must first be a clean dataset that follows a standard tabular format: the top row should list all variables across the columns and the columns should contain the data. Once you have a clean dataset in each tab, there are two options for output for Excel data files with multiple tabs. Excel Data File >> HEAL CSV Data Dictionary (one per tab) This will take a multi-tab Excel file and output one data dictionary for each tab in the Excel. The naming convention of the file will be 'heal-csv-dd-filename-tabname.' Each data dictionary will include a row for every variable within that specific tab. Excel Data File >> HEAL CSV Data Dictionary (one across tabs) This will take a multi-tab Excel file and output a single data dictionary with structure 'heal-csv-dd-filename.' This single data dictionary will include a row for every variable across all tabs. If you use this method, it is important that you ensure that variable names across sheets are consistent. This works particularly well if your data is structured such that the same variables are used across sheets. However, if you are using the same variable name in multiple different sheets, but it does not have the same meaning in each sheet, you should either vary the name of variables across sheets or you should use the one per tab option.","title":"Excel Data File with multiple tabs"},{"location":"datadict/create/#sas-file","text":"For tabular files saved in SAS (sas7bdat), you will want to have an accompanying catalog file (sas7bcat). Although the sas7bdat contains variable metadata information (variable names and variable labels/descriptions), the sas7bcat contains information about the formats and encoding of the variables, which are important for producing a complete data dictionary.","title":"SAS File"},{"location":"datadict/create/#creating-a-sas7bdat-and-sas7bcat-file","text":"Many SAS users build formats and labels into their data processing and analysis scripts. In this section, we provide syntax that can be easily copy-pasted into these existing workflows to create sas7bdat and sas7bcat files to input into the vlmd tool. This script template can be run separately or inserted directly at the end of a SAS user's workflow. Note If inserted directly, remember to delete the lines with %INCLUDE ) Template template.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SECOND SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file. If you already have an out directory assigned, skip this step and replace \u201cout\u201d with your out directory libname in the flow*/ libname out \"<INSERT THE DESIRED LOCATION (FILE PATH) TO YOUR SAS7BCAT AND SAS7BDAT FILES HERE>\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) */ data out . yourdata; set < INSERT THE NAME OF YOUR FINAL SAS DATASET HERE> ; run; The below SAS syntax is an example of how to use the template within your SAS workflow. The below sample script creates all of our variable and value labels. Your workflow may include multiple SAS scripts with multiple format statements and may include analyses and other PROC calls for data exploration, but for demonstration purposes, this example only uses one script and focuses on defining the variable and value labels. Example my_existing_sas_workflow.sas /*1. Read in input data */ proc import datafile= \"myprojectfolder/input/mydata.csv\" out =raw dbms=csv replace ; getnames=yes ; run; /*2. Set up proc format and apply formats and variable labels in data step */ /*Create encodings (value labels)*/ proc format; VALUE YESNO 0 = \"No\" 1 = \"Yes\" VALUE PUBLIC 1 = 'State mental health authority (SMHA)' 2 = 'Other state government agency or department' 3 = 'Regional/district authority or county, local, or municipal government' 4 = 'Tribal government' 5 = 'Indian Health Service' 6 = 'Department of Veterans Affairs' 7 = 'Other' VALUE FOCUS 1 = 'Mental health treatment' 2 = 'Substance abuse treatment' 3 = 'Mix of mental health and substance abuse treatment (neither is primary)' 4 = 'General health care' 5 = 'Other service focus' ; **Apply formats to dataset; data processed; set raw; /*Assign formats*/ format YOUNGADULTS TREATPSYCHOTHRPY TREATTRAUMATHRPY YESNO. FOCUS FOCUS. PUBLIC PUBLIC.; /*Add variable labels*/ label YOUNGADULTS= \"Accepts young adults (aged 18-25 years old) for Tx\" TREATPSYCHOTHRPY= \"Facility offers individual psychotherapy\" TREATTRAUMATHRPY= \"Facility offers trauma therapy\" FOCUS= \"Primary treatment focus of facility\" PUBLIC= \"Public agency or department that operates facility\" ; run; This second script called my_output.sas is the filled out template. Note the %INCLUDE function that calls my_existing_sas_workflow.sas my_output.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ */ %INCLUDE \"myprojectfolder/my_existing_workflow.sas\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file.*/ libname out \"myprojectfolder/output\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) to your output folder*/ data out . yourdata; set processed ; run;","title":"Creating a sas7bdat and sas7bcat file"},{"location":"datadict/create/#running-through-the-tool","text":"After creating the necessary sas7bdat and sas7bcat files, you are ready to convert to a HEAL-compliant data dictionary using the data packaging tool. Before you begin, ensure that your sas7bdat and sas7bcat files are saved in the same folder. The tool will only ask you to select your sas7bdat file. If the sas7bcat file is located in the same directory, the tool will automatically detect it, as well. If not detected, the tool will run without the sas7bcat catalog file and the encodings (i.e., value labels) will not be extracted from the catalog file and will not appear in your data dictionary. The output will be a minimal HEAL-compliant data dictionary.","title":"Running through the tool"},{"location":"datadict/create/#minimal-csv-data-dictionary","text":"If you have already created a data dictionary in CSV format, you can also use that to generate a HEAL-compliant data dictionary. The only requirements for a \"minimal CSV data dictionary\" to be ingested by the tool and converted into a HEAL-compliant data dictionary are two columns: name and description. With these two columns included, the data dictionary output will be a valid data dictionary (although it will be a fairly minimal data dictionary). However, this does not mean that you must only include these two columns. You may already have additional columns in your existing data dictionary, or you may want to add columns beyond name and description to better describe your dataset. For information on which additional columns it may be most helpful to include within your minimal data dictionary, and how to create, label, and format them to be successfully ingested and output by the data dictionary converter tool, refer to the HEAL Data Dictionary metadata schema .","title":"Minimal CSV Data Dictionary"},{"location":"datadict/create/#redcap-data-dictionary","text":"If you collected data in a REDCap data management system, HEAL-compliant data dictionaries can be generated directly from an exported REDCap data dictionary. The REDCap data dictionary export serves the purpose of providing variable-level metadata in a standardized, tabular format and is generally easy to export.","title":"REDCap Data Dictionary"},{"location":"datadict/create/#export-your-redcap-data-dictionary","text":"To download a REDCap CSV export, do the following*: After logging in to your REDCap project page, locate the Data dictionary page. A link to this page may be available on the project side bar (see image below) or in the Project Setup tab at the top of your page. After arriving at the Data dictionary page, click on Download the current data dictionary to export the dictionary (see below). *there may be slight differences depending on your specific REDCap instance and version","title":"Export your REDCap data dictionary"},{"location":"datadict/validate/","text":"Validate a Data Dictionary \u00b6 This feature is still in production. Data dictionary validation will be available in the next release of the tool.","title":"Validate a Data Dictionary"},{"location":"datadict/validate/#validate-a-data-dictionary","text":"This feature is still in production. Data dictionary validation will be available in the next release of the tool.","title":"Validate a Data Dictionary"},{"location":"datadict/view/","text":"Viewing or Editing a Data Dictionary \u00b6 If you would like to view or edit any of your existing HEAL-compliant Data Dictionaries, you can use the \"View/Edit\" feature. This feature may be especially useful if you have input a non-metadata-rich file type into the data dictionary tool (e.g., CSV, Excel) and would like to manually add some additional information to the output data dictionary beyond name and description, such as encodings, constraints, and formats. This tool is meant to allow you to more easily edit your data dictionary. However, you can also make edits directly in the CSV within Excel or another spreadsheet program. If you do make edits directly within the CSV, be sure to re-save it as a CSV each time you make edits. Navigate to \"View/Edit\" on the Data Dictionary tab. Select \"View/Edit CSV.\" The window below will pop up. Select \"Load CSV.\" Navigate to your working data package directory (you will not automatically be taken to your working data package directory) and select the HEAL-compliant data dictionary you would like to view or edit. Your data dictionary will populate in the window. You will be able to make edits here. When you have finished making edits, be sure to select \"Save CSV\" before closing the window.","title":"View/Edit a Data Dictionary"},{"location":"datadict/view/#viewing-or-editing-a-data-dictionary","text":"If you would like to view or edit any of your existing HEAL-compliant Data Dictionaries, you can use the \"View/Edit\" feature. This feature may be especially useful if you have input a non-metadata-rich file type into the data dictionary tool (e.g., CSV, Excel) and would like to manually add some additional information to the output data dictionary beyond name and description, such as encodings, constraints, and formats. This tool is meant to allow you to more easily edit your data dictionary. However, you can also make edits directly in the CSV within Excel or another spreadsheet program. If you do make edits directly within the CSV, be sure to re-save it as a CSV each time you make edits. Navigate to \"View/Edit\" on the Data Dictionary tab. Select \"View/Edit CSV.\" The window below will pop up. Select \"Load CSV.\" Navigate to your working data package directory (you will not automatically be taken to your working data package directory) and select the HEAL-compliant data dictionary you would like to view or edit. Your data dictionary will populate in the window. You will be able to make edits here. When you have finished making edits, be sure to select \"Save CSV\" before closing the window.","title":"Viewing or Editing a Data Dictionary"},{"location":"datadir/","text":"Creating or Continuing A Data Package \u00b6 The Data Package tab will always be the first place you visit when you open the data packaging tool. The Data Package directory is where all of your data packaging documentation will live, including your study\u2019s experiment tracker, resource tracker, results trackers, and data dictionaries. The first time you open the data packaging tool, you will need to create a Data Package directory . After you have created your Data Package directory, you will not need to do so again. However, each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session. Once you have created or set your working data package directory, throughout your session, the window at the top of the tool will display your working data package directory.","title":"The Data Package Tab"},{"location":"datadir/#creating-or-continuing-a-data-package","text":"The Data Package tab will always be the first place you visit when you open the data packaging tool. The Data Package directory is where all of your data packaging documentation will live, including your study\u2019s experiment tracker, resource tracker, results trackers, and data dictionaries. The first time you open the data packaging tool, you will need to create a Data Package directory . After you have created your Data Package directory, you will not need to do so again. However, each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session. Once you have created or set your working data package directory, throughout your session, the window at the top of the tool will display your working data package directory.","title":"Creating or Continuing A Data Package"},{"location":"datadir/pkgdir/","text":"Creating a Data Package Directory \u00b6 Click on the \"Data Package\" tab. Within the \"Create\" tab, select \"Create New Data Package.\" Select the location where you want to save the Data Package directory in the File Explorer pop up window. Once you select a location, the folder \"dsc-pkg\" will appear within that folder. The tool will also display the new folder location in the user status message box and set the dsc-pkg folder you have just created as your working data package directory for the current session: Your new dsc-pkg directory will contain an empty Experiment Tracker and Resource Tracker. The following steps will guide you through how to use the tool to fill out the Experiment Tracker, Resource Tracker, and Results Tracker (the last of which will be created as you move through the process of entering results information).","title":"Creating a New Data Package"},{"location":"datadir/pkgdir/#creating-a-data-package-directory","text":"Click on the \"Data Package\" tab. Within the \"Create\" tab, select \"Create New Data Package.\" Select the location where you want to save the Data Package directory in the File Explorer pop up window. Once you select a location, the folder \"dsc-pkg\" will appear within that folder. The tool will also display the new folder location in the user status message box and set the dsc-pkg folder you have just created as your working data package directory for the current session: Your new dsc-pkg directory will contain an empty Experiment Tracker and Resource Tracker. The following steps will guide you through how to use the tool to fill out the Experiment Tracker, Resource Tracker, and Results Tracker (the last of which will be created as you move through the process of entering results information).","title":"Creating a Data Package Directory"},{"location":"datadir/setdir/","text":"Setting Your Working Data Package Directory \u00b6 Although you will only need to create your data package once, you will need to set your data package working directory each time you open the tool. This will allow the tool to interface with your data packaging folder and its contents. To set your working data package directory: Navigate to the \"Create or Continue Data Package\" and select \"Continue Existing Data Package.\" Navigate to the data packaging directory on which you would like to work and select the folder. Once you select the directory, the User Status Message Box will print out the result that your working data package directory has been set. The file path to your working data package directory will also appear in the box at the top of the tool. This path will remain at the top of the tool throughout your session.","title":"Setting Your Working Data Package Directory"},{"location":"datadir/setdir/#setting-your-working-data-package-directory","text":"Although you will only need to create your data package once, you will need to set your data package working directory each time you open the tool. This will allow the tool to interface with your data packaging folder and its contents. To set your working data package directory: Navigate to the \"Create or Continue Data Package\" and select \"Continue Existing Data Package.\" Navigate to the data packaging directory on which you would like to work and select the folder. Once you select the directory, the User Status Message Box will print out the result that your working data package directory has been set. The file path to your working data package directory will also appear in the box at the top of the tool. This path will remain at the top of the tool throughout your session.","title":"Setting Your Working Data Package Directory"},{"location":"exptrack/","text":"About the Experiment Tracker \u00b6 This tab fills out the Experiment Tracker, which provides context on the experiments involved in the project including research questions, hypotheses, and approach. You may only have one experiment, in which case you only need to go through the process of annotating and saving your experiment to the Experiment Tracker once. However, if you have multiple experiments in your study, you will need to annotate and save each experiment to the tracker separately. You will only have one Experiment Tracker for your study, with one entry per experiment. The Experiment Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder. Example of an Experiment Tracker with one experiment entered:","title":"About the Experiment Tracker"},{"location":"exptrack/#about-the-experiment-tracker","text":"This tab fills out the Experiment Tracker, which provides context on the experiments involved in the project including research questions, hypotheses, and approach. You may only have one experiment, in which case you only need to go through the process of annotating and saving your experiment to the Experiment Tracker once. However, if you have multiple experiments in your study, you will need to annotate and save each experiment to the tracker separately. You will only have one Experiment Tracker for your study, with one entry per experiment. The Experiment Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder. Example of an Experiment Tracker with one experiment entered:","title":"About the Experiment Tracker"},{"location":"exptrack/addexp/","text":"Adding a New Experiment \u00b6 Getting Started \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate an experiment, the tool cannot automatically generate your experiment-ID or connect your experiment to your data package folder. You will receive the error message below. Navigate to the \"Add Experiment\" tab and select \"Add a new experiment\". The tool will generate your experiment ID automatically and sequentially, based on what is already in your working data package directory. Filling Out the Form \u00b6 Tip For additional information about each form field, please refer to the Experiment Tracker schema . Experiment name : This field can act as a more descriptive shorthand name for the experiment in addition to the experiment ID. The experiment name should follow the format of default-experiment-name, with words separated by a \"-\". Although not required, filling in the experiment name may help your internal team, as well as external investigators, to quickly understand the purpose and content of the experiment without having to read through the description, questions, and hypotheses. If you do not follow the required format, you will receive an error: Your experiment name must also be unique. When you enter an experiment name, the tool will review your other annotated experiments to confirm that the experiment name you have assigned is unique. If your experiment name is unique, the User Status Message Box will print a confirmation: Experiment Question(s) and Experiment Hypothesis(es) To add an experiment question/hypothesis, click on the paper icon. You can add multiple experimental questions and hypotheses for the same experiment. To add another, click on the paper icon again. When you have multiple questions/hypotheses entered, you can also change the order using the highlighted arrows. You can also use the 'X' to remove questions/hypotheses entered. Saving Your Experiment \u00b6 Once you have finished entering the experiment information, select \"Save experiment.\" Warning Make sure that you do not have your Experiment Tracker open before trying to save. If you attempt to save an experiment but have the Experiment Tracker open, the annotated experiment file will save to your dsc-pkg folder, but the tool will not be able to automatically save the information to the Experiment Tracker. You will receive this error: As the printed message explains, in this case, you will have to use the \"Batch add existing experiment(s) to tracker\" option to add this annotated experiment file to the Experiment Tracker. If the experiment is saved successfully, the User Status Message Box will display this message to indicate your experiment saved successfully and that the experiment has been written to the Experiment Tracker file: Although the tool will automatically add your experiment to the Experiment Tracker as part of the \"save\" process, your individual experiment annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated experiment There is an error in automatically adding the experiment to the Experiment Tracker, which would necessitate manually batch adding experiments to the tracker After you have added a new experiment, you can annotate a new experiment. If you would like to annotate a new experiment, you can select \"Clear form\" at the top of the Annotate Experiment window. This will reset your form and generate the next sequential experiment ID, so you can start annotating. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated.","title":"Add a New Experiment"},{"location":"exptrack/addexp/#adding-a-new-experiment","text":"","title":"Adding a New Experiment"},{"location":"exptrack/addexp/#getting-started","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate an experiment, the tool cannot automatically generate your experiment-ID or connect your experiment to your data package folder. You will receive the error message below. Navigate to the \"Add Experiment\" tab and select \"Add a new experiment\". The tool will generate your experiment ID automatically and sequentially, based on what is already in your working data package directory.","title":"Getting Started"},{"location":"exptrack/addexp/#filling-out-the-form","text":"Tip For additional information about each form field, please refer to the Experiment Tracker schema . Experiment name : This field can act as a more descriptive shorthand name for the experiment in addition to the experiment ID. The experiment name should follow the format of default-experiment-name, with words separated by a \"-\". Although not required, filling in the experiment name may help your internal team, as well as external investigators, to quickly understand the purpose and content of the experiment without having to read through the description, questions, and hypotheses. If you do not follow the required format, you will receive an error: Your experiment name must also be unique. When you enter an experiment name, the tool will review your other annotated experiments to confirm that the experiment name you have assigned is unique. If your experiment name is unique, the User Status Message Box will print a confirmation: Experiment Question(s) and Experiment Hypothesis(es) To add an experiment question/hypothesis, click on the paper icon. You can add multiple experimental questions and hypotheses for the same experiment. To add another, click on the paper icon again. When you have multiple questions/hypotheses entered, you can also change the order using the highlighted arrows. You can also use the 'X' to remove questions/hypotheses entered.","title":"Filling Out the Form"},{"location":"exptrack/addexp/#saving-your-experiment","text":"Once you have finished entering the experiment information, select \"Save experiment.\" Warning Make sure that you do not have your Experiment Tracker open before trying to save. If you attempt to save an experiment but have the Experiment Tracker open, the annotated experiment file will save to your dsc-pkg folder, but the tool will not be able to automatically save the information to the Experiment Tracker. You will receive this error: As the printed message explains, in this case, you will have to use the \"Batch add existing experiment(s) to tracker\" option to add this annotated experiment file to the Experiment Tracker. If the experiment is saved successfully, the User Status Message Box will display this message to indicate your experiment saved successfully and that the experiment has been written to the Experiment Tracker file: Although the tool will automatically add your experiment to the Experiment Tracker as part of the \"save\" process, your individual experiment annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated experiment There is an error in automatically adding the experiment to the Experiment Tracker, which would necessitate manually batch adding experiments to the tracker After you have added a new experiment, you can annotate a new experiment. If you would like to annotate a new experiment, you can select \"Clear form\" at the top of the Annotate Experiment window. This will reset your form and generate the next sequential experiment ID, so you can start annotating. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated.","title":"Saving Your Experiment"},{"location":"exptrack/batchexp/","text":"Advanced \u00b6 Batch Add Experiment(s) to Tracker \u00b6 If you try to save an experiment while you have the Experiment Tracker open, you will receive an error. The annotated experiment file will save as a .txt file within the dsc-pkg folder, but it will not be added to the Experiment Tracker. You will need to do this manually using the \"Batch add existing experiment(s) to tracker\" option. Ensure that your Experiment Tracker is closed before attempting to batch add experiments. Navigate to the \"Add Experiment\" tab and select \"Batch add existing experiment(s) to tracker\" under \"Advanced.\" Select the experiments that you want to add. It may be easiest to select all existing annotated experiment files when using this feature. The tool will scan the experiment files you select and only add those that are not already included in the Experiment Tracker. Note: These files follow the naming convention \"exp-trk-exp-\" If your files are successfully added to the Experiment Tracker, the User Status Message Box will provide a confirmation message:","title":"Advanced - Batch Add Experiments to the Tracker"},{"location":"exptrack/batchexp/#advanced","text":"","title":"Advanced"},{"location":"exptrack/batchexp/#batch-add-experiments-to-tracker","text":"If you try to save an experiment while you have the Experiment Tracker open, you will receive an error. The annotated experiment file will save as a .txt file within the dsc-pkg folder, but it will not be added to the Experiment Tracker. You will need to do this manually using the \"Batch add existing experiment(s) to tracker\" option. Ensure that your Experiment Tracker is closed before attempting to batch add experiments. Navigate to the \"Add Experiment\" tab and select \"Batch add existing experiment(s) to tracker\" under \"Advanced.\" Select the experiments that you want to add. It may be easiest to select all existing annotated experiment files when using this feature. The tool will scan the experiment files you select and only add those that are not already included in the Experiment Tracker. Note: These files follow the naming convention \"exp-trk-exp-\" If your files are successfully added to the Experiment Tracker, the User Status Message Box will provide a confirmation message:","title":"Batch Add Experiment(s) to Tracker"},{"location":"exptrack/editexp/","text":"Editing an Experiment \u00b6 If you want to edit an experiment annotation after you have created it, you can do so in the tool using the \"Edit an existing experiment\" feature. Info We encourage you to use the form to edit your experiments rather than entering/editing information manually into the Experiment Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit an existing experiment\" in the \"Add Experiment\" tab. Navigate to your dsc-pkg folder and select the annotated experiment .txt file that you want to edit. For example: The information on your annotated experiment will populate in the \"Annotate Experiment\" window. When you edit your first experiment, the tool will create an \"archive\" folder and will archive the original version of your result annotation (.txt) file there, so there are no issues with duplicate file naming. The User Status Message Box will also display a message providing information on the location of the original annotation file. Note Currently, you can only edit an experiment once within the tool, due to an issue of duplicate files in the archive folder. This will be addressed in later releases of the tool. For a temporary fix, if you need to make second or third edits to the same experiment file, you should go into the archive folder and change the name of the experiment txt file saved there (for example, you can change the name from \"exp-trk-exp-1\" to \"exp-trk-exp-1-1\"). This will allow the tool to archive your current experiment annotation without returning an error. Make any necessary edits to your experiment file, and then select \"Save experiment.\"","title":"Edit an Existing Experiment"},{"location":"exptrack/editexp/#editing-an-experiment","text":"If you want to edit an experiment annotation after you have created it, you can do so in the tool using the \"Edit an existing experiment\" feature. Info We encourage you to use the form to edit your experiments rather than entering/editing information manually into the Experiment Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit an existing experiment\" in the \"Add Experiment\" tab. Navigate to your dsc-pkg folder and select the annotated experiment .txt file that you want to edit. For example: The information on your annotated experiment will populate in the \"Annotate Experiment\" window. When you edit your first experiment, the tool will create an \"archive\" folder and will archive the original version of your result annotation (.txt) file there, so there are no issues with duplicate file naming. The User Status Message Box will also display a message providing information on the location of the original annotation file. Note Currently, you can only edit an experiment once within the tool, due to an issue of duplicate files in the archive folder. This will be addressed in later releases of the tool. For a temporary fix, if you need to make second or third edits to the same experiment file, you should go into the archive folder and change the name of the experiment txt file saved there (for example, you can change the name from \"exp-trk-exp-1\" to \"exp-trk-exp-1-1\"). This will allow the tool to archive your current experiment annotation without returning an error. Make any necessary edits to your experiment file, and then select \"Save experiment.\"","title":"Editing an Experiment"},{"location":"exptrack/exptotrack/","text":"Adding an Experiment to the Experiment Tracker \u00b6 After adding a new experiment, you will need to add it to your study's Experiment Tracker. Close the \"Annotate a new experiment\" window and select \"Add experiment to tracker\" in the \"Add Experiment\" tab. When the File Explorer window pops up, navigate to the dsc-pkg folder and select the text file you want to add to the tracker. For the first experiment added, the file name will be \"exp-trk-exp-1\". Your experiment will be written to the experiment tracker. The User Status Message Box will print a confirmation: Navigate to your dsc-pkg folder in your File Explorer and open your Experiment Tracker file. Confirm your experiment appears in the tracker. This step is not required, but it is recommended you check the tracker output after adding your first experiment to ensure the output looks correct. Viewing the Tracker If you want to review your Experiment Tracker at any point, you can view the current tracker within the tool to identify whether there are errors or changes to be made.","title":"Adding an Experiment to the Experiment Tracker"},{"location":"exptrack/exptotrack/#adding-an-experiment-to-the-experiment-tracker","text":"After adding a new experiment, you will need to add it to your study's Experiment Tracker. Close the \"Annotate a new experiment\" window and select \"Add experiment to tracker\" in the \"Add Experiment\" tab. When the File Explorer window pops up, navigate to the dsc-pkg folder and select the text file you want to add to the tracker. For the first experiment added, the file name will be \"exp-trk-exp-1\". Your experiment will be written to the experiment tracker. The User Status Message Box will print a confirmation: Navigate to your dsc-pkg folder in your File Explorer and open your Experiment Tracker file. Confirm your experiment appears in the tracker. This step is not required, but it is recommended you check the tracker output after adding your first experiment to ensure the output looks correct. Viewing the Tracker If you want to review your Experiment Tracker at any point, you can view the current tracker within the tool to identify whether there are errors or changes to be made.","title":"Adding an Experiment to the Experiment Tracker"},{"location":"exptrack/viewexp/","text":"Viewing the Experiment Tracker \u00b6 If you need to view anything that you have already input into the Experiment Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Experiment Tracker within the application to: Review which experiments you have already annotated and determining which you still need to annotate. Find/confirm the experiment ID for a particular experiment to include in resource annotation or to determine edits that need to be made when there has been a change. Navigate to \"View Tracker\" on the Experiment Tracker tab. Select \"View Experiment Tracker.\" The window below will pop up. Select \"Load Experiment Tracker.\" Your experiment tracker will populate in the window.","title":"View the Experiment Tracker"},{"location":"exptrack/viewexp/#viewing-the-experiment-tracker","text":"If you need to view anything that you have already input into the Experiment Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Experiment Tracker within the application to: Review which experiments you have already annotated and determining which you still need to annotate. Find/confirm the experiment ID for a particular experiment to include in resource annotation or to determine edits that need to be made when there has been a change. Navigate to \"View Tracker\" on the Experiment Tracker tab. Select \"View Experiment Tracker.\" The window below will pop up. Select \"Load Experiment Tracker.\" Your experiment tracker will populate in the window.","title":"Viewing the Experiment Tracker"},{"location":"resotrack/","text":"About the Resource Tracker \u00b6 This tab fills out the Resource Tracker, which provides an annotated inventory of all resources involved in the study. The depth and extent of information included in the Resource Tracker will be determined by how you want to share data and how you want to annotate the data you share. For help in making these decisions, refer to the HEAL data packaging guidance documentation . This guidance will provide information on how you should fill out each tracker based on your chosen annotation approach. You will only have one Resource Tracker for your study, with one entry per data or non-data/supporting file. The Resource Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder.","title":"About the Resource Tracker"},{"location":"resotrack/#about-the-resource-tracker","text":"This tab fills out the Resource Tracker, which provides an annotated inventory of all resources involved in the study. The depth and extent of information included in the Resource Tracker will be determined by how you want to share data and how you want to annotate the data you share. For help in making these decisions, refer to the HEAL data packaging guidance documentation . This guidance will provide information on how you should fill out each tracker based on your chosen annotation approach. You will only have one Resource Tracker for your study, with one entry per data or non-data/supporting file. The Resource Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder.","title":"About the Resource Tracker"},{"location":"resotrack/addresource/","text":"Adding a New Resource \u00b6 Getting Started \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a resource, the tool cannot automatically generate your resource-ID or connect your resource to your data package folder. You will receive the error message below. Navigate to the \"Add Resource\" tab and select \"Add a new resource.\" The tool will look through your set working data package directory to determine whether there are existing annotated resource files saved in the folder and will automatically generate the next sequential Resource ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this: Filling Out the Form Fields \u00b6 Tip For additional information about each form field, please refer to the Resource Tracker schema Hovering over each field in the form will provide additional information about what should be contained in the field. For example, for the Resource Title field: Fill out the Resource File Path and Resource Description . Select a Resource Category . Based on the Resource Category selected, additional fields will appear within the form. Resource Categories (and Sub-Categories) \u00b6 Below is a table of all the resource category and sub-category options for your reference. The table also contains information on which fields will appear when you choose a specific category or sub-category. Resource Category Sub-category Additional Resource Annotation Fields for Category Multi-result Figure Table Text Draft publication Publication Report White paper Poster Results Resource - Sub-Category Associated Results Tracker : provides the path to the Results Tracker associated with this multi-result file; Note that the Associated Files/Dependencies field will no longer appear. Single-result Figure Table Text Draft publication Publication Report White paper Poster Results Resource - Sub-Category Tabular-data Raw data Processed intermediate data Processed final data Resource Row Description : explanation of what one row within the tabular file represents Data Resource - Sub-Category Associated Data Dictionary : file path for the data dictionary associated with the tabular file (should not be put in the Associated Files/Dependencies field) Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Non-tabular-data Raw data Processed intermediate data Processed final data Data Resource - Sub-Category Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Metadata HEAL-formatted data dictionary Other formatted data dictionary Protocol ID map Analysis plan HEAL-formatted results tracker HEAL-formatted experiment tracker Metadata Resource - Sub-Category Note that if you select heal-formatted-results-tracker as the sub-category, the \"Associated Files/Dependencies field will no longer appear. Code No sub-categories No additional Resource Tracker fields Experiment Resource 'Belongs' To \u00b6 This option allows you to associate your resources directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu. Associated Files/Dependencies \u00b6 This is where you will list dependencies associated with the resource. How you record dependencies will depend on your annotation approach. For more information about how to decide on your annotation approach, refer to the HEAL data packaging guidance documentation . Regardless of your annotation approach, there are two ways to add \"Associated Files/Dependencies\" in the form. Warning You should only utilize one of the below methods for entering dependencies for a specific resource. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Resource Dependencies\" option, those files may overwrite the files you entered manually. Single-add : If you are adding only a few associated files/dependencies, you can add each individually using the \"Associated Files/Dependencies\" arrow button: Multi-add : If you would like to add many associated files at once, you can use the \"Add Multiple Resource Dependencies\" option, which can be found at the top of the window: Fill in this field with associated files/dependencies using drag and drop. The files you add via drag and drop will automatically appear in the \"Associated Files/Dependencies\" section of the form. Access \u00b6 This specifies the level of access that you will apply to this resource (permanent private, temporary private, restricted access, or public). If you select \"temporary-private,\" you will need to also denote 1) the level of access for the resource after the temporary private period and 2) the timepoint of the end of the temporary private period (Access Date). Add an additional row and select the level of access of the resource once the temporary private period ends. Fill in the \"Access Date\" when the temporary private period will end. This can just be a projection; you are not bound by this date. For other access levels, you will not need to complete these additional steps. Software used to produce/read the resource file \u00b6 If specific or proprietary software is required to open or read the resource, you should fill this out. This field is not required. If no special/proprietary software was used to produce/read the resource file, leave this field blank. Adding Multiple \"Like\" Files \u00b6 If you have multiple \"like\" files with a similar naming convention, you may want to add and annotate them all at once rather than individually. The tool has a special feature that you can utilize to annotate multiple \"like\" files all at once. What are \"like\" files? \u00b6 Examples of \"like\" files may be multiple datasets where each is a run of the same set of experiments or experimental results where each dataset corresponds to one subject's data. \"Like\" files will also have the same file extension. To be able to use this feature in the tool, \"like\" files must follow a common naming convention: For example, multiple data files by subject ID grouped in folders by week would be \"like\" files. The naming convention here is week-#/subject-# Another example: for an experiment testing samples on multiple different dates, files could follow the naming convention sample_1_date_20230818, sample_2_date_20230818, etc. If you have \"like\" files, but they don't follow a common naming convention, you will need to re-name the files (using a common naming convention) in order to be able to use this feature. If you have determined that you have a set of 'like' resources that you would like to annotate all at once, follow the steps below. How to add multiple \"like\" files \u00b6 Select \"Add Multiple 'like' Resources\" Drag and drop all \"like\" files you want to annotate together. The first of those files paths will appear in the \"Resource File Path\" field in the form. If your \"like\" files are in \"like\" folders (as in the above example of week-#/subject-# structure), you can drag the folders into the box, and the tool will unpack them for you. Once you add your \"like\" files, a box will pop up asking you to add a naming convention. You will need to enter a naming convention for your like files in the \"Resource File Name Convention\" box shown below: Follow the instructions in the dialog box above as to how to create a naming convention. Specifically, make sure that you use the {} brackets to bound the number, date, or descriptive information that changes from one like file to another. Your will specify your naming convention slightly differently depending on whether it is integrated within the directory structure (e.g., multiple data files by subject ID grouped in folders by week) or within the filename (e.g., multiple data files within the same directory that only differ by filename). If your naming convention is within the directory structure : Copy the file path from the Resource File Path field and paste into the Resource File Name Convention box: Change the piece that changes from one like file to another to a descriptive name within {}. Do not remove the file extension from the path (e.g., .txt, .csv, .xlsx). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. You have retained the file extension in the path. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended: If your naming convention is fully contained within the file name : You should only include the file name in the \"Resource File Name Convention\" field (rather than the file path). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended. Saving Your Resource \u00b6 Once you have finished entering the resource information, select \"Save resource.\" Warning Make sure you do not have your Resource Tracker open before trying to save. If you attempt to save a resource but have the Resource Tracker open, the annotated resource file will save to your dsc-pkg folder, but the tool will not be able to save the information to the Resource Tracker. You will receive this error: As the printed message explains, in this case, you will have to use the \"Batch add existing resource(s) to tracker\" option to add this annotated resource file to the Resource Tracker. After you select \"Save resource,\" the User Status Message Box should display a message confirming that your resource file saved successfully and that the resource has been written to the Resource Tracker file: This message will also include a note about all the files you listed as associated files/dependencies for your resource. This should be a helpful guide as to what resource(s) to annotate next, depending on your annotation approach. Although the tool will automatically add your resource to the Resource Tracker as part of the \"save\" process, your individual resource annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) directly unless: You need to edit an existing annotated resource There was an error in automatically the resoresourceruce to the Resource Tracker, which would necessitate manually batch adding resources to the tracker Next Steps \u00b6 After you have saved your resource, you can annotate a new resource. If you would like to annotate a new resource, you can select \"Clear form\" at the top of the Annotate Resource window. This will reset your form and generate the next sequential resource ID, so you can start annotating a new resource. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated.","title":"Add a New Resource"},{"location":"resotrack/addresource/#adding-a-new-resource","text":"","title":"Adding a New Resource"},{"location":"resotrack/addresource/#getting-started","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a resource, the tool cannot automatically generate your resource-ID or connect your resource to your data package folder. You will receive the error message below. Navigate to the \"Add Resource\" tab and select \"Add a new resource.\" The tool will look through your set working data package directory to determine whether there are existing annotated resource files saved in the folder and will automatically generate the next sequential Resource ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this:","title":"Getting Started"},{"location":"resotrack/addresource/#filling-out-the-form-fields","text":"Tip For additional information about each form field, please refer to the Resource Tracker schema Hovering over each field in the form will provide additional information about what should be contained in the field. For example, for the Resource Title field: Fill out the Resource File Path and Resource Description . Select a Resource Category . Based on the Resource Category selected, additional fields will appear within the form.","title":"Filling Out the Form Fields"},{"location":"resotrack/addresource/#resource-categories-and-sub-categories","text":"Below is a table of all the resource category and sub-category options for your reference. The table also contains information on which fields will appear when you choose a specific category or sub-category. Resource Category Sub-category Additional Resource Annotation Fields for Category Multi-result Figure Table Text Draft publication Publication Report White paper Poster Results Resource - Sub-Category Associated Results Tracker : provides the path to the Results Tracker associated with this multi-result file; Note that the Associated Files/Dependencies field will no longer appear. Single-result Figure Table Text Draft publication Publication Report White paper Poster Results Resource - Sub-Category Tabular-data Raw data Processed intermediate data Processed final data Resource Row Description : explanation of what one row within the tabular file represents Data Resource - Sub-Category Associated Data Dictionary : file path for the data dictionary associated with the tabular file (should not be put in the Associated Files/Dependencies field) Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Non-tabular-data Raw data Processed intermediate data Processed final data Data Resource - Sub-Category Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Metadata HEAL-formatted data dictionary Other formatted data dictionary Protocol ID map Analysis plan HEAL-formatted results tracker HEAL-formatted experiment tracker Metadata Resource - Sub-Category Note that if you select heal-formatted-results-tracker as the sub-category, the \"Associated Files/Dependencies field will no longer appear. Code No sub-categories No additional Resource Tracker fields","title":"Resource Categories (and Sub-Categories)"},{"location":"resotrack/addresource/#experiment-resource-belongs-to","text":"This option allows you to associate your resources directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu.","title":"Experiment Resource 'Belongs' To"},{"location":"resotrack/addresource/#associated-filesdependencies","text":"This is where you will list dependencies associated with the resource. How you record dependencies will depend on your annotation approach. For more information about how to decide on your annotation approach, refer to the HEAL data packaging guidance documentation . Regardless of your annotation approach, there are two ways to add \"Associated Files/Dependencies\" in the form. Warning You should only utilize one of the below methods for entering dependencies for a specific resource. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Resource Dependencies\" option, those files may overwrite the files you entered manually. Single-add : If you are adding only a few associated files/dependencies, you can add each individually using the \"Associated Files/Dependencies\" arrow button: Multi-add : If you would like to add many associated files at once, you can use the \"Add Multiple Resource Dependencies\" option, which can be found at the top of the window: Fill in this field with associated files/dependencies using drag and drop. The files you add via drag and drop will automatically appear in the \"Associated Files/Dependencies\" section of the form.","title":"Associated Files/Dependencies"},{"location":"resotrack/addresource/#access","text":"This specifies the level of access that you will apply to this resource (permanent private, temporary private, restricted access, or public). If you select \"temporary-private,\" you will need to also denote 1) the level of access for the resource after the temporary private period and 2) the timepoint of the end of the temporary private period (Access Date). Add an additional row and select the level of access of the resource once the temporary private period ends. Fill in the \"Access Date\" when the temporary private period will end. This can just be a projection; you are not bound by this date. For other access levels, you will not need to complete these additional steps.","title":"Access"},{"location":"resotrack/addresource/#software-used-to-produceread-the-resource-file","text":"If specific or proprietary software is required to open or read the resource, you should fill this out. This field is not required. If no special/proprietary software was used to produce/read the resource file, leave this field blank.","title":"Software used to produce/read the resource file"},{"location":"resotrack/addresource/#adding-multiple-like-files","text":"If you have multiple \"like\" files with a similar naming convention, you may want to add and annotate them all at once rather than individually. The tool has a special feature that you can utilize to annotate multiple \"like\" files all at once.","title":"Adding Multiple \"Like\" Files"},{"location":"resotrack/addresource/#what-are-like-files","text":"Examples of \"like\" files may be multiple datasets where each is a run of the same set of experiments or experimental results where each dataset corresponds to one subject's data. \"Like\" files will also have the same file extension. To be able to use this feature in the tool, \"like\" files must follow a common naming convention: For example, multiple data files by subject ID grouped in folders by week would be \"like\" files. The naming convention here is week-#/subject-# Another example: for an experiment testing samples on multiple different dates, files could follow the naming convention sample_1_date_20230818, sample_2_date_20230818, etc. If you have \"like\" files, but they don't follow a common naming convention, you will need to re-name the files (using a common naming convention) in order to be able to use this feature. If you have determined that you have a set of 'like' resources that you would like to annotate all at once, follow the steps below.","title":"What are \"like\" files?"},{"location":"resotrack/addresource/#how-to-add-multiple-like-files","text":"Select \"Add Multiple 'like' Resources\" Drag and drop all \"like\" files you want to annotate together. The first of those files paths will appear in the \"Resource File Path\" field in the form. If your \"like\" files are in \"like\" folders (as in the above example of week-#/subject-# structure), you can drag the folders into the box, and the tool will unpack them for you. Once you add your \"like\" files, a box will pop up asking you to add a naming convention. You will need to enter a naming convention for your like files in the \"Resource File Name Convention\" box shown below: Follow the instructions in the dialog box above as to how to create a naming convention. Specifically, make sure that you use the {} brackets to bound the number, date, or descriptive information that changes from one like file to another. Your will specify your naming convention slightly differently depending on whether it is integrated within the directory structure (e.g., multiple data files by subject ID grouped in folders by week) or within the filename (e.g., multiple data files within the same directory that only differ by filename). If your naming convention is within the directory structure : Copy the file path from the Resource File Path field and paste into the Resource File Name Convention box: Change the piece that changes from one like file to another to a descriptive name within {}. Do not remove the file extension from the path (e.g., .txt, .csv, .xlsx). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. You have retained the file extension in the path. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended: If your naming convention is fully contained within the file name : You should only include the file name in the \"Resource File Name Convention\" field (rather than the file path). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended.","title":"How to add multiple \"like\" files"},{"location":"resotrack/addresource/#saving-your-resource","text":"Once you have finished entering the resource information, select \"Save resource.\" Warning Make sure you do not have your Resource Tracker open before trying to save. If you attempt to save a resource but have the Resource Tracker open, the annotated resource file will save to your dsc-pkg folder, but the tool will not be able to save the information to the Resource Tracker. You will receive this error: As the printed message explains, in this case, you will have to use the \"Batch add existing resource(s) to tracker\" option to add this annotated resource file to the Resource Tracker. After you select \"Save resource,\" the User Status Message Box should display a message confirming that your resource file saved successfully and that the resource has been written to the Resource Tracker file: This message will also include a note about all the files you listed as associated files/dependencies for your resource. This should be a helpful guide as to what resource(s) to annotate next, depending on your annotation approach. Although the tool will automatically add your resource to the Resource Tracker as part of the \"save\" process, your individual resource annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) directly unless: You need to edit an existing annotated resource There was an error in automatically the resoresourceruce to the Resource Tracker, which would necessitate manually batch adding resources to the tracker","title":"Saving Your Resource"},{"location":"resotrack/addresource/#next-steps","text":"After you have saved your resource, you can annotate a new resource. If you would like to annotate a new resource, you can select \"Clear form\" at the top of the Annotate Resource window. This will reset your form and generate the next sequential resource ID, so you can start annotating a new resource. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated.","title":"Next Steps"},{"location":"resotrack/batchreso/","text":"Advanced \u00b6 Batch Add Resource(s) to Tracker \u00b6 If you try to save a resource while you have the Resource Tracker open, you will receive an error. The annotated resource file will save as a .txt file within the dsc-pkg folder, but it will not be added to the Resource Tracker. You will need to add this resource manually using the \"Batch add existing resource(s) to tracker\" option. Ensure that your Resource Tracker is not open before attempting to batch add resources. Navigate to the \"Add Resource\" tab and select \"Batch add existing resource(s) to tracker\" under \"Advanced.\" Select the resources that you want to add. It may be easiest to select all existing annotated resource files when using this feature. The tool will scan the resource files you select and only add those that are not already included within the Resource Tracker, so selecting a file that has already been included in the Resource Tracker will not produce an error here. Note: Resource annotation txt files follow the naming convention \"resource-trk-resource-\" If your files are successfully added to the Resource Tracker, the User Status Message Box will provide a confirmation message:","title":"Advanced - Batch Add Resources to the Tracker"},{"location":"resotrack/batchreso/#advanced","text":"","title":"Advanced"},{"location":"resotrack/batchreso/#batch-add-resources-to-tracker","text":"If you try to save a resource while you have the Resource Tracker open, you will receive an error. The annotated resource file will save as a .txt file within the dsc-pkg folder, but it will not be added to the Resource Tracker. You will need to add this resource manually using the \"Batch add existing resource(s) to tracker\" option. Ensure that your Resource Tracker is not open before attempting to batch add resources. Navigate to the \"Add Resource\" tab and select \"Batch add existing resource(s) to tracker\" under \"Advanced.\" Select the resources that you want to add. It may be easiest to select all existing annotated resource files when using this feature. The tool will scan the resource files you select and only add those that are not already included within the Resource Tracker, so selecting a file that has already been included in the Resource Tracker will not produce an error here. Note: Resource annotation txt files follow the naming convention \"resource-trk-resource-\" If your files are successfully added to the Resource Tracker, the User Status Message Box will provide a confirmation message:","title":"Batch Add Resource(s) to Tracker"},{"location":"resotrack/editresource/","text":"Editing an Existing Resource \u00b6 If you want to edit a resource after you have created it, you can do so in the tool using the \"Edit an existing resource\" feature. Info We encourage you to use the tool to edit your resources rather than entering/editing information manually into the Resource Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing resource\" in the \"Add Resource\" tab. Your dsc-pkg folder will open in File Explorer. Select the anntotated resource .txt file that you want to edit. For example : The information on your annotated resource will population in the \"Annotate Result\" window. When you edit your first resource, the tool will create an \"archive\" folder and will archive the original version of your resource annotation (.txt) file there, so there are no issues with duplicate file naming. The User Status Message Box will also display a message providing information on the location of the original annotation file (see example above). Note Currently, you can only edit a resource once within the tool, due to an issue of duplicate files in the archive folder. This will be addressed in later releases of the tool. For a temporary fix, if you need to make second or third edits to the same resource file, you should go into the archive folder and change the name of the resource txt file saved there (for example, you can change the name from \"resource-trk-result-1\" to \"resource-trk-result-1-1\" and so on for additional revisions). This will prevent an error. Make any necessary edits to your resource file, and then select \"Save resource.\"","title":"Edit an Existing Resource"},{"location":"resotrack/editresource/#editing-an-existing-resource","text":"If you want to edit a resource after you have created it, you can do so in the tool using the \"Edit an existing resource\" feature. Info We encourage you to use the tool to edit your resources rather than entering/editing information manually into the Resource Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing resource\" in the \"Add Resource\" tab. Your dsc-pkg folder will open in File Explorer. Select the anntotated resource .txt file that you want to edit. For example : The information on your annotated resource will population in the \"Annotate Result\" window. When you edit your first resource, the tool will create an \"archive\" folder and will archive the original version of your resource annotation (.txt) file there, so there are no issues with duplicate file naming. The User Status Message Box will also display a message providing information on the location of the original annotation file (see example above). Note Currently, you can only edit a resource once within the tool, due to an issue of duplicate files in the archive folder. This will be addressed in later releases of the tool. For a temporary fix, if you need to make second or third edits to the same resource file, you should go into the archive folder and change the name of the resource txt file saved there (for example, you can change the name from \"resource-trk-result-1\" to \"resource-trk-result-1-1\" and so on for additional revisions). This will prevent an error. Make any necessary edits to your resource file, and then select \"Save resource.\"","title":"Editing an Existing Resource"},{"location":"resotrack/viewresource/","text":"Viewing the Resource Tracker \u00b6 If you need to view anything that you have already input into the Resource Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Resource Tracker within the application to: Review which individual resources you have already annotated and determine which you still need to annotate. Find/confirm the resource ID for a particular resource to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Resource Tracker tab. Select \"View Resource Tracker.\" The window below will pop up. Select \"Load Resource Tracker.\" Your Resource Tracker will populate in the window.","title":"View the Resource Tracker"},{"location":"resotrack/viewresource/#viewing-the-resource-tracker","text":"If you need to view anything that you have already input into the Resource Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Resource Tracker within the application to: Review which individual resources you have already annotated and determine which you still need to annotate. Find/confirm the resource ID for a particular resource to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Resource Tracker tab. Select \"View Resource Tracker.\" The window below will pop up. Select \"Load Resource Tracker.\" Your Resource Tracker will populate in the window.","title":"Viewing the Resource Tracker"},{"location":"resulttrack/","text":"About the Results Tracker \u00b6 This tab will help you create and fill out Results Tracker(s). Each Results Tracker provides an annotated inventory of all results included in a multi-result file. The depth and extent of information included in a Results Tracker will be determined by the approach you have chosen for annotation of your data. You should create one Results Tracker for each multi-result file (e.g., manuscript, poster, etc.) that you share. If you only have one multi-result file that you are planning to share, you will only need to create one Results Tracker. However, if you have multiple multi-result files, you will need to create a Results Tracker for each multi-result file. Example of a Results Tracker with multiple individual results annotated: A Note on the Results Tracker Unlike the Experiment Tracker and Resource Tracker shells, which automatically appeared in your dsc-pkg folder, you will create the Results Tracker(s) through the process of adding individual results.","title":"About the Results Tracker"},{"location":"resulttrack/#about-the-results-tracker","text":"This tab will help you create and fill out Results Tracker(s). Each Results Tracker provides an annotated inventory of all results included in a multi-result file. The depth and extent of information included in a Results Tracker will be determined by the approach you have chosen for annotation of your data. You should create one Results Tracker for each multi-result file (e.g., manuscript, poster, etc.) that you share. If you only have one multi-result file that you are planning to share, you will only need to create one Results Tracker. However, if you have multiple multi-result files, you will need to create a Results Tracker for each multi-result file. Example of a Results Tracker with multiple individual results annotated: A Note on the Results Tracker Unlike the Experiment Tracker and Resource Tracker shells, which automatically appeared in your dsc-pkg folder, you will create the Results Tracker(s) through the process of adding individual results.","title":"About the Results Tracker"},{"location":"resulttrack/addresult/","text":"Adding a New Result \u00b6 Getting Started \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a result, the tool cannot automatically generate your result-ID or connect your result to your data package folder. You will receive the error message below. Navigate to the \"Add Results\" tab and select \"Add a new result.\" The tool will look through your set working data package directory to determine whether there are existing annotated results files saved in the folder and will automatically generate the next sequential Result ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this: Filling Out the Form \u00b6 Tip For additional information about each form field, please refer to the Results Tracker schema . Hovering over each field in the form will provide additional information about what should be contained within the field. For example, for the Result Category field: Fill out a short Result Description. Select a Result Category. Based on the Result Category selected, additional questions will appear within the form. Experiment Result 'Belongs' To : You can define the experiment with which your result is associated here. This option allows you to associate your results directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu. Associated Multi-Result File(s) : You will also need to provide the path for the Associated Multi-Result File (e.g., manuscript, poster, etc.), in which the individual result appears. To add, select the arrow below the field: If the result is associated with multiple multi-result files , select the arrow again and enter the paths to each of the multi-result files here. This will allow the tool to create a results tracker for each of those multi-result files in future steps (or add the individual result to the right results trackers), all of which will be associated with this result. Figure Number/Table Number : If you selected \"Figure\" or \"Table\" within \"Result Category,\" you will need to provide a corresponding figure/table number for each \"Associated Multi-Result File.\" Click on the arrow to insert each figure/table number. Ensure that the figure/table numbers are in the same order as the multi-result files. You can adjust the order using the green up and down arrows. Associated Files/Dependencies : There are two ways to add \"Associated Files/Dependencies,\" manually or via batch add. See below for descriptions of each. Warning You should only utilize one of the below methods for entering dependencies when adding a specific result. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Results Dependencies\" option, those files may overwrite the files you entered manually. Manually adding Associated Files/Dependencies If you are adding only a few associated files/dependencies, you can add each row individually using the arrow button: Batch adding Associated Files/Dependencies If you would like to add many associated files at once, you can use the \"Add Multiple Results Dependencies\" option, which can be found at the top of the \"Add Results\" window: Fill in this field with associated files/dependencies using drag-and-drop from your file explorer. The files you drag and drop will automatically appear in the \"Associated Files/Dependencies\" section in the form. Result Supports : describes the larger claim that the result is used to support in the multi-result file. This is not required but can be very useful for data reuse and interpretation for future researchers. Saving Your Result \u00b6 When you are done filling out the form, select \"Save result.\" Warning Make sure that you do not have your Results Tracker open before trying to save. If you attempt to save a result but have the corresponding Results Tracker open, the annotated result file will save to your dsc-pkg folder, but the tool will not be able to automatically save the information to the Results Tracker. You will receive this error: As the printed message explains, in this case, you will have to use the \"Batch add existing result(s) to tracker\" option to add this annotated result file to the Results Tracker. If your result saves successfully, The User Status Message Box will display this message to indicate your result saved successfully and that the result has been written to the Results Tracker file. Although the tool will generate the necessary Results Trackers and add your result automatically as part of the \"save\" process, your individual result annotation file will also be saved within your dsc-pkg folder as a .txt file. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated result There is an error in automatically adding results to the Results Tracker, which would necessitate manually batch adding results to the tracker Clear the form. When the form resets, the next sequential Result ID will be generated, so you can start annotating a new result right away.","title":"Add a New Result"},{"location":"resulttrack/addresult/#adding-a-new-result","text":"","title":"Adding a New Result"},{"location":"resulttrack/addresult/#getting-started","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a result, the tool cannot automatically generate your result-ID or connect your result to your data package folder. You will receive the error message below. Navigate to the \"Add Results\" tab and select \"Add a new result.\" The tool will look through your set working data package directory to determine whether there are existing annotated results files saved in the folder and will automatically generate the next sequential Result ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this:","title":"Getting Started"},{"location":"resulttrack/addresult/#filling-out-the-form","text":"Tip For additional information about each form field, please refer to the Results Tracker schema . Hovering over each field in the form will provide additional information about what should be contained within the field. For example, for the Result Category field: Fill out a short Result Description. Select a Result Category. Based on the Result Category selected, additional questions will appear within the form. Experiment Result 'Belongs' To : You can define the experiment with which your result is associated here. This option allows you to associate your results directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu. Associated Multi-Result File(s) : You will also need to provide the path for the Associated Multi-Result File (e.g., manuscript, poster, etc.), in which the individual result appears. To add, select the arrow below the field: If the result is associated with multiple multi-result files , select the arrow again and enter the paths to each of the multi-result files here. This will allow the tool to create a results tracker for each of those multi-result files in future steps (or add the individual result to the right results trackers), all of which will be associated with this result. Figure Number/Table Number : If you selected \"Figure\" or \"Table\" within \"Result Category,\" you will need to provide a corresponding figure/table number for each \"Associated Multi-Result File.\" Click on the arrow to insert each figure/table number. Ensure that the figure/table numbers are in the same order as the multi-result files. You can adjust the order using the green up and down arrows. Associated Files/Dependencies : There are two ways to add \"Associated Files/Dependencies,\" manually or via batch add. See below for descriptions of each. Warning You should only utilize one of the below methods for entering dependencies when adding a specific result. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Results Dependencies\" option, those files may overwrite the files you entered manually. Manually adding Associated Files/Dependencies If you are adding only a few associated files/dependencies, you can add each row individually using the arrow button: Batch adding Associated Files/Dependencies If you would like to add many associated files at once, you can use the \"Add Multiple Results Dependencies\" option, which can be found at the top of the \"Add Results\" window: Fill in this field with associated files/dependencies using drag-and-drop from your file explorer. The files you drag and drop will automatically appear in the \"Associated Files/Dependencies\" section in the form. Result Supports : describes the larger claim that the result is used to support in the multi-result file. This is not required but can be very useful for data reuse and interpretation for future researchers.","title":"Filling Out the Form"},{"location":"resulttrack/addresult/#saving-your-result","text":"When you are done filling out the form, select \"Save result.\" Warning Make sure that you do not have your Results Tracker open before trying to save. If you attempt to save a result but have the corresponding Results Tracker open, the annotated result file will save to your dsc-pkg folder, but the tool will not be able to automatically save the information to the Results Tracker. You will receive this error: As the printed message explains, in this case, you will have to use the \"Batch add existing result(s) to tracker\" option to add this annotated result file to the Results Tracker. If your result saves successfully, The User Status Message Box will display this message to indicate your result saved successfully and that the result has been written to the Results Tracker file. Although the tool will generate the necessary Results Trackers and add your result automatically as part of the \"save\" process, your individual result annotation file will also be saved within your dsc-pkg folder as a .txt file. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated result There is an error in automatically adding results to the Results Tracker, which would necessitate manually batch adding results to the tracker Clear the form. When the form resets, the next sequential Result ID will be generated, so you can start annotating a new result right away.","title":"Saving Your Result"},{"location":"resulttrack/batchresult/","text":"Advanced \u00b6 Batch Add Result(s) to Tracker \u00b6 If you try to save a result while you have the corresponding Results Tracker open, you will receive an error. The annotated result file will save as a .txt file within the dsc-pkg folder, but it will not be added to the Results Tracker. You will need to do this manually using the \"Batch add existing result(s) to tracker\" option. Ensure that none of your Results Trackers are open before attempting to batch add results. Navigate to the \"Add Result\" tab and select \"Batch add existing result(s) to tracker\" under \"Advanced.\" Select the results that you want to add. It may be easiest to select all existing annotated result files when using this feature. The tool will scan the result files you select and only add those that are not already included in within the Results Tracker, so selecting a file that has already been included in the Results Tracker will not produce an error here. Note: These files follow the naming convention \"result-trk-result-\" If your files are successfully added to the appropriate Results Trackers, the User Status Message Box will provide a confirmation message:","title":"Advanced - Batch Add Results to the Tracker"},{"location":"resulttrack/batchresult/#advanced","text":"","title":"Advanced"},{"location":"resulttrack/batchresult/#batch-add-results-to-tracker","text":"If you try to save a result while you have the corresponding Results Tracker open, you will receive an error. The annotated result file will save as a .txt file within the dsc-pkg folder, but it will not be added to the Results Tracker. You will need to do this manually using the \"Batch add existing result(s) to tracker\" option. Ensure that none of your Results Trackers are open before attempting to batch add results. Navigate to the \"Add Result\" tab and select \"Batch add existing result(s) to tracker\" under \"Advanced.\" Select the results that you want to add. It may be easiest to select all existing annotated result files when using this feature. The tool will scan the result files you select and only add those that are not already included in within the Results Tracker, so selecting a file that has already been included in the Results Tracker will not produce an error here. Note: These files follow the naming convention \"result-trk-result-\" If your files are successfully added to the appropriate Results Trackers, the User Status Message Box will provide a confirmation message:","title":"Batch Add Result(s) to Tracker"},{"location":"resulttrack/editresult/","text":"Editing an Existing Result \u00b6 If you want to edit a result after you have created it, you can do so in the tool using the \"Edit an existing result\" feature. Info We encourage you to use the form to edit your results rather than entering/editing information manually into the Results Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing result\" in the \"Add Result\" tab. Navigate to your dsc-pkg folder and select the annotated result .txt file that you want to edit. For example: The information on your annotated result will populate in the \"Annotate Result\" window. When you edit your first result, the tool will create an \"archive\" folder and will archive the original version of your result annotation (.txt) file there, so there are no issues with file naming. The User Status Message Box will also display a message providing information on the location of the original annotation file (see example above). Note Currently, you can only edit a result once within the tool, due to an issue of duplicate files in the archive folder. This will be addressed in later releases of the tool. For a temporary fix, if you need to make second or third edits to the same result file, you should go into the archive folder and change the name of the result txt file saved there (for example, you can change the name from \"result-trk-result-1\" to \"result-trk-result-1-1\"). Make any necessary edits to your result file, and then select \"Save result.\"","title":"Edit an Existing Result"},{"location":"resulttrack/editresult/#editing-an-existing-result","text":"If you want to edit a result after you have created it, you can do so in the tool using the \"Edit an existing result\" feature. Info We encourage you to use the form to edit your results rather than entering/editing information manually into the Results Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing result\" in the \"Add Result\" tab. Navigate to your dsc-pkg folder and select the annotated result .txt file that you want to edit. For example: The information on your annotated result will populate in the \"Annotate Result\" window. When you edit your first result, the tool will create an \"archive\" folder and will archive the original version of your result annotation (.txt) file there, so there are no issues with file naming. The User Status Message Box will also display a message providing information on the location of the original annotation file (see example above). Note Currently, you can only edit a result once within the tool, due to an issue of duplicate files in the archive folder. This will be addressed in later releases of the tool. For a temporary fix, if you need to make second or third edits to the same result file, you should go into the archive folder and change the name of the result txt file saved there (for example, you can change the name from \"result-trk-result-1\" to \"result-trk-result-1-1\"). Make any necessary edits to your result file, and then select \"Save result.\"","title":"Editing an Existing Result"},{"location":"resulttrack/resulttotrack/","text":"Adding Result(s) to Result Tracker(s) \u00b6 Once you have annotated your results files, close the \"Annotate Result\" window and return to the \"Add Result\" tab. Click on \"Add result to tracker.\" Navigate to the results that you want to add. You can select multiple by holding down \"ctrl\" (\"command\" on a Mac) while selecting your results files. After selecting these files, another window will pop up to select your DSC package directory, which is where your results trackers will generate (this should be the same folder where your results annotation txt files are saved). If you have not already created results trackers, your folder should show no trackers found when you select the dsc-pkg folder: Once you select the folder, you will receive information in the User Status Message Box notifying you that the Results Tracker(s) have been created based on your results file(s). In the example below, results added were associated with two different multi-result files, so two results trackers were created and saved in the dsc-pkg folder. And the individual results were automatically entered into each tracker, as appropriate. Once the Results Trackers have been generated through this step, you can still continue to add results to your existing Results Trackers using the \"Add result to tracker\" option. New results will be added to the corresponding Results Tracker files. Once you have entered a few results, you may want to review your Results Tracker(s) to ensure that your results have been entered correctly. Viewing and Editing the Tracker You can review your Results Tracker at any point using the view feature . If you find there is something you would like to add to an entry or an error that you would like to correct, you can edit any result within the tool .","title":"Adding Result(s) to Result Tracker(s)"},{"location":"resulttrack/resulttotrack/#adding-results-to-result-trackers","text":"Once you have annotated your results files, close the \"Annotate Result\" window and return to the \"Add Result\" tab. Click on \"Add result to tracker.\" Navigate to the results that you want to add. You can select multiple by holding down \"ctrl\" (\"command\" on a Mac) while selecting your results files. After selecting these files, another window will pop up to select your DSC package directory, which is where your results trackers will generate (this should be the same folder where your results annotation txt files are saved). If you have not already created results trackers, your folder should show no trackers found when you select the dsc-pkg folder: Once you select the folder, you will receive information in the User Status Message Box notifying you that the Results Tracker(s) have been created based on your results file(s). In the example below, results added were associated with two different multi-result files, so two results trackers were created and saved in the dsc-pkg folder. And the individual results were automatically entered into each tracker, as appropriate. Once the Results Trackers have been generated through this step, you can still continue to add results to your existing Results Trackers using the \"Add result to tracker\" option. New results will be added to the corresponding Results Tracker files. Once you have entered a few results, you may want to review your Results Tracker(s) to ensure that your results have been entered correctly. Viewing and Editing the Tracker You can review your Results Tracker at any point using the view feature . If you find there is something you would like to add to an entry or an error that you would like to correct, you can edit any result within the tool .","title":"Adding Result(s) to Result Tracker(s)"},{"location":"resulttrack/viewresult/","text":"Viewing the Results Tracker \u00b6 If you need to view anything that you have already input into the Results Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Results Tracker within the application to: Review which individual results associated with a multi-result file that you have already annotated and determining which you still need to annotate. Find/confirm the result ID for a particular result to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Results Tracker tab. Select \"View Results Tracker.\" The window below will pop up. Select \"Load Results Tracker.\" Find and select the results tracker. Your results tracker will populate in the window.","title":"View the Results Tracker"},{"location":"resulttrack/viewresult/#viewing-the-results-tracker","text":"If you need to view anything that you have already input into the Results Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Results Tracker within the application to: Review which individual results associated with a multi-result file that you have already annotated and determining which you still need to annotate. Find/confirm the result ID for a particular result to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Results Tracker tab. Select \"View Results Tracker.\" The window below will pop up. Select \"Load Results Tracker.\" Find and select the results tracker. Your results tracker will populate in the window.","title":"Viewing the Results Tracker"},{"location":"schemas/","text":"Standard Data Package Metadata Schemas \u00b6 View metadata schemas. Experiment Tracker Resource Tracker Results Tracker Data Dictionary","title":"Standard Data Package Metadata Schemas"},{"location":"schemas/#standard-data-package-metadata-schemas","text":"View metadata schemas. Experiment Tracker Resource Tracker Results Tracker Data Dictionary","title":"Standard Data Package Metadata Schemas"},{"location":"schemas/md_data_dict/","text":"HEAL Data Dictionary \u00b6 HEAL DSC Core Metadata piece to track and provide basic information about variables in a tabular data file (i.e. a data file with rows and columns) from your HEAL study. Objective is to list all variables and descriptive information about those variables. This will ensure that potential secondary data users know what data has been collected or calculated and how to use these data. Note that a given study can have multiple tabular data files; You should create a data dictionary for each tabular data file. Thus, a study may have multiple data dictionaries This is an abridged version of the schema and only describes the fields/information you should provide for each variable. For the full HEAL Data Dictionary document schema specification, see here . NOTE: Only name and description properties are required. For categorical variables, constraints.enum and encodings (where applicable) properties are highly encouraged. For studies using HEAL or other common data elements (CDEs), standardsMappings information is highly encouraged. type and format properties may be particularly useful for some variable types (e.g. date-like variables) Properties \u00b6 module (string) : The section, form, survey instrument, set of measures or other broad category used to group variables. Examples: Demographics PROMIS Medical History name (string,required) : The name of a variable (i.e., field) as it appears in the data. Examples: gender_id title (string) : The human-readable title or label of the variable. Examples: Gender identity description (string,required) : An extended description of the variable. This could be the definition of a variable or the question text (e.g., if a survey). Include measurement units in the description where relevant (e.g. temperature in celsius, distance in millimeters). Examples: The participant's age at the time of study enrollment, in years type (string) : A classification or category of a particular data element or property expected or allowed in the dataset. Must be one of: [\"number\", \"integer\", \"string\", \"any\", \"boolean\", \"date\", \"datetime\", \"time\", \"year\", \"yearmonth\", \"duration\", \"geopoint\"] . For details and examples of each of these types see here . format (of below) : Indicates the format of the type specified in the type property. Each format is dependent on the type specified. For example: If type is \"string\", then see the String formats . If type is \"date\", \"datetime\", or \"time\", default format is ISO8601 formatting for those respective types (see details on ISO8601 format for Date , Datetime , or Time ) - If you want to specify a date-like variable using standard Python/C strptime syntax, see here for details. See here for more information about appropriate format values by variable type . constraints.maxLength (integer) : Indicates the maximum length of an iterable (e.g., array, string, or object). For example, if 'Hello World' is the longest value of a categorical variable, this would be a maxLength of 11. constraints.enum (string) : Constrains possible values to a set of values. If a variable is contrained to a set of values, you may want to consider providing more information about what each value in the set mean using the encodings property for the same variable (e.g. If a variable has possible values of 1, 2, and 3 and these correspond to \"yes\", \"no\" and \"maybe\", you can indicate the constraint of this variable to values of 1, 2, and 3 using the constraints.enum property for that variable, and you can indicate that 1=\"yes\", 2=\"no\", and 3=\"maybe\" using the encodings property for that variable). Examples: 1|2|3|4|5|6|7|8 Treated|Control constraints.pattern (string) : A regular expression pattern the data MUST conform to. constraints.maximum (integer) : Specifies the maximum value of a field (e.g., maximum -- or most recent -- date, maximum integer etc). Note, this is different than maxLength property. constraints.minimum (integer) : Specifies the minimum value of a field. encodings (string) : For variables constrained to a set of values, variable value encodings provide a way to further annotate each value in the constrained set of values the variable can take on, making values easier to understand. If a variable is contrained to a set of values, you may want to consider providing the set of values to which the variable is constrained using the constraints.enum property for that variable, and then providing more information about what each value in the set means using the encodings property for the same variable (e.g. If a variable has possible values of 1, 2, and 3 and these correspond to \"yes\", \"no\" and \"maybe\", you can indicate the constraint of this variable to values of 1, 2, and 3 using the constraints.enum property for that variable, and you can indicate that 1=\"yes\", 2=\"no\", and 3=\"maybe\" using the encodings property for that variable). Examples: 0=No|1=Yes HW=Hello world|GBW=Good bye world|HM=Hi,Mike ordered (boolean) : Indicates whether a categorical variable is ordered. This variable is relevant for variables that have an ordered relationship but not necessarily a numerical relationship (e.g., Strongly disagree < Disagree < Neutral < Agree). If ordered is set as True, order will be set based on ordering of values provided in the constraints.enum property for this variable. missingValues (string) : A list of missing values specific to a variable. Examples: Missing|Skipped|No preference Missing trueValues (string) : For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values. Examples: REQUIRED required|Yes|Y|Checked falseValues (string) : For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values. standardsMappings.url (string) : A url that links out to a published, standardized mapping for the variable. For example, if a variable corresponds to the first question in a published, validated survey instrument to measure depression (e.g. PHQ9), provide a link to the PHQ9 Questionnaire at the NIH Common Data Element Repository. This property is under development, and may be restricted in future to persistent identifier urls such as a DOI . Examples: https://cde.nlm.nih.gov/formView?tinyId=myG8MkTbwg standardsMappings.type (string) : The type of published, standardized mapping available for the variable (e.g. a variable may correspond to a Common Data Element, or CDE, within the NIH Common Data Elements program). This property is under development, and will have a controlled vocabulary. Examples: cde ontology reference_list standardsMappings.label (string) : A free text label that may be used to provide any information available about a published, standardized mapping available for the variable in an unstructured manner (e.g. if a variable corresponds to the first question in the PHQ9 Questionnaire, which is a published, validated survey instrument to measure depression, it may be useful to provide information about th standard that variable reflects using free text such as \"depression, PHQ, PHQ9\"). standardsMappings.source (string) : The source of the published, standardized mapping available for the variable (e.g. the NIH CDE Repository ). This property is under development, and will have a controlled vocabulary. standardsMappings.id (string) : The identifier (ID) of the published, standardized mapping available for the variable within the source provided in the standardsMappings.source property for this variable (e.g. the PHQ9 Questionnaire has been assigned ID \" myG8MkTbwg \" at the NIH CDE Repository CDE source). relatedConcepts.url (string) : The url that links out to the published, standardized concept. Examples: https://meshb.nlm.nih.gov/record/ui?ui=D018410 relatedConcepts.type (string) : The type of mapping to a published set of concepts related to the given field such as ontological information (eg. NCI thesaurus, bioportal etc) relatedConcepts.label (string) : A free text label of mapping to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc) relatedConcepts.source (string) : The source of the related concept. This property is under development, and will have a controlled vocabulary. relatedConcepts.id (string) : The id locating the individual mapping within the given source. univarStats.median (number) univarStats.mean (number) univarStats.std (number) univarStats.min (number) univarStats.max (number) univarStats.mode (number) univarStats.count (integer) univarStats.twentyFifthPercentile (number) univarStats.seventyFifthPercentile (number) univarStats.categoricalMarginals.name (string) univarStats.categoricalMarginals.count (integer) End of schema - Extra infomation \u00b6 type enum definitions \u00b6 number (A numeric value with optional decimal places. (e.g., 3.14)) integer (A whole number without decimal places. (e.g., 42)) string (A sequence of characters. (e.g., \\\"test\\\")) any (Any type of data is allowed. (e.g., true)) boolean (A binary value representing true or false. (e.g., true)) date (A specific calendar date. (e.g., \\\"2023-05-25\\\")) datetime (A specific date and time, including timezone information. (e.g., \\\"2023-05-25T10:30:00Z\\\")) time (A specific time of day. (e.g., \\\"10:30:00\\\")) year (A specific year. (e.g., 2023) yearmonth (A specific year and month. (e.g., \\\"2023-05\\\")) duration (A length of time. (e.g., \\\"PT1H\\\") geopoint (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278])) format details for date, datetime, time type variables \u00b6 Date Formats (string) A format for a date variable ( date , time , datetime ). Highly recommended to be an ISO8601 format string default : An ISO8601 format string. any : Any parsable representation of a date/time/datetime. The implementing library can attempt to parse the datetime via a range of strategies. **{PATTERN}**: The value can be parsed according to `{PATTERN}`, which `MUST` follow the date formatting syntax of C / Python [strftime](http://strftime.org/) such as: - \"`%Y-%m-%d` (for date, e.g., 2023-05-25)\" - \"`%Y%-%d` (for date, e.g., 20230525) for date without dashes\" - \"`%Y-%m-%dT%H:%M:%S` (for datetime, e.g., 2023-05-25T10:30:45)\" - \"`%Y-%m-%dT%H:%M:%SZ` (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z)\" - \"`%Y-%m-%dT%H:%M:%S%z` (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300)\" - \"`%Y-%m-%dT%H:%M` (for datetime without seconds, e.g., 2023-05-25T10:30)\" - \"`%Y-%m-%dT%H` (for datetime without minutes and seconds, e.g., 2023-05-25T10)\" - \"`%H:%M:%S` (for time, e.g., 10:30:45)\" - \"`%H:%M:%SZ` (for time with UTC timezone, e.g., 10:30:45Z)\" - \"`%H:%M:%S%z` (for time with timezone offset, e.g., 10:30:45+0300)\"","title":"Data Dictionary"},{"location":"schemas/md_data_dict/#heal-data-dictionary","text":"HEAL DSC Core Metadata piece to track and provide basic information about variables in a tabular data file (i.e. a data file with rows and columns) from your HEAL study. Objective is to list all variables and descriptive information about those variables. This will ensure that potential secondary data users know what data has been collected or calculated and how to use these data. Note that a given study can have multiple tabular data files; You should create a data dictionary for each tabular data file. Thus, a study may have multiple data dictionaries This is an abridged version of the schema and only describes the fields/information you should provide for each variable. For the full HEAL Data Dictionary document schema specification, see here . NOTE: Only name and description properties are required. For categorical variables, constraints.enum and encodings (where applicable) properties are highly encouraged. For studies using HEAL or other common data elements (CDEs), standardsMappings information is highly encouraged. type and format properties may be particularly useful for some variable types (e.g. date-like variables)","title":"HEAL Data Dictionary"},{"location":"schemas/md_data_dict/#properties","text":"module (string) : The section, form, survey instrument, set of measures or other broad category used to group variables. Examples: Demographics PROMIS Medical History name (string,required) : The name of a variable (i.e., field) as it appears in the data. Examples: gender_id title (string) : The human-readable title or label of the variable. Examples: Gender identity description (string,required) : An extended description of the variable. This could be the definition of a variable or the question text (e.g., if a survey). Include measurement units in the description where relevant (e.g. temperature in celsius, distance in millimeters). Examples: The participant's age at the time of study enrollment, in years type (string) : A classification or category of a particular data element or property expected or allowed in the dataset. Must be one of: [\"number\", \"integer\", \"string\", \"any\", \"boolean\", \"date\", \"datetime\", \"time\", \"year\", \"yearmonth\", \"duration\", \"geopoint\"] . For details and examples of each of these types see here . format (of below) : Indicates the format of the type specified in the type property. Each format is dependent on the type specified. For example: If type is \"string\", then see the String formats . If type is \"date\", \"datetime\", or \"time\", default format is ISO8601 formatting for those respective types (see details on ISO8601 format for Date , Datetime , or Time ) - If you want to specify a date-like variable using standard Python/C strptime syntax, see here for details. See here for more information about appropriate format values by variable type . constraints.maxLength (integer) : Indicates the maximum length of an iterable (e.g., array, string, or object). For example, if 'Hello World' is the longest value of a categorical variable, this would be a maxLength of 11. constraints.enum (string) : Constrains possible values to a set of values. If a variable is contrained to a set of values, you may want to consider providing more information about what each value in the set mean using the encodings property for the same variable (e.g. If a variable has possible values of 1, 2, and 3 and these correspond to \"yes\", \"no\" and \"maybe\", you can indicate the constraint of this variable to values of 1, 2, and 3 using the constraints.enum property for that variable, and you can indicate that 1=\"yes\", 2=\"no\", and 3=\"maybe\" using the encodings property for that variable). Examples: 1|2|3|4|5|6|7|8 Treated|Control constraints.pattern (string) : A regular expression pattern the data MUST conform to. constraints.maximum (integer) : Specifies the maximum value of a field (e.g., maximum -- or most recent -- date, maximum integer etc). Note, this is different than maxLength property. constraints.minimum (integer) : Specifies the minimum value of a field. encodings (string) : For variables constrained to a set of values, variable value encodings provide a way to further annotate each value in the constrained set of values the variable can take on, making values easier to understand. If a variable is contrained to a set of values, you may want to consider providing the set of values to which the variable is constrained using the constraints.enum property for that variable, and then providing more information about what each value in the set means using the encodings property for the same variable (e.g. If a variable has possible values of 1, 2, and 3 and these correspond to \"yes\", \"no\" and \"maybe\", you can indicate the constraint of this variable to values of 1, 2, and 3 using the constraints.enum property for that variable, and you can indicate that 1=\"yes\", 2=\"no\", and 3=\"maybe\" using the encodings property for that variable). Examples: 0=No|1=Yes HW=Hello world|GBW=Good bye world|HM=Hi,Mike ordered (boolean) : Indicates whether a categorical variable is ordered. This variable is relevant for variables that have an ordered relationship but not necessarily a numerical relationship (e.g., Strongly disagree < Disagree < Neutral < Agree). If ordered is set as True, order will be set based on ordering of values provided in the constraints.enum property for this variable. missingValues (string) : A list of missing values specific to a variable. Examples: Missing|Skipped|No preference Missing trueValues (string) : For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values. Examples: REQUIRED required|Yes|Y|Checked falseValues (string) : For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values. standardsMappings.url (string) : A url that links out to a published, standardized mapping for the variable. For example, if a variable corresponds to the first question in a published, validated survey instrument to measure depression (e.g. PHQ9), provide a link to the PHQ9 Questionnaire at the NIH Common Data Element Repository. This property is under development, and may be restricted in future to persistent identifier urls such as a DOI . Examples: https://cde.nlm.nih.gov/formView?tinyId=myG8MkTbwg standardsMappings.type (string) : The type of published, standardized mapping available for the variable (e.g. a variable may correspond to a Common Data Element, or CDE, within the NIH Common Data Elements program). This property is under development, and will have a controlled vocabulary. Examples: cde ontology reference_list standardsMappings.label (string) : A free text label that may be used to provide any information available about a published, standardized mapping available for the variable in an unstructured manner (e.g. if a variable corresponds to the first question in the PHQ9 Questionnaire, which is a published, validated survey instrument to measure depression, it may be useful to provide information about th standard that variable reflects using free text such as \"depression, PHQ, PHQ9\"). standardsMappings.source (string) : The source of the published, standardized mapping available for the variable (e.g. the NIH CDE Repository ). This property is under development, and will have a controlled vocabulary. standardsMappings.id (string) : The identifier (ID) of the published, standardized mapping available for the variable within the source provided in the standardsMappings.source property for this variable (e.g. the PHQ9 Questionnaire has been assigned ID \" myG8MkTbwg \" at the NIH CDE Repository CDE source). relatedConcepts.url (string) : The url that links out to the published, standardized concept. Examples: https://meshb.nlm.nih.gov/record/ui?ui=D018410 relatedConcepts.type (string) : The type of mapping to a published set of concepts related to the given field such as ontological information (eg. NCI thesaurus, bioportal etc) relatedConcepts.label (string) : A free text label of mapping to a published set of concepts related to the given field such as ontological information (eg., NCI thesaurus, bioportal etc) relatedConcepts.source (string) : The source of the related concept. This property is under development, and will have a controlled vocabulary. relatedConcepts.id (string) : The id locating the individual mapping within the given source. univarStats.median (number) univarStats.mean (number) univarStats.std (number) univarStats.min (number) univarStats.max (number) univarStats.mode (number) univarStats.count (integer) univarStats.twentyFifthPercentile (number) univarStats.seventyFifthPercentile (number) univarStats.categoricalMarginals.name (string) univarStats.categoricalMarginals.count (integer)","title":"Properties"},{"location":"schemas/md_data_dict/#end-of-schema-extra-infomation","text":"","title":"End of schema - Extra infomation"},{"location":"schemas/md_data_dict/#type-enum-definitions","text":"number (A numeric value with optional decimal places. (e.g., 3.14)) integer (A whole number without decimal places. (e.g., 42)) string (A sequence of characters. (e.g., \\\"test\\\")) any (Any type of data is allowed. (e.g., true)) boolean (A binary value representing true or false. (e.g., true)) date (A specific calendar date. (e.g., \\\"2023-05-25\\\")) datetime (A specific date and time, including timezone information. (e.g., \\\"2023-05-25T10:30:00Z\\\")) time (A specific time of day. (e.g., \\\"10:30:00\\\")) year (A specific year. (e.g., 2023) yearmonth (A specific year and month. (e.g., \\\"2023-05\\\")) duration (A length of time. (e.g., \\\"PT1H\\\") geopoint (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278]))","title":"type enum definitions"},{"location":"schemas/md_data_dict/#format-details-for-date-datetime-time-type-variables","text":"Date Formats (string) A format for a date variable ( date , time , datetime ). Highly recommended to be an ISO8601 format string default : An ISO8601 format string. any : Any parsable representation of a date/time/datetime. The implementing library can attempt to parse the datetime via a range of strategies. **{PATTERN}**: The value can be parsed according to `{PATTERN}`, which `MUST` follow the date formatting syntax of C / Python [strftime](http://strftime.org/) such as: - \"`%Y-%m-%d` (for date, e.g., 2023-05-25)\" - \"`%Y%-%d` (for date, e.g., 20230525) for date without dashes\" - \"`%Y-%m-%dT%H:%M:%S` (for datetime, e.g., 2023-05-25T10:30:45)\" - \"`%Y-%m-%dT%H:%M:%SZ` (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z)\" - \"`%Y-%m-%dT%H:%M:%S%z` (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300)\" - \"`%Y-%m-%dT%H:%M` (for datetime without seconds, e.g., 2023-05-25T10:30)\" - \"`%Y-%m-%dT%H` (for datetime without minutes and seconds, e.g., 2023-05-25T10)\" - \"`%H:%M:%S` (for time, e.g., 10:30:45)\" - \"`%H:%M:%SZ` (for time with UTC timezone, e.g., 10:30:45Z)\" - \"`%H:%M:%S%z` (for time with timezone offset, e.g., 10:30:45+0300)\"","title":"format details for date, datetime, time type variables"},{"location":"schemas/md_experiment_tracker/","text":"HEAL Experiment Tracker \u00b6 HEAL DSC Core Metadata piece to track and provide basic information about experiment(s) you will perform as part of your HEAL study. Clinical studies will often have only one experiment to report, while basic science studies often have several experiments that are grouped together under a single study. Properties \u00b6 experiment.id (string) : id assigned to each experiment relevant to the data package; prefix is 'exp-' followed by a number starting with 1 for the first experiment, and iterating by 1 for each successive experiment (i.e. exp-1, exp-2, etc.). experiment.type (string) : discovery|materials and methods development. Must be one of: [\"discovery\", \"materials and methods development\"] . experiment.description (string) : provide a brief description of the experiment; this is NOT a protocol. experiment.question (array) : what question(s) does the experimentalist hope to address with this experiment? be as specific as possible. Items (string) experiment.hypothesis (array) : for each question the experimentalist hopes to address with this experiment, what does the experimentalist hypothesize will be the result(s) of the experiment? Be as specific as possible. Items (string)","title":"Experiment Tracker"},{"location":"schemas/md_experiment_tracker/#heal-experiment-tracker","text":"HEAL DSC Core Metadata piece to track and provide basic information about experiment(s) you will perform as part of your HEAL study. Clinical studies will often have only one experiment to report, while basic science studies often have several experiments that are grouped together under a single study.","title":"HEAL Experiment Tracker"},{"location":"schemas/md_experiment_tracker/#properties","text":"experiment.id (string) : id assigned to each experiment relevant to the data package; prefix is 'exp-' followed by a number starting with 1 for the first experiment, and iterating by 1 for each successive experiment (i.e. exp-1, exp-2, etc.). experiment.type (string) : discovery|materials and methods development. Must be one of: [\"discovery\", \"materials and methods development\"] . experiment.description (string) : provide a brief description of the experiment; this is NOT a protocol. experiment.question (array) : what question(s) does the experimentalist hope to address with this experiment? be as specific as possible. Items (string) experiment.hypothesis (array) : for each question the experimentalist hopes to address with this experiment, what does the experimentalist hypothesize will be the result(s) of the experiment? Be as specific as possible. Items (string)","title":"Properties"},{"location":"schemas/md_resource_tracker/","text":"HEAL Resource Tracker \u00b6 HEAL DSC Core Metadata piece to track and provide basic information about resource(s)/file(s) that support/are produced by/result from experiments you perform/will perform as part of your HEAL study.Objective is to list at least all files that will be submitted to a data repository in order to describe what each file is, how they relate to each other/how to use them, and how they relate to results/publications shared by the study group. Files may include results files (e.g. publications or draft publications/pieces of publications), processed and raw data files, protocol and analytic plan files, data dictionaries for tabular data files, other metadata as appropriate to data/field type, etc. Properties \u00b6 resource.id (string) : Unique ID assigned to each resource file; If using the DSC Packaging application to annotate your resource(s), these IDs will be auto-assigned when you use the Add DSC Package button above the form to add your DSC Package Directory. Auto-assignment of IDs occurs by searching the directory for any resource annotation files already saved, identifying the resource ID with the highest resource ID number, and adding 1 to that number to get the resource ID number and unique resource ID for the current resource. path (string) : The full file path to your resource file. If you are using the DSC Packaging application and would like to use a single form to annotate multiple 'like' files, click the 'Add Multiple like Files' button above the form and drag and drop all of the like files you want to annotate together in that box. The file path for the first of the file paths you dropped in the box will be added to this field. description (string) : A description of your resource. For resources that consist of multiple 'like' files, provide a description of the multi-file resource here and use the Resource File Description field to provide any description specific to each/any one specific file in the set. category (string) : Broad category your resource falls into; Generally, these categories are: results, data, metadata, code. However, the actual category options parse the categories just a bit finer (e.g. options for data resources include either 'tabular-data' or 'non-tabular-data'). Must be one of: [\"\", \"multi-result\", \"single-result\", \"tabular-data\", \"non-tabular-data\", \"metadata\", \"code\"] . exp.belongs.to (string) : If the file pertains specifically to one of the study experiments, list the experiment ID for that experiment here; If the file pertains to more than one experiment, or to all experiments/the study as a whole, leave this blank; Use the experiment ID as assigned/formatted in your Experiment Tracker file (prefix is 'exp-' followed by a number starting with 1 for the first experiment, and iterating by 1 for each successive experiment - i.e. exp-1, exp-2, etc.). name (string) : File path stem; Auto-inferred from file path. title (string) : Human-readable title/name of resource. description.file.name.convention (string) : For multi-file resource containing multiple files of the same type (multiple 'like' files), provide the naming convention of the files (e.g. for a file set: [subject-01-protocol-A-day-2020-06-05.csv, subject-02-protocol-A-day-2020-06-05.csv, subject-02-protocol-B-day-2020-12-05.csv], you would specify the naming convention as: subject-{subject ID}-protocol-{protocol ID}-day-{date of measurment in YYYY-MM-DD}). If you are using the DSC Packaging application, you can use the Apply Name Convention button above the form to validate your name convention format and use a valid file name convention to generate a minimal 'Resource File Description' that is a minimal description specific to each file in the multi-file resource set. description.file (string) : For a multi-file resource containing multiple files of the same type (multiple 'like' files), a description specific to the specific current file that is a component of that multi-file set. description.row (string) : For a tabular data resource, a description of what one row in the tabular data resource represents; e.g. one row represents one subject at one timepoint. category.sub.metadata (string) : Sub-category for a metadata resource. Must be one of: [\"\", \"heal-formatted-data-dictionary\", \"other-formatted-data-dictionary\", \"protocol\", \"id-map\", \"analysis-plan\", \"heal-formatted-results-tracker\", \"heal-formatted-experiment-tracker\"] . category.sub.data (string) : Sub-category for a data resource. Must be one of: [\"\", \"raw\", \"processed-intermediate\", \"processed-final\"] . category.sub.results (string) : Sub-category for a results resource. Must be one of: [\"\", \"figure\", \"table\", \"text\", \"draft-publication\", \"publication\", \"report\", \"white-paper\", \"presentation\", \"poster\"] . assoc.file.dd (array) : For a tabular data file resources, a reference/file path to associated data dictionary file(s) - preferably in heal csv data dictionary format. Items (string) assoc.file.protocol (array) : For a data file resource, a reference/file path to associated protocol file(s). Items (string) assoc.file.result.tracker (array) : For a multi-result file resource, a reference/file path to associated HEAL results tracker file - HEAL results tracker is a file that tracks each result in a multi-result file (e.g. a publication, poster, etc.), along with the data and other supporting files that underly/support each result. If you are using the DSC Packaging Desktop Application, you can head to the Result Tracker tab of the application to create a HEAL formatted result tracker for your multi-result resource file(s). Items (string) assoc.file.depends.on (array) : For all resource files, if the current resource file has dependencies/if other files are necessary to make this file (e.g. raw data file necessary to make processed data file), or to interpret/understand this file (e.g. protocol, analysis plan, etc.), list them here; if documenting resources wholistically (i.e. documenting all resources related to a study), only list dependencies one layer deep; if documenting resources minimally (i.e. only documenting resources that will be publicly shared), list dependencies liberally; dependencies can be data, code, protocol, etc.; if already listed under assoc.file.dd, assoc.file.protocol, or assoc.file.id.map no need to repeat here. Items (string) assoc.file.result.depends.on (array) : if the current resource file is a heal formatted result tracker (this tracks the single results in a multi-result file, like a publication), use this field to list each result in the tracker along with its corresponding dependencies (i.e. files the result depends on, or are necessary to make/reach/interpret the result); if documenting resources wholistically (i.e. documenting all resources related to a study), only list dependencies one layer deep; if documenting resources minimally (i.e. only documenting resources that will be publicly shared), list dependencies liberally; dependencies can be data, code, protocol, etc. Items (object) result.id (string) result.id.depends.on (array) assoc.file.multi.like.file (array) : if the current resource file is annotating a resource that is one of multiple 'like' files, this field will list all files that are part of the resources. Items (string) access (array) : What is the current/final access level anticipated for this resource? Options are permanent-private (current and final access level is private), temporary-private (current access level is private but final access level will be either restricted-access or public), restricted-access (current, final, or current AND final access level will allow request of data with barriers/restrictions to access), public (current, final, or current AND final access level will allow largely unrestricted request of/access to data); Many investigators will designate data as currently temporary-private, with a final access level of either restricted-access or public: In this case choose both temporary-private AND either 1) restricted-access or 2) public, then add the date at which you expect to transition from temporary-private to either restricted-access or public in the Access Date field below; Private means members of the public cannot request access; Restricted access means they can request access but there is gate-keeping; Public access means they can often access the data without requesting access, and with minimal barriers to access. Items (string) : Must be one of: [\"\", \"permanent-private\", \"temporary-private\", \"restricted-access\", \"public\"] . access.date (string) : If the resource file is currently being held as temporary-private access level and will transition to either restricted-access or public access level at some point, please provide an anticipated date at which this transition will occur - Best guesses are appreciated, however you will NOT be held to this date and may update this date at any time. format (string) : auto inferred; e.g. csv. format.software (string) : If the file format of the resource file is proprietary and requires specific software to open/interpret, provide the software name and version used by the study group to produce/work with the file; e.g. Origin 11.0, CorelDraw 5.6. profile (string) : auto inferred; e.g. tabular-data-resource. mediatype (string) : auto inferred; e.g. text/csv. encoding (string) : auto inferred; e.g. utf-8. schema (string) : auto inferred; for tabular resource, schema of fields contained in tabular resource; might replace this with ref to either heal csv dd or heal json dd. resource.create.date.time (string) : Date time of resource creation; auto-inferred. resource.mod.date.time (string) : Date time at which the resource was last modified; auto-inferred. restrk.create.date.time (string) : Date time at which the resource tracker file for the resource was created; auto-inferred. restrk.mod.date.time (string) : Date time at which the resource tracker file for the resource was last modified; auto-inferred.","title":"Resource Tracker"},{"location":"schemas/md_resource_tracker/#heal-resource-tracker","text":"HEAL DSC Core Metadata piece to track and provide basic information about resource(s)/file(s) that support/are produced by/result from experiments you perform/will perform as part of your HEAL study.Objective is to list at least all files that will be submitted to a data repository in order to describe what each file is, how they relate to each other/how to use them, and how they relate to results/publications shared by the study group. Files may include results files (e.g. publications or draft publications/pieces of publications), processed and raw data files, protocol and analytic plan files, data dictionaries for tabular data files, other metadata as appropriate to data/field type, etc.","title":"HEAL Resource Tracker"},{"location":"schemas/md_resource_tracker/#properties","text":"resource.id (string) : Unique ID assigned to each resource file; If using the DSC Packaging application to annotate your resource(s), these IDs will be auto-assigned when you use the Add DSC Package button above the form to add your DSC Package Directory. Auto-assignment of IDs occurs by searching the directory for any resource annotation files already saved, identifying the resource ID with the highest resource ID number, and adding 1 to that number to get the resource ID number and unique resource ID for the current resource. path (string) : The full file path to your resource file. If you are using the DSC Packaging application and would like to use a single form to annotate multiple 'like' files, click the 'Add Multiple like Files' button above the form and drag and drop all of the like files you want to annotate together in that box. The file path for the first of the file paths you dropped in the box will be added to this field. description (string) : A description of your resource. For resources that consist of multiple 'like' files, provide a description of the multi-file resource here and use the Resource File Description field to provide any description specific to each/any one specific file in the set. category (string) : Broad category your resource falls into; Generally, these categories are: results, data, metadata, code. However, the actual category options parse the categories just a bit finer (e.g. options for data resources include either 'tabular-data' or 'non-tabular-data'). Must be one of: [\"\", \"multi-result\", \"single-result\", \"tabular-data\", \"non-tabular-data\", \"metadata\", \"code\"] . exp.belongs.to (string) : If the file pertains specifically to one of the study experiments, list the experiment ID for that experiment here; If the file pertains to more than one experiment, or to all experiments/the study as a whole, leave this blank; Use the experiment ID as assigned/formatted in your Experiment Tracker file (prefix is 'exp-' followed by a number starting with 1 for the first experiment, and iterating by 1 for each successive experiment - i.e. exp-1, exp-2, etc.). name (string) : File path stem; Auto-inferred from file path. title (string) : Human-readable title/name of resource. description.file.name.convention (string) : For multi-file resource containing multiple files of the same type (multiple 'like' files), provide the naming convention of the files (e.g. for a file set: [subject-01-protocol-A-day-2020-06-05.csv, subject-02-protocol-A-day-2020-06-05.csv, subject-02-protocol-B-day-2020-12-05.csv], you would specify the naming convention as: subject-{subject ID}-protocol-{protocol ID}-day-{date of measurment in YYYY-MM-DD}). If you are using the DSC Packaging application, you can use the Apply Name Convention button above the form to validate your name convention format and use a valid file name convention to generate a minimal 'Resource File Description' that is a minimal description specific to each file in the multi-file resource set. description.file (string) : For a multi-file resource containing multiple files of the same type (multiple 'like' files), a description specific to the specific current file that is a component of that multi-file set. description.row (string) : For a tabular data resource, a description of what one row in the tabular data resource represents; e.g. one row represents one subject at one timepoint. category.sub.metadata (string) : Sub-category for a metadata resource. Must be one of: [\"\", \"heal-formatted-data-dictionary\", \"other-formatted-data-dictionary\", \"protocol\", \"id-map\", \"analysis-plan\", \"heal-formatted-results-tracker\", \"heal-formatted-experiment-tracker\"] . category.sub.data (string) : Sub-category for a data resource. Must be one of: [\"\", \"raw\", \"processed-intermediate\", \"processed-final\"] . category.sub.results (string) : Sub-category for a results resource. Must be one of: [\"\", \"figure\", \"table\", \"text\", \"draft-publication\", \"publication\", \"report\", \"white-paper\", \"presentation\", \"poster\"] . assoc.file.dd (array) : For a tabular data file resources, a reference/file path to associated data dictionary file(s) - preferably in heal csv data dictionary format. Items (string) assoc.file.protocol (array) : For a data file resource, a reference/file path to associated protocol file(s). Items (string) assoc.file.result.tracker (array) : For a multi-result file resource, a reference/file path to associated HEAL results tracker file - HEAL results tracker is a file that tracks each result in a multi-result file (e.g. a publication, poster, etc.), along with the data and other supporting files that underly/support each result. If you are using the DSC Packaging Desktop Application, you can head to the Result Tracker tab of the application to create a HEAL formatted result tracker for your multi-result resource file(s). Items (string) assoc.file.depends.on (array) : For all resource files, if the current resource file has dependencies/if other files are necessary to make this file (e.g. raw data file necessary to make processed data file), or to interpret/understand this file (e.g. protocol, analysis plan, etc.), list them here; if documenting resources wholistically (i.e. documenting all resources related to a study), only list dependencies one layer deep; if documenting resources minimally (i.e. only documenting resources that will be publicly shared), list dependencies liberally; dependencies can be data, code, protocol, etc.; if already listed under assoc.file.dd, assoc.file.protocol, or assoc.file.id.map no need to repeat here. Items (string) assoc.file.result.depends.on (array) : if the current resource file is a heal formatted result tracker (this tracks the single results in a multi-result file, like a publication), use this field to list each result in the tracker along with its corresponding dependencies (i.e. files the result depends on, or are necessary to make/reach/interpret the result); if documenting resources wholistically (i.e. documenting all resources related to a study), only list dependencies one layer deep; if documenting resources minimally (i.e. only documenting resources that will be publicly shared), list dependencies liberally; dependencies can be data, code, protocol, etc. Items (object) result.id (string) result.id.depends.on (array) assoc.file.multi.like.file (array) : if the current resource file is annotating a resource that is one of multiple 'like' files, this field will list all files that are part of the resources. Items (string) access (array) : What is the current/final access level anticipated for this resource? Options are permanent-private (current and final access level is private), temporary-private (current access level is private but final access level will be either restricted-access or public), restricted-access (current, final, or current AND final access level will allow request of data with barriers/restrictions to access), public (current, final, or current AND final access level will allow largely unrestricted request of/access to data); Many investigators will designate data as currently temporary-private, with a final access level of either restricted-access or public: In this case choose both temporary-private AND either 1) restricted-access or 2) public, then add the date at which you expect to transition from temporary-private to either restricted-access or public in the Access Date field below; Private means members of the public cannot request access; Restricted access means they can request access but there is gate-keeping; Public access means they can often access the data without requesting access, and with minimal barriers to access. Items (string) : Must be one of: [\"\", \"permanent-private\", \"temporary-private\", \"restricted-access\", \"public\"] . access.date (string) : If the resource file is currently being held as temporary-private access level and will transition to either restricted-access or public access level at some point, please provide an anticipated date at which this transition will occur - Best guesses are appreciated, however you will NOT be held to this date and may update this date at any time. format (string) : auto inferred; e.g. csv. format.software (string) : If the file format of the resource file is proprietary and requires specific software to open/interpret, provide the software name and version used by the study group to produce/work with the file; e.g. Origin 11.0, CorelDraw 5.6. profile (string) : auto inferred; e.g. tabular-data-resource. mediatype (string) : auto inferred; e.g. text/csv. encoding (string) : auto inferred; e.g. utf-8. schema (string) : auto inferred; for tabular resource, schema of fields contained in tabular resource; might replace this with ref to either heal csv dd or heal json dd. resource.create.date.time (string) : Date time of resource creation; auto-inferred. resource.mod.date.time (string) : Date time at which the resource was last modified; auto-inferred. restrk.create.date.time (string) : Date time at which the resource tracker file for the resource was created; auto-inferred. restrk.mod.date.time (string) : Date time at which the resource tracker file for the resource was last modified; auto-inferred.","title":"Properties"},{"location":"schemas/md_results_tracker/","text":"HEAL Results Tracker \u00b6 HEAL DSC Core Metadata piece to track and provide basic information about results statements or figures in a multi-result file (e.g. a publication) that presents results from your HEAL study. Objective is to list at least all results that have been/will be published in order to describe each result, the data/non-data files each result depends on, and how to use these data/non-data files to reproduce published results. Properties \u00b6 result.id (string) : Unique ID assigned to each result; If using the DSC Packaging application to annotate your resource(s), these IDs will be auto-assigned when you use the Add Result Tracker button above the form to add your Result Tracker Directory. Auto-assignment of IDs occurs by searching the directory for any result annotation files already saved, identifying the result ID with the highest result ID number, and adding 1 to that number to get the result ID number and unique result ID for the current result. description (string) : A description of your result. For figure results this may be the figure caption. For text results, it is recommended that this text be identical or very similar to the text of result as shared in text of the multi-result file that is published or provided as part of the data package. category (string) : Broad category your result falls into; Generally, these categories are: figure, or text. Must be one of: [\"\", \"figure\", \"table\", \"text\"] . assoc.multi.result.file (array) : The multi-result file(s) in which this result has been shared. Items (string) figure.number (array) : If the result is a figure result, provide the number of the figure as it appears in the corresponding multi-result file; Examples include '1' if the result is in figure 1, or '1a' if the result is in figure 1A. If the result is included in more than one multi-result file, use the Associated Multi-Result File(s) field above to specify all multi-result files in which the result appears, and add the figure number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; figure-number-in-file-1, figure-number-in-file-2). Items (string) table.number (array) : If the result is a table result, provide the number of the table as it appears in the corresponding multi-result file; Examples include '1' if the result is in table 1, or '1a' if the result is in table 1A. If the result is included in more than one multi-result file, use the Associated Multi-Result File(s) field above to specify all multi-result files in which the result appears, and add the table number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; table-number-in-file-1, table-number-in-file-2). Items (string) assoc.file.depends.on (array) : Data and/or non-data supporting files the result depends upon (e.g. data, analysis plan/code, etc.). If you are using the DSC Packaging App and have many result dependencies to add, you can use the Add Multiple Result Dependencies button above the form to reveal an interface where you can drag and drop many files at once. If documenting resources wholistically (i.e. documenting all resources related to a study), only list dependencies one layer deep; if documenting resources minimally (i.e. only documenting resources that will be publicly shared), list dependencies liberally; dependencies can be data, code, protocol, etc. Items (string) result.supports (array) : Describe a larger claim(s) that this result is used to support in text that is published or provided as part of the data package. Items (string) restrk.create.date.time (string) : Date time at which the result annotation file for the result was created; auto-inferred. restrk.mod.date.time (string) : Date time at which the result annotation file for the result was last modified; auto-inferred.","title":"Results Tracker"},{"location":"schemas/md_results_tracker/#heal-results-tracker","text":"HEAL DSC Core Metadata piece to track and provide basic information about results statements or figures in a multi-result file (e.g. a publication) that presents results from your HEAL study. Objective is to list at least all results that have been/will be published in order to describe each result, the data/non-data files each result depends on, and how to use these data/non-data files to reproduce published results.","title":"HEAL Results Tracker"},{"location":"schemas/md_results_tracker/#properties","text":"result.id (string) : Unique ID assigned to each result; If using the DSC Packaging application to annotate your resource(s), these IDs will be auto-assigned when you use the Add Result Tracker button above the form to add your Result Tracker Directory. Auto-assignment of IDs occurs by searching the directory for any result annotation files already saved, identifying the result ID with the highest result ID number, and adding 1 to that number to get the result ID number and unique result ID for the current result. description (string) : A description of your result. For figure results this may be the figure caption. For text results, it is recommended that this text be identical or very similar to the text of result as shared in text of the multi-result file that is published or provided as part of the data package. category (string) : Broad category your result falls into; Generally, these categories are: figure, or text. Must be one of: [\"\", \"figure\", \"table\", \"text\"] . assoc.multi.result.file (array) : The multi-result file(s) in which this result has been shared. Items (string) figure.number (array) : If the result is a figure result, provide the number of the figure as it appears in the corresponding multi-result file; Examples include '1' if the result is in figure 1, or '1a' if the result is in figure 1A. If the result is included in more than one multi-result file, use the Associated Multi-Result File(s) field above to specify all multi-result files in which the result appears, and add the figure number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; figure-number-in-file-1, figure-number-in-file-2). Items (string) table.number (array) : If the result is a table result, provide the number of the table as it appears in the corresponding multi-result file; Examples include '1' if the result is in table 1, or '1a' if the result is in table 1A. If the result is included in more than one multi-result file, use the Associated Multi-Result File(s) field above to specify all multi-result files in which the result appears, and add the table number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; table-number-in-file-1, table-number-in-file-2). Items (string) assoc.file.depends.on (array) : Data and/or non-data supporting files the result depends upon (e.g. data, analysis plan/code, etc.). If you are using the DSC Packaging App and have many result dependencies to add, you can use the Add Multiple Result Dependencies button above the form to reveal an interface where you can drag and drop many files at once. If documenting resources wholistically (i.e. documenting all resources related to a study), only list dependencies one layer deep; if documenting resources minimally (i.e. only documenting resources that will be publicly shared), list dependencies liberally; dependencies can be data, code, protocol, etc. Items (string) result.supports (array) : Describe a larger claim(s) that this result is used to support in text that is published or provided as part of the data package. Items (string) restrk.create.date.time (string) : Date time at which the result annotation file for the result was created; auto-inferred. restrk.mod.date.time (string) : Date time at which the result annotation file for the result was last modified; auto-inferred.","title":"Properties"}]}