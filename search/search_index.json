{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HEAL Data Packaging Tool \u00b6 This document walks through the process for creating and completing a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers: About the Tool and the Trackers \u00b6 Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas Downloading and Navigating the Tool \u00b6 Downloading the Tool for Windows and Mac Navigating the Tool","title":""},{"location":"#heal-data-packaging-tool","text":"This document walks through the process for creating and completing a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers:","title":"HEAL Data Packaging Tool"},{"location":"#about-the-tool-and-the-trackers","text":"Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas","title":"About the Tool and the Trackers"},{"location":"#downloading-and-navigating-the-tool","text":"Downloading the Tool for Windows and Mac Navigating the Tool","title":"Downloading and Navigating the Tool"},{"location":"about/","text":"HEAL Data Packaging Tool \u00b6 This document walks through the process for creating and completing a a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers: About the Tool and the Trackers \u00b6 Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas Downloading and Navigating the Tool \u00b6 Downloading the Tool for Windows and Mac Navigating the Tool","title":"HEAL Data Packaging Tool"},{"location":"about/#heal-data-packaging-tool","text":"This document walks through the process for creating and completing a a HEAL-compliant \"data package\" using the HEAL Data Packaging Tool. Find out more about the HEAL Data Packaging Tool and how using it can help ease the process of creating a HEAL-compliant data package that will make your data understandable and usable for future researchers:","title":"HEAL Data Packaging Tool"},{"location":"about/#about-the-tool-and-the-trackers","text":"Purpose of the HEAL Data Packaging Tool Standard Data Package Metadata Schemas","title":"About the Tool and the Trackers"},{"location":"about/#downloading-and-navigating-the-tool","text":"Downloading the Tool for Windows and Mac Navigating the Tool","title":"Downloading and Navigating the Tool"},{"location":"about/nav/","text":"Using the Tool \u00b6 Note When you open the tool, the window (console) below will pop up and begin running. Do not close it. Once it executes, the tool will open. You will need to leave this window open when you are using the tool. Note: The screenshot above shows the Windows console. The Mac console will look slightly different. When the tool loads, it will look like this (Windows): Tabs \u00b6 The tabs within the tool are organized sequentially to walk through the steps of data packaging: Data Package, Experiment Tracker, Resource Tracker, Results Tracker, and Data Dictionary. Within each of these tabs, there are 2-3 sub-tabs. Each has an \"Info\" tab, which provides information on what the app will create within the selected step. Depending on which domain you are viewing, the additional tabs will vary. Each individual tab will provide the necessary forms and guidance to execute the steps for that domain. App Messages and Guidance \u00b6 Working Data Package Directory \u00b6 The Working Data Package Directory will always be displayed at the top of the tool's main window. Each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session. User Status Message Box \u00b6 Within each tab, there is a User Status Message Box: The User Status Message Box will print out messages when you make certain selections or save changes to files (e.g., adding a result to a Results Tracker). The box will provide information on the status of changes and any errors that may occur. It will also provide helpful tips on next steps. This is another tool meant to help you through the process, so we advise you to review the messages and use the tips provided. Guide to Text Colors \u00b6 Color Form Fields User Status Message Box Blue Required, but can be filled in by an automatic process Information on next steps Green Required Successful process message Black Not required, but useful to include Process message Red N/A Error message","title":"Navigating the Tool"},{"location":"about/nav/#using-the-tool","text":"Note When you open the tool, the window (console) below will pop up and begin running. Do not close it. Once it executes, the tool will open. You will need to leave this window open when you are using the tool. Note: The screenshot above shows the Windows console. The Mac console will look slightly different. When the tool loads, it will look like this (Windows):","title":"Using the Tool"},{"location":"about/nav/#tabs","text":"The tabs within the tool are organized sequentially to walk through the steps of data packaging: Data Package, Experiment Tracker, Resource Tracker, Results Tracker, and Data Dictionary. Within each of these tabs, there are 2-3 sub-tabs. Each has an \"Info\" tab, which provides information on what the app will create within the selected step. Depending on which domain you are viewing, the additional tabs will vary. Each individual tab will provide the necessary forms and guidance to execute the steps for that domain.","title":"Tabs"},{"location":"about/nav/#app-messages-and-guidance","text":"","title":"App Messages and Guidance"},{"location":"about/nav/#working-data-package-directory","text":"The Working Data Package Directory will always be displayed at the top of the tool's main window. Each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session.","title":"Working Data Package Directory"},{"location":"about/nav/#user-status-message-box","text":"Within each tab, there is a User Status Message Box: The User Status Message Box will print out messages when you make certain selections or save changes to files (e.g., adding a result to a Results Tracker). The box will provide information on the status of changes and any errors that may occur. It will also provide helpful tips on next steps. This is another tool meant to help you through the process, so we advise you to review the messages and use the tips provided.","title":"User Status Message Box"},{"location":"about/nav/#guide-to-text-colors","text":"Color Form Fields User Status Message Box Blue Required, but can be filled in by an automatic process Information on next steps Green Required Successful process message Black Not required, but useful to include Process message Red N/A Error message","title":"Guide to Text Colors"},{"location":"about/purpose/","text":"Purpose of the HEAL Data Packaging Tool \u00b6 Compiling and accurately documenting the aspects of your study's data and supporting documents in a way that will be understandable and usable for future researchers can be a difficult task. This tool was developed to help ease the burden of understanding and effectively fulfilling HEAL data sharing requirements. This tool provides you with easy-to-fill-out forms and step-by-step guidance that will help you to document and annotate your study's experiments, results, and resources to maximize your study's findability and replicability by future researchers. When you fill out these forms, the tool will package up the information into different trackers, which you will then deposit into the repository you choose, along with your other data package components, as supporting documentation. The tool and the resulting trackers will provide systematic annotation of your data package. For more information on the data packaging process, such as how to prepare your data and supporting documents before starting your package and how to determine your annotation approach, refer to the HEAL data packaging guidance documentation .","title":"Purpose"},{"location":"about/purpose/#purpose-of-the-heal-data-packaging-tool","text":"Compiling and accurately documenting the aspects of your study's data and supporting documents in a way that will be understandable and usable for future researchers can be a difficult task. This tool was developed to help ease the burden of understanding and effectively fulfilling HEAL data sharing requirements. This tool provides you with easy-to-fill-out forms and step-by-step guidance that will help you to document and annotate your study's experiments, results, and resources to maximize your study's findability and replicability by future researchers. When you fill out these forms, the tool will package up the information into different trackers, which you will then deposit into the repository you choose, along with your other data package components, as supporting documentation. The tool and the resulting trackers will provide systematic annotation of your data package. For more information on the data packaging process, such as how to prepare your data and supporting documents before starting your package and how to determine your annotation approach, refer to the HEAL data packaging guidance documentation .","title":"Purpose of the HEAL Data Packaging Tool"},{"location":"about/trackers/","text":"The Trackers \u00b6 The tool builds three different trackers that provide a standardized way to supply supporting annotation (metadata) in conjunction with your shared data: an experiment tracker, a resource tracker, and a results tracker. Information on the purpose and general content of each tracker is in the table below. Tracker Purpose Content Experiment Tracker Provides contextual information on the experiments involved in the project Details each experiment, including research questions, approach, and hypotheses Resource Tracker Provides inventory and annotated information for all data and supporting files List of data and non-data/supporting files, including description, path, and dependencies Results Tracker Provides detailed information on all results and their association with publications List of each result, including type and description; there should be one results tracker per multi-result file The Data Packaging tool will provide you with easy-to-understand forms that feed into these trackers. You will not need to complete them manually within the tracker. For more information on the fields within each tracker, please refer to the metadata schemas .","title":"The Trackers"},{"location":"about/trackers/#the-trackers","text":"The tool builds three different trackers that provide a standardized way to supply supporting annotation (metadata) in conjunction with your shared data: an experiment tracker, a resource tracker, and a results tracker. Information on the purpose and general content of each tracker is in the table below. Tracker Purpose Content Experiment Tracker Provides contextual information on the experiments involved in the project Details each experiment, including research questions, approach, and hypotheses Resource Tracker Provides inventory and annotated information for all data and supporting files List of data and non-data/supporting files, including description, path, and dependencies Results Tracker Provides detailed information on all results and their association with publications List of each result, including type and description; there should be one results tracker per multi-result file The Data Packaging tool will provide you with easy-to-understand forms that feed into these trackers. You will not need to complete them manually within the tracker. For more information on the fields within each tracker, please refer to the metadata schemas .","title":"The Trackers"},{"location":"about/download/start-mac/","text":"Downloading the Desktop Application Tool for Mac \u00b6 What to Do First DO NOT delete your dsc-pkg folder or contents: If you have already used the tool to create/initialize your data package (i.e. created your dsc-pkg folder within your study folder), DO NOT delete your dsc-pkg folder or any of its contents (i.e. standard data package metadata files such as experiment, resource, and results trackers and data dictionaries) Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-mac.zip\" to download the tool. The folder should automatically unzip to Downloads. Right click on the dsc-pkg-tool icon. Warning If you double click on the dsc-pkg-tool icon, you will receive a warning that the tool \"cannot be opened because it is from an unidentified developer.\" You can bypass this error by opening via right-click. You will receive a pop-up asking you to confirm that you want to open. Select \"Open.\" The tool should open:","title":"Mac"},{"location":"about/download/start-mac/#downloading-the-desktop-application-tool-for-mac","text":"What to Do First DO NOT delete your dsc-pkg folder or contents: If you have already used the tool to create/initialize your data package (i.e. created your dsc-pkg folder within your study folder), DO NOT delete your dsc-pkg folder or any of its contents (i.e. standard data package metadata files such as experiment, resource, and results trackers and data dictionaries) Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-mac.zip\" to download the tool. The folder should automatically unzip to Downloads. Right click on the dsc-pkg-tool icon. Warning If you double click on the dsc-pkg-tool icon, you will receive a warning that the tool \"cannot be opened because it is from an unidentified developer.\" You can bypass this error by opening via right-click. You will receive a pop-up asking you to confirm that you want to open. Select \"Open.\" The tool should open:","title":"Downloading the Desktop Application Tool for Mac"},{"location":"about/download/start-win/","text":"Downloading the Desktop Application Tool for Windows \u00b6 What to Do First Delete previous version(s) of the tool: If you have downloaded a previous version of the tool, delete the previous version of the tool (dsc-pkg-tool) prior to downloading and unzipping the current version of the tool, as you will be unable to save two files with the same name within the same folder. DO NOT delete your dsc-pkg folder or contents: If you have already used the tool to create/initialize your data package (i.e. created your dsc-pkg folder within your study folder), DO NOT delete your dsc-pkg folder or any of its contents (i.e. standard data package metadata files such as experiment, resource, and results trackers and data dictionaries) Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-windows.zip\" to download the tool. Unzip the files. You can unzip the files to your downloads folder or to another folder that you prefer. Tip If you did not delete your previous version of the dsc_pkg_tool before unzipping to the same folder, you can overwrite the old version of the tool with this new version by selecting \"Replace the file in the destination folder\" in the pop-up window. Once you have unzipped the files, the dsc_pkg_tool file will appear. Double-click the file to open the tool.","title":"Windows"},{"location":"about/download/start-win/#downloading-the-desktop-application-tool-for-windows","text":"What to Do First Delete previous version(s) of the tool: If you have downloaded a previous version of the tool, delete the previous version of the tool (dsc-pkg-tool) prior to downloading and unzipping the current version of the tool, as you will be unable to save two files with the same name within the same folder. DO NOT delete your dsc-pkg folder or contents: If you have already used the tool to create/initialize your data package (i.e. created your dsc-pkg folder within your study folder), DO NOT delete your dsc-pkg folder or any of its contents (i.e. standard data package metadata files such as experiment, resource, and results trackers and data dictionaries) Navigate to the latest release for the tool . Expand \"Assets\" and select \"dsc-pkg-tool-windows.zip\" to download the tool. Unzip the files. You can unzip the files to your downloads folder or to another folder that you prefer. Tip If you did not delete your previous version of the dsc_pkg_tool before unzipping to the same folder, you can overwrite the old version of the tool with this new version by selecting \"Replace the file in the destination folder\" in the pop-up window. Once you have unzipped the files, the dsc_pkg_tool file will appear. Double-click the file to open the tool.","title":"Downloading the Desktop Application Tool for Windows"},{"location":"datadict/","text":"About the Data Dictionary Tab \u00b6 This tab creates HEAL-compliant data dictionaries, which provide metadata, including variable labels and values, for tabular or tabular-like data files in your data package. You should create a data dictionary for each tabular or tabular-like data file you collect/share as part of your study. The HEAL data dictionary converter can take data files and data dictionary files as inputs. Data files accepted include CSV files, Excel files with multiple tabs, SPSS .sav files, Stata .dta files, SAS .sas7bdat files. Data dictionary files accepted include REDCap CSV data dictionary files and minimal CSV data dictionary files. Before attempting to convert your tabular data file into a HEAL-compliant data dictionary, you may have to complete a few specific steps based on the file type (e.g., for REDCap data dictionaries, you must download from REDCap in the correct format). In order to ensure your input file is in the correct format, review the instructions here . Tips and Best Practices for Data Dictionaries We recommend that you save all of your HEAL-compliant data dictionaries in the same folder. The tool will automatically do this for you. Any data dictionary you create with the tool will be output into your dsc-pkg folder. You should apply a consistent naming convention to your data dictionaries. The tool will do this for you. Any data dictionary you create will be output with the same file name with \"heal-csv-dd\" appended at the beginning.","title":"About the Data Dictionary Tab"},{"location":"datadict/#about-the-data-dictionary-tab","text":"This tab creates HEAL-compliant data dictionaries, which provide metadata, including variable labels and values, for tabular or tabular-like data files in your data package. You should create a data dictionary for each tabular or tabular-like data file you collect/share as part of your study. The HEAL data dictionary converter can take data files and data dictionary files as inputs. Data files accepted include CSV files, Excel files with multiple tabs, SPSS .sav files, Stata .dta files, SAS .sas7bdat files. Data dictionary files accepted include REDCap CSV data dictionary files and minimal CSV data dictionary files. Before attempting to convert your tabular data file into a HEAL-compliant data dictionary, you may have to complete a few specific steps based on the file type (e.g., for REDCap data dictionaries, you must download from REDCap in the correct format). In order to ensure your input file is in the correct format, review the instructions here . Tips and Best Practices for Data Dictionaries We recommend that you save all of your HEAL-compliant data dictionaries in the same folder. The tool will automatically do this for you. Any data dictionary you create with the tool will be output into your dsc-pkg folder. You should apply a consistent naming convention to your data dictionaries. The tool will do this for you. Any data dictionary you create will be output with the same file name with \"heal-csv-dd\" appended at the beginning.","title":"About the Data Dictionary Tab"},{"location":"datadict/create/","text":"Create a New Data Dictionary \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to create a data dictionary. If you have not set your working data package directory before attempting to use the data dictionary converter, the tool will not be able to save your output data dictionary to your data package folder. You will receive the error message below. Creating a new data dictionary \u00b6 When you would like to create a new data dictionary, go to the \"Create\" tab. You will be able to start either with a data file or a data dictionary file, if you have one. Special considerations for certain files To ensure that your files are able to be read into the tool and converted correctly, certain file types may require some additional considerations/preparation. Multi-tab Excel files SAS files Minimal CSV Data Dictionaries REDCap Data Dictionaries Select the data dictionary conversion that you would like to complete and select the corresponding file in File Explorer. If the conversion is successful, then the User Status Message Box will print a successful message: Some input file types contain more metadata than others, so depending on the input file, you may need to take additional steps to ensure you have a valid HEAL-compliant data dictionary. Ensuring that you have a valid HEAL data dictionary \u00b6 Once you have output your data dictionary, you may have to take additional steps, depending on your original input file type, to ensure that your data dictionary is \"valid.\" A valid HEAL-compliant data dictionary will contain at least a name and description for each variable. If you started with an input file that was rich in metadata, this metadata will be extracted by the tool. You can expect that the data dictionary output by the tool will be fairly complete and likely will be valid. Metadata-rich files include SPSS and Stata files, and SAS files (if a sas7bcat file is included). Similarly, if you input a REDCap CSV data dictionary, your output HEAL CSV data dictionary should be fairly complete and valid. Example of the data dictionary output based on a metadata-rich file: If you started with a CSV or Excel file, however, the output data dictionary will be a \"minimal data dictionary.\" Unlike metadata-rich files (SPSS, Stata, SAS), which contain information about variable names, labels, and encodings within the file, CSV and Excel files do not contain this metadata. Therefore, the output data dictionary will contain the variable names and types, but not descriptions. The tool will also attempt to infer whether variables are categorical, and if so, what those categories are. However, if there are categories not included in the data, those will not be able to be inferred and included. Example of the data dictionary output based on a CSV or Excel file: If you start with a non-metatadata-rich file, you will need to edit your data dictionary after it has been output. For the data dictionary to be considered valid, each variable must have a name and description. You may also want to add in additional constraints that the tool did not infer such as variable encodings. For more information on the additional columns within the HEAL-compliant data dictionary output by the tool as well as guidance on which fields may be most useful to prioritize filling out, refer to the Data Dictionary metadata schema . Special considerations for specific file types \u00b6 Certain data files and data dictionaries may require additional steps and preparation. See below for information on these specific circumstances for certain data files. Excel Data File with multiple tabs SAS File Minimal CSV Data Dictionary REDCap Data Dictionary Excel Data File with multiple tabs \u00b6 In order for the tool to successfully produce a data dictionary from an Excel file with multiple tabs, each tab within that Excel must first be a clean dataset that follows a standard tabular format: the top row should list all variables across the columns and the columns should contain the data. Once you have a clean dataset in each tab, there are two options for output for Excel data files with multiple tabs. Excel Data File >> HEAL CSV Data Dictionary (one per tab) This will take a multi-tab Excel file and output one data dictionary for each tab in the Excel. The naming convention of the file will be 'heal-csv-dd-filename-tabname.' Each data dictionary will include a row for every variable within that specific tab. Excel Data File >> HEAL CSV Data Dictionary (one across tabs) This will take a multi-tab Excel file and output a single data dictionary with structure 'heal-csv-dd-filename.' This single data dictionary will include a row for every variable across all tabs. If you use this method, it is important that you ensure that variable names across sheets are consistent. This works particularly well if your data is structured such that the same variables are used across sheets. However, if you are using the same variable name in multiple different sheets, but it does not have the same meaning in each sheet, you should either vary the name of variables across sheets or you should use the one per tab option. SAS File \u00b6 For tabular files saved in SAS (sas7bdat), you will want to have an accompanying catalog file (sas7bcat). Although the sas7bdat contains variable metadata information (variable names and variable labels/descriptions), the sas7bcat contains information about the formats and encoding of the variables, which are important for producing a complete data dictionary. Creating a sas7bdat and sas7bcat file \u00b6 Many SAS users build formats and labels into their data processing and analysis scripts. In this section, we provide syntax that can be easily copy-pasted into these existing workflows to create sas7bdat and sas7bcat files to input into the vlmd tool. This script template can be run separately or inserted directly at the end of a SAS user's workflow. Note If inserted directly, remember to delete the lines with %INCLUDE ) Template template.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SECOND SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file. If you already have an out directory assigned, skip this step and replace \u201cout\u201d with your out directory libname in the flow*/ libname out \"<INSERT THE DESIRED LOCATION (FILE PATH) TO YOUR SAS7BCAT AND SAS7BDAT FILES HERE>\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) */ data out . yourdata; set < INSERT THE NAME OF YOUR FINAL SAS DATASET HERE> ; run; The below SAS syntax is an example of how to use the template within your SAS workflow. The below sample script creates all of our variable and value labels. Your workflow may include multiple SAS scripts with multiple format statements and may include analyses and other PROC calls for data exploration, but for demonstration purposes, this example only uses one script and focuses on defining the variable and value labels. Example my_existing_sas_workflow.sas /*1. Read in input data */ proc import datafile= \"myprojectfolder/input/mydata.csv\" out =raw dbms=csv replace ; getnames=yes ; run; /*2. Set up proc format and apply formats and variable labels in data step */ /*Create encodings (value labels)*/ proc format; VALUE YESNO 0 = \"No\" 1 = \"Yes\" VALUE PUBLIC 1 = 'State mental health authority (SMHA)' 2 = 'Other state government agency or department' 3 = 'Regional/district authority or county, local, or municipal government' 4 = 'Tribal government' 5 = 'Indian Health Service' 6 = 'Department of Veterans Affairs' 7 = 'Other' VALUE FOCUS 1 = 'Mental health treatment' 2 = 'Substance abuse treatment' 3 = 'Mix of mental health and substance abuse treatment (neither is primary)' 4 = 'General health care' 5 = 'Other service focus' ; **Apply formats to dataset; data processed; set raw; /*Assign formats*/ format YOUNGADULTS TREATPSYCHOTHRPY TREATTRAUMATHRPY YESNO. FOCUS FOCUS. PUBLIC PUBLIC.; /*Add variable labels*/ label YOUNGADULTS= \"Accepts young adults (aged 18-25 years old) for Tx\" TREATPSYCHOTHRPY= \"Facility offers individual psychotherapy\" TREATTRAUMATHRPY= \"Facility offers trauma therapy\" FOCUS= \"Primary treatment focus of facility\" PUBLIC= \"Public agency or department that operates facility\" ; run; This second script called my_output.sas is the filled out template. Note the %INCLUDE function that calls my_existing_sas_workflow.sas my_output.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ */ %INCLUDE \"myprojectfolder/my_existing_workflow.sas\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file.*/ libname out \"myprojectfolder/output\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) to your output folder*/ data out . yourdata; set processed ; run; Running through the tool \u00b6 After creating the necessary sas7bdat and sas7bcat files, you are ready to convert to a HEAL-compliant data dictionary using the data packaging tool. Before you begin, ensure that your sas7bdat and sas7bcat files are saved in the same folder. The tool will only ask you to select your sas7bdat file. If the sas7bcat file is located in the same directory, the tool will automatically detect it, as well. If not detected, the tool will run without the sas7bcat catalog file and the encodings (i.e., value labels) will not be extracted from the catalog file and will not appear in your data dictionary. The output will be a minimal HEAL-compliant data dictionary. Minimal CSV Data Dictionary \u00b6 If you have already created a data dictionary in CSV format, you can also use that to generate a HEAL-compliant data dictionary. The only requirements for a \"minimal CSV data dictionary\" to be ingested by the tool and converted into a HEAL-compliant data dictionary are two columns: name and description. With these two columns included, the data dictionary output will be a valid data dictionary (although it will be a fairly minimal data dictionary). However, this does not mean that you must only include these two columns. You may already have additional columns in your existing data dictionary, or you may want to add columns beyond name and description to better describe your dataset. For information on which additional columns it may be most helpful to include within your minimal data dictionary, and how to create, label, and format them to be successfully ingested and output by the data dictionary converter tool, refer to the HEAL Data Dictionary metadata schema . REDCap Data Dictionary \u00b6 If you collected data in a REDCap data management system, HEAL-compliant data dictionaries can be generated directly from an exported REDCap data dictionary. The REDCap data dictionary export serves the purpose of providing variable-level metadata in a standardized, tabular format and is generally easy to export. Export your REDCap data dictionary \u00b6 To download a REDCap CSV export, do the following*: After logging in to your REDCap project page, locate the Data dictionary page. A link to this page may be available on the project side bar (see image below) or in the Project Setup tab at the top of your page. After arriving at the Data dictionary page, click on Download the current data dictionary to export the dictionary (see below). *there may be slight differences depending on your specific REDCap instance and version","title":"Create a Data Dictionary"},{"location":"datadict/create/#create-a-new-data-dictionary","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to create a data dictionary. If you have not set your working data package directory before attempting to use the data dictionary converter, the tool will not be able to save your output data dictionary to your data package folder. You will receive the error message below.","title":"Create a New Data Dictionary"},{"location":"datadict/create/#creating-a-new-data-dictionary","text":"When you would like to create a new data dictionary, go to the \"Create\" tab. You will be able to start either with a data file or a data dictionary file, if you have one. Special considerations for certain files To ensure that your files are able to be read into the tool and converted correctly, certain file types may require some additional considerations/preparation. Multi-tab Excel files SAS files Minimal CSV Data Dictionaries REDCap Data Dictionaries Select the data dictionary conversion that you would like to complete and select the corresponding file in File Explorer. If the conversion is successful, then the User Status Message Box will print a successful message: Some input file types contain more metadata than others, so depending on the input file, you may need to take additional steps to ensure you have a valid HEAL-compliant data dictionary.","title":"Creating a new data dictionary"},{"location":"datadict/create/#ensuring-that-you-have-a-valid-heal-data-dictionary","text":"Once you have output your data dictionary, you may have to take additional steps, depending on your original input file type, to ensure that your data dictionary is \"valid.\" A valid HEAL-compliant data dictionary will contain at least a name and description for each variable. If you started with an input file that was rich in metadata, this metadata will be extracted by the tool. You can expect that the data dictionary output by the tool will be fairly complete and likely will be valid. Metadata-rich files include SPSS and Stata files, and SAS files (if a sas7bcat file is included). Similarly, if you input a REDCap CSV data dictionary, your output HEAL CSV data dictionary should be fairly complete and valid. Example of the data dictionary output based on a metadata-rich file: If you started with a CSV or Excel file, however, the output data dictionary will be a \"minimal data dictionary.\" Unlike metadata-rich files (SPSS, Stata, SAS), which contain information about variable names, labels, and encodings within the file, CSV and Excel files do not contain this metadata. Therefore, the output data dictionary will contain the variable names and types, but not descriptions. The tool will also attempt to infer whether variables are categorical, and if so, what those categories are. However, if there are categories not included in the data, those will not be able to be inferred and included. Example of the data dictionary output based on a CSV or Excel file: If you start with a non-metatadata-rich file, you will need to edit your data dictionary after it has been output. For the data dictionary to be considered valid, each variable must have a name and description. You may also want to add in additional constraints that the tool did not infer such as variable encodings. For more information on the additional columns within the HEAL-compliant data dictionary output by the tool as well as guidance on which fields may be most useful to prioritize filling out, refer to the Data Dictionary metadata schema .","title":"Ensuring that you have a valid HEAL data dictionary"},{"location":"datadict/create/#special-considerations-for-specific-file-types","text":"Certain data files and data dictionaries may require additional steps and preparation. See below for information on these specific circumstances for certain data files. Excel Data File with multiple tabs SAS File Minimal CSV Data Dictionary REDCap Data Dictionary","title":"Special considerations for specific file types"},{"location":"datadict/create/#excel-data-file-with-multiple-tabs","text":"In order for the tool to successfully produce a data dictionary from an Excel file with multiple tabs, each tab within that Excel must first be a clean dataset that follows a standard tabular format: the top row should list all variables across the columns and the columns should contain the data. Once you have a clean dataset in each tab, there are two options for output for Excel data files with multiple tabs. Excel Data File >> HEAL CSV Data Dictionary (one per tab) This will take a multi-tab Excel file and output one data dictionary for each tab in the Excel. The naming convention of the file will be 'heal-csv-dd-filename-tabname.' Each data dictionary will include a row for every variable within that specific tab. Excel Data File >> HEAL CSV Data Dictionary (one across tabs) This will take a multi-tab Excel file and output a single data dictionary with structure 'heal-csv-dd-filename.' This single data dictionary will include a row for every variable across all tabs. If you use this method, it is important that you ensure that variable names across sheets are consistent. This works particularly well if your data is structured such that the same variables are used across sheets. However, if you are using the same variable name in multiple different sheets, but it does not have the same meaning in each sheet, you should either vary the name of variables across sheets or you should use the one per tab option.","title":"Excel Data File with multiple tabs"},{"location":"datadict/create/#sas-file","text":"For tabular files saved in SAS (sas7bdat), you will want to have an accompanying catalog file (sas7bcat). Although the sas7bdat contains variable metadata information (variable names and variable labels/descriptions), the sas7bcat contains information about the formats and encoding of the variables, which are important for producing a complete data dictionary.","title":"SAS File"},{"location":"datadict/create/#creating-a-sas7bdat-and-sas7bcat-file","text":"Many SAS users build formats and labels into their data processing and analysis scripts. In this section, we provide syntax that can be easily copy-pasted into these existing workflows to create sas7bdat and sas7bcat files to input into the vlmd tool. This script template can be run separately or inserted directly at the end of a SAS user's workflow. Note If inserted directly, remember to delete the lines with %INCLUDE ) Template template.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ %INCLUDE \"<INSERT SAS SCRIPT HERE FILE PATH HERE>\" ; /* THIS WILL RUN A SECOND SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file. If you already have an out directory assigned, skip this step and replace \u201cout\u201d with your out directory libname in the flow*/ libname out \"<INSERT THE DESIRED LOCATION (FILE PATH) TO YOUR SAS7BCAT AND SAS7BDAT FILES HERE>\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) */ data out . yourdata; set < INSERT THE NAME OF YOUR FINAL SAS DATASET HERE> ; run; The below SAS syntax is an example of how to use the template within your SAS workflow. The below sample script creates all of our variable and value labels. Your workflow may include multiple SAS scripts with multiple format statements and may include analyses and other PROC calls for data exploration, but for demonstration purposes, this example only uses one script and focuses on defining the variable and value labels. Example my_existing_sas_workflow.sas /*1. Read in input data */ proc import datafile= \"myprojectfolder/input/mydata.csv\" out =raw dbms=csv replace ; getnames=yes ; run; /*2. Set up proc format and apply formats and variable labels in data step */ /*Create encodings (value labels)*/ proc format; VALUE YESNO 0 = \"No\" 1 = \"Yes\" VALUE PUBLIC 1 = 'State mental health authority (SMHA)' 2 = 'Other state government agency or department' 3 = 'Regional/district authority or county, local, or municipal government' 4 = 'Tribal government' 5 = 'Indian Health Service' 6 = 'Department of Veterans Affairs' 7 = 'Other' VALUE FOCUS 1 = 'Mental health treatment' 2 = 'Substance abuse treatment' 3 = 'Mix of mental health and substance abuse treatment (neither is primary)' 4 = 'General health care' 5 = 'Other service focus' ; **Apply formats to dataset; data processed; set raw; /*Assign formats*/ format YOUNGADULTS TREATPSYCHOTHRPY TREATTRAUMATHRPY YESNO. FOCUS FOCUS. PUBLIC PUBLIC.; /*Add variable labels*/ label YOUNGADULTS= \"Accepts young adults (aged 18-25 years old) for Tx\" TREATPSYCHOTHRPY= \"Facility offers individual psychotherapy\" TREATTRAUMATHRPY= \"Facility offers trauma therapy\" FOCUS= \"Primary treatment focus of facility\" PUBLIC= \"Public agency or department that operates facility\" ; run; This second script called my_output.sas is the filled out template. Note the %INCLUDE function that calls my_existing_sas_workflow.sas my_output.sas /*1. Read in data file without value labels and run full code. Note: The most important pieces to run here are the PROC FORMAT statement(s) and any data steps that assign formats and variable labels which are needed for the data dictionary. You may have defined variable labels and values in separate scripts for different analyses. In order to capture all your defined variable labels and values across scripts, you will need an %INCLUDE statement for each SAS script that defines unique variable labels or value labels.*/ */ %INCLUDE \"myprojectfolder/my_existing_workflow.sas\" ; /* THIS WILL RUN A SEPARATE SAS SCRIPT*/ /*2. Output the format catalog (sas7bcat) */ /*2a. If you do not have an out directory, assign one to output the SAS catalog and data file.*/ libname out \"myprojectfolder/output\" ; /*2b. Output the format catalog. Note: The format catalog is automatically stored in work.formats. This step copies the format file to the out directory as a sas7bcat file.*/ proc catalog cat=work . FORMATS; copy out = out . FORMATS ; run; /*3. Output the data file (sas7bdat) to your output folder*/ data out . yourdata; set processed ; run;","title":"Creating a sas7bdat and sas7bcat file"},{"location":"datadict/create/#running-through-the-tool","text":"After creating the necessary sas7bdat and sas7bcat files, you are ready to convert to a HEAL-compliant data dictionary using the data packaging tool. Before you begin, ensure that your sas7bdat and sas7bcat files are saved in the same folder. The tool will only ask you to select your sas7bdat file. If the sas7bcat file is located in the same directory, the tool will automatically detect it, as well. If not detected, the tool will run without the sas7bcat catalog file and the encodings (i.e., value labels) will not be extracted from the catalog file and will not appear in your data dictionary. The output will be a minimal HEAL-compliant data dictionary.","title":"Running through the tool"},{"location":"datadict/create/#minimal-csv-data-dictionary","text":"If you have already created a data dictionary in CSV format, you can also use that to generate a HEAL-compliant data dictionary. The only requirements for a \"minimal CSV data dictionary\" to be ingested by the tool and converted into a HEAL-compliant data dictionary are two columns: name and description. With these two columns included, the data dictionary output will be a valid data dictionary (although it will be a fairly minimal data dictionary). However, this does not mean that you must only include these two columns. You may already have additional columns in your existing data dictionary, or you may want to add columns beyond name and description to better describe your dataset. For information on which additional columns it may be most helpful to include within your minimal data dictionary, and how to create, label, and format them to be successfully ingested and output by the data dictionary converter tool, refer to the HEAL Data Dictionary metadata schema .","title":"Minimal CSV Data Dictionary"},{"location":"datadict/create/#redcap-data-dictionary","text":"If you collected data in a REDCap data management system, HEAL-compliant data dictionaries can be generated directly from an exported REDCap data dictionary. The REDCap data dictionary export serves the purpose of providing variable-level metadata in a standardized, tabular format and is generally easy to export.","title":"REDCap Data Dictionary"},{"location":"datadict/create/#export-your-redcap-data-dictionary","text":"To download a REDCap CSV export, do the following*: After logging in to your REDCap project page, locate the Data dictionary page. A link to this page may be available on the project side bar (see image below) or in the Project Setup tab at the top of your page. After arriving at the Data dictionary page, click on Download the current data dictionary to export the dictionary (see below). *there may be slight differences depending on your specific REDCap instance and version","title":"Export your REDCap data dictionary"},{"location":"datadict/validate/","text":"Validate a Data Dictionary \u00b6 You can use the Data Dictionary Validation tool to confirm that your data dictionary is HEAL-compliant. You may want to do this if you have made edits to a data dictionary that was produced by the tool or if you have another data dictionary that you believe could be considered HEAL-compliant. Before using the validation feature, you may want to review your data dictionary to confirm that you think it is likely HEAL-compliant. Please refer to the Data Dictionary schema for information on what makes a data dictionary HEAL compliant. Select Validate HEAL CSV Data Dictionary. Navigate to and select the data dictionary you would like to validate. The User Status Message Box will print out a message with some information about the validation attempt. If the data dictionary is HEAL-compliant, the user status message box will print out a confirmation message. If the data dictionary is not HEAL compliant, the user status message box will print out information about what part of the validation failed. For more information about what needs to be changed/added to make your data dictionary HEAL-compliant, refer to the Data Dictionary schema . In the below example, the data dictionary is missing descriptions for the variables. Description is a required field, so the validation fails. Once you have a validated, HEAL-compliant data dictionary, this step is complete. If you make any edits to the data dictionary after validating, you should run the validation again to confirm that it is still compliant.","title":"Validate a Data Dictionary"},{"location":"datadict/validate/#validate-a-data-dictionary","text":"You can use the Data Dictionary Validation tool to confirm that your data dictionary is HEAL-compliant. You may want to do this if you have made edits to a data dictionary that was produced by the tool or if you have another data dictionary that you believe could be considered HEAL-compliant. Before using the validation feature, you may want to review your data dictionary to confirm that you think it is likely HEAL-compliant. Please refer to the Data Dictionary schema for information on what makes a data dictionary HEAL compliant. Select Validate HEAL CSV Data Dictionary. Navigate to and select the data dictionary you would like to validate. The User Status Message Box will print out a message with some information about the validation attempt. If the data dictionary is HEAL-compliant, the user status message box will print out a confirmation message. If the data dictionary is not HEAL compliant, the user status message box will print out information about what part of the validation failed. For more information about what needs to be changed/added to make your data dictionary HEAL-compliant, refer to the Data Dictionary schema . In the below example, the data dictionary is missing descriptions for the variables. Description is a required field, so the validation fails. Once you have a validated, HEAL-compliant data dictionary, this step is complete. If you make any edits to the data dictionary after validating, you should run the validation again to confirm that it is still compliant.","title":"Validate a Data Dictionary"},{"location":"datadict/view/","text":"Viewing or Editing a Data Dictionary \u00b6 If you would like to view or edit any of your existing HEAL-compliant Data Dictionaries, you can use the \"View/Edit\" feature. This feature may be especially useful if you have input a non-metadata-rich file type into the data dictionary tool (e.g., CSV, Excel) and would like to manually add some additional information to the output data dictionary beyond name and description, such as encodings, constraints, and formats. This tool is meant to allow you to more easily edit your data dictionary. However, you can also make edits directly in the CSV within Excel or another spreadsheet program. If you do make edits directly within the CSV, be sure to re-save it as a CSV each time you make edits. Navigate to \"View/Edit\" on the Data Dictionary tab. Select \"View/Edit CSV.\" The window below will pop up. Select \"Load CSV.\" Navigate to your working data package directory (you will not automatically be taken to your working data package directory) and select the HEAL-compliant data dictionary you would like to view or edit. Your data dictionary will populate in the window. You will be able to make edits here. When you have finished making edits, be sure to select \"Save CSV\" before closing the window.","title":"View/Edit a Data Dictionary"},{"location":"datadict/view/#viewing-or-editing-a-data-dictionary","text":"If you would like to view or edit any of your existing HEAL-compliant Data Dictionaries, you can use the \"View/Edit\" feature. This feature may be especially useful if you have input a non-metadata-rich file type into the data dictionary tool (e.g., CSV, Excel) and would like to manually add some additional information to the output data dictionary beyond name and description, such as encodings, constraints, and formats. This tool is meant to allow you to more easily edit your data dictionary. However, you can also make edits directly in the CSV within Excel or another spreadsheet program. If you do make edits directly within the CSV, be sure to re-save it as a CSV each time you make edits. Navigate to \"View/Edit\" on the Data Dictionary tab. Select \"View/Edit CSV.\" The window below will pop up. Select \"Load CSV.\" Navigate to your working data package directory (you will not automatically be taken to your working data package directory) and select the HEAL-compliant data dictionary you would like to view or edit. Your data dictionary will populate in the window. You will be able to make edits here. When you have finished making edits, be sure to select \"Save CSV\" before closing the window.","title":"Viewing or Editing a Data Dictionary"},{"location":"datadir/","text":"Creating or Continuing A Data Package \u00b6 The Data Package tab will always be the first place you visit when you open the data packaging tool. The Data Package directory is where all of your data packaging documentation will live, including your study\u2019s experiment tracker, resource tracker, results trackers, and data dictionaries. The first time you open the data packaging tool, you will need to create a Data Package directory . After you have created your Data Package directory, you will not need to do so again. However, each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session. Once you have created or set your working data package directory, throughout your session, the window at the top of the tool will display your working data package directory.","title":"The Data Package Tab"},{"location":"datadir/#creating-or-continuing-a-data-package","text":"The Data Package tab will always be the first place you visit when you open the data packaging tool. The Data Package directory is where all of your data packaging documentation will live, including your study\u2019s experiment tracker, resource tracker, results trackers, and data dictionaries. The first time you open the data packaging tool, you will need to create a Data Package directory . After you have created your Data Package directory, you will not need to do so again. However, each time you open the data packaging tool, you will first need to set your working data package directory (e.g., provide the path to your existing data package directory). This will enable the tool to interface with the data package folder during your session. Once you have created or set your working data package directory, throughout your session, the window at the top of the tool will display your working data package directory.","title":"Creating or Continuing A Data Package"},{"location":"datadir/pkgdir/","text":"Creating a Data Package Directory \u00b6 Click on the \"Data Package\" tab. Within the \"Create\" tab, select \"Create New Data Package.\" Select the location where you want to save the Data Package directory in the File Explorer pop up window. Once you select a location, the folder \"dsc-pkg\" will appear within that folder. The tool will also display the new folder location in the user status message box and set the dsc-pkg folder you have just created as your working data package directory for the current session: Your new dsc-pkg directory will contain an empty Experiment Tracker and Resource Tracker. The following steps will guide you through how to use the tool to fill out the Experiment Tracker, Resource Tracker, and Results Tracker (the last of which will be created as you move through the process of entering results information).","title":"Create a New Data Package"},{"location":"datadir/pkgdir/#creating-a-data-package-directory","text":"Click on the \"Data Package\" tab. Within the \"Create\" tab, select \"Create New Data Package.\" Select the location where you want to save the Data Package directory in the File Explorer pop up window. Once you select a location, the folder \"dsc-pkg\" will appear within that folder. The tool will also display the new folder location in the user status message box and set the dsc-pkg folder you have just created as your working data package directory for the current session: Your new dsc-pkg directory will contain an empty Experiment Tracker and Resource Tracker. The following steps will guide you through how to use the tool to fill out the Experiment Tracker, Resource Tracker, and Results Tracker (the last of which will be created as you move through the process of entering results information).","title":"Creating a Data Package Directory"},{"location":"datadir/setdir/","text":"Setting Your Working Data Package Directory \u00b6 Although you will only need to create your data package once, you will need to set your data package working directory each time you open the tool. This will allow the tool to interface with your data packaging folder and its contents. To set your working data package directory: Navigate to the \"Create or Continue Data Package\" and select \"Continue Existing Data Package.\" Navigate to the data packaging directory on which you would like to work and select the folder. Once you select the directory, the tool will review the files within your dsc-pkg folder and confirm that they are up to date with the most recent version of the tool. If your dsc-pkg folder is up to date with the most recent version of the tool: The User Status Message Box will print out a result that your working data package directly has been set. It will also print a confirmation that the dsc-pkg files are up to date. The file path to your working data package directory will also appear in the box at the top of the tool. This path will remain at the top of the tool throughout your session. If your dsc-pkg folder is not up to date with the most recent version of the tool: The User Status Message Box will print out a warning that some files in your data package directory are not up to date. You will need to update the dsc-pkg directory using the [Audit and Update] feature.","title":"Set Your Working Data Package Directory"},{"location":"datadir/setdir/#setting-your-working-data-package-directory","text":"Although you will only need to create your data package once, you will need to set your data package working directory each time you open the tool. This will allow the tool to interface with your data packaging folder and its contents. To set your working data package directory: Navigate to the \"Create or Continue Data Package\" and select \"Continue Existing Data Package.\" Navigate to the data packaging directory on which you would like to work and select the folder. Once you select the directory, the tool will review the files within your dsc-pkg folder and confirm that they are up to date with the most recent version of the tool. If your dsc-pkg folder is up to date with the most recent version of the tool: The User Status Message Box will print out a result that your working data package directly has been set. It will also print a confirmation that the dsc-pkg files are up to date. The file path to your working data package directory will also appear in the box at the top of the tool. This path will remain at the top of the tool throughout your session. If your dsc-pkg folder is not up to date with the most recent version of the tool: The User Status Message Box will print out a warning that some files in your data package directory are not up to date. You will need to update the dsc-pkg directory using the [Audit and Update] feature.","title":"Setting Your Working Data Package Directory"},{"location":"datadir/update/","text":"Auditing and Updating A Data Package Directory \u00b6 If you try to \"Continue an Existing Data Package\" and the files within your data package are not up to date with the current version of the tool, you will receive a warning message to update your files before proceeding. To update your data package, navigate to \"Audit and Update\" tab and select \"Update Package Versions.\" Depending on the size of the data package you are updating, this may take a few minutes. First, the tool will audit the current files within your data package and determine which need to be updated. Next, the tool will update the necessary files and print out confirmation of the update in the user status message box, as well as information on any files that were unable to be updated. After updating your data package, your newly updated data package will have the same name as your original data package. The original version of the data package directory will be saved with an archive label. The user status message box will print a confirmation of this.","title":"Audit and Update Your Data Package Directory"},{"location":"datadir/update/#auditing-and-updating-a-data-package-directory","text":"If you try to \"Continue an Existing Data Package\" and the files within your data package are not up to date with the current version of the tool, you will receive a warning message to update your files before proceeding. To update your data package, navigate to \"Audit and Update\" tab and select \"Update Package Versions.\" Depending on the size of the data package you are updating, this may take a few minutes. First, the tool will audit the current files within your data package and determine which need to be updated. Next, the tool will update the necessary files and print out confirmation of the update in the user status message box, as well as information on any files that were unable to be updated. After updating your data package, your newly updated data package will have the same name as your original data package. The original version of the data package directory will be saved with an archive label. The user status message box will print a confirmation of this.","title":"Auditing and Updating A Data Package Directory"},{"location":"exptrack/","text":"About the Experiment Tracker \u00b6 This tab fills out the Experiment Tracker, which provides context on the experiments involved in the project including research questions, hypotheses, and approach. You may only have one experiment, in which case you only need to go through the process of annotating and saving your experiment to the Experiment Tracker once. However, if you have multiple experiments in your study, you will need to annotate and save each experiment to the tracker separately. You will only have one Experiment Tracker for your study, with one entry per experiment. The Experiment Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder. Example of an Experiment Tracker with one experiment entered:","title":"About the Experiment Tracker"},{"location":"exptrack/#about-the-experiment-tracker","text":"This tab fills out the Experiment Tracker, which provides context on the experiments involved in the project including research questions, hypotheses, and approach. You may only have one experiment, in which case you only need to go through the process of annotating and saving your experiment to the Experiment Tracker once. However, if you have multiple experiments in your study, you will need to annotate and save each experiment to the tracker separately. You will only have one Experiment Tracker for your study, with one entry per experiment. The Experiment Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder. Example of an Experiment Tracker with one experiment entered:","title":"About the Experiment Tracker"},{"location":"exptrack/addexp/","text":"Adding a New Experiment \u00b6 Getting Started \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate an experiment, the tool cannot automatically generate your experiment-ID or connect your experiment to your data package folder. You will receive the error message below. Navigate to the \"Add Experiment\" tab and select \"Add a new experiment\". The tool will generate your experiment ID automatically and sequentially, based on what is already in your working data package directory. Filling Out the Form \u00b6 Tip For additional information about each form field, please refer to the Experiment Tracker schema . Experiment name : This field can act as a more descriptive shorthand name for the experiment in addition to the experiment ID. This field is optional. You may not want to use it if, for example, your study only has one experiment. The experiment name should follow the format of default-experiment-name, with words separated by a \"-\". Although not required, filling in the experiment name may help your internal team, as well as external investigators, to quickly understand the purpose and content of the experiment without having to read through the description, questions, and hypotheses. If you do not follow the required format, you will receive an error: Your experiment name must also be unique. When you enter an experiment name, the tool will review your other annotated experiments to confirm that the experiment name you have assigned is unique. If your experiment name is unique, the User Status Message Box will print a confirmation: Experiment Question(s) and Experiment Hypothesis(es) To add an experiment question/hypothesis, click on the paper icon. You can add multiple experimental questions and hypotheses for the same experiment. To add another, click on the paper icon again. When you have multiple questions/hypotheses entered, you can also change the order using the highlighted arrows. You can also use the 'X' to remove questions/hypotheses entered. Saving Your Experiment \u00b6 Once you have finished entering the experiment information, select \"Save experiment.\" Warning Make sure that you do not have your Experiment Tracker open before trying to save. If you attempt to save an experiment but have the Experiment Tracker open, the annotated experiment file will not save. You will receive this error: To save your experiment, you will need to close the Experiment Tracker and then press \"save experiment\" again. If the experiment is saved successfully, the User Status Message Box will display this message to indicate your experiment saved successfully and that the experiment has been written to the Experiment Tracker file: Although the tool will automatically add your experiment to the Experiment Tracker as part of the \"save\" process, your individual experiment annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated experiment There is an error in automatically adding the experiment to the Experiment Tracker, which would necessitate manually batch adding experiments to the tracker After you have added a new experiment, you can annotate a new experiment. If you would like to annotate a new experiment, you can select \"Clear form\" at the top of the Annotate Experiment window. This will reset your form and generate the next sequential experiment ID, so you can start annotating. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated.","title":"Add a New Experiment"},{"location":"exptrack/addexp/#adding-a-new-experiment","text":"","title":"Adding a New Experiment"},{"location":"exptrack/addexp/#getting-started","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate an experiment, the tool cannot automatically generate your experiment-ID or connect your experiment to your data package folder. You will receive the error message below. Navigate to the \"Add Experiment\" tab and select \"Add a new experiment\". The tool will generate your experiment ID automatically and sequentially, based on what is already in your working data package directory.","title":"Getting Started"},{"location":"exptrack/addexp/#filling-out-the-form","text":"Tip For additional information about each form field, please refer to the Experiment Tracker schema . Experiment name : This field can act as a more descriptive shorthand name for the experiment in addition to the experiment ID. This field is optional. You may not want to use it if, for example, your study only has one experiment. The experiment name should follow the format of default-experiment-name, with words separated by a \"-\". Although not required, filling in the experiment name may help your internal team, as well as external investigators, to quickly understand the purpose and content of the experiment without having to read through the description, questions, and hypotheses. If you do not follow the required format, you will receive an error: Your experiment name must also be unique. When you enter an experiment name, the tool will review your other annotated experiments to confirm that the experiment name you have assigned is unique. If your experiment name is unique, the User Status Message Box will print a confirmation: Experiment Question(s) and Experiment Hypothesis(es) To add an experiment question/hypothesis, click on the paper icon. You can add multiple experimental questions and hypotheses for the same experiment. To add another, click on the paper icon again. When you have multiple questions/hypotheses entered, you can also change the order using the highlighted arrows. You can also use the 'X' to remove questions/hypotheses entered.","title":"Filling Out the Form"},{"location":"exptrack/addexp/#saving-your-experiment","text":"Once you have finished entering the experiment information, select \"Save experiment.\" Warning Make sure that you do not have your Experiment Tracker open before trying to save. If you attempt to save an experiment but have the Experiment Tracker open, the annotated experiment file will not save. You will receive this error: To save your experiment, you will need to close the Experiment Tracker and then press \"save experiment\" again. If the experiment is saved successfully, the User Status Message Box will display this message to indicate your experiment saved successfully and that the experiment has been written to the Experiment Tracker file: Although the tool will automatically add your experiment to the Experiment Tracker as part of the \"save\" process, your individual experiment annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated experiment There is an error in automatically adding the experiment to the Experiment Tracker, which would necessitate manually batch adding experiments to the tracker After you have added a new experiment, you can annotate a new experiment. If you would like to annotate a new experiment, you can select \"Clear form\" at the top of the Annotate Experiment window. This will reset your form and generate the next sequential experiment ID, so you can start annotating. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated.","title":"Saving Your Experiment"},{"location":"exptrack/batchexp/","text":"Advanced \u00b6 Add a New Experiment Based on an Existing Experiment \u00b6 If you need to annotate an experiment that is very similar to a previously annotated experiment, with only slight changes, you may want to use the \"Add a new experiment based on existing experiment\" option. With this feature, you will select a previously annotated experiment, and tool will copy the information from the chosen experiment into a new experiment form with a unique experiment-ID. You will then only need to edit the information rather than reproduce it. Select \"Add a new experiment based on an existing experiment.\" Your working data package folder will open automatically. Select the experiment on which you want to base your new experiment annotation. The annotate experiment form will open and populate with the selected experiment information with a unique ID. Edit the form to reflect the differences in this new experiment. Save the form. Batch Add Experiment(s) to Tracker \u00b6 This feature allows you to manually add existing annotated experiments to the Experiment Tracker. You should not generally need to use this feature, but it is included to account for the possibility that an error in the saving process could cause your annotated experiment to be saved as a .txt file but not automatically added to the Experiment Tracker. In this case, you will be able to use the \"Batch add existing experiment(s) to tracker\" option to add these experiment(s) to the appropriate tracker. Ensure that your Experiment Tracker is closed before attempting to batch add experiments. Navigate to the \"Add Experiment\" tab and select \"Batch add existing experiment(s) to tracker\" under \"Advanced.\" Select the experiments that you want to add. It may be easiest to select all existing annotated experiment files when using this feature. The tool will scan the experiment files you select and only add those that are not already included in the Experiment Tracker. Note: These files follow the naming convention \"exp-trk-exp-\" If your files are successfully added to the Experiment Tracker, the User Status Message Box will provide a confirmation message:","title":"Advanced - Batch Add Experiments to the Tracker"},{"location":"exptrack/batchexp/#advanced","text":"","title":"Advanced"},{"location":"exptrack/batchexp/#add-a-new-experiment-based-on-an-existing-experiment","text":"If you need to annotate an experiment that is very similar to a previously annotated experiment, with only slight changes, you may want to use the \"Add a new experiment based on existing experiment\" option. With this feature, you will select a previously annotated experiment, and tool will copy the information from the chosen experiment into a new experiment form with a unique experiment-ID. You will then only need to edit the information rather than reproduce it. Select \"Add a new experiment based on an existing experiment.\" Your working data package folder will open automatically. Select the experiment on which you want to base your new experiment annotation. The annotate experiment form will open and populate with the selected experiment information with a unique ID. Edit the form to reflect the differences in this new experiment. Save the form.","title":"Add a New Experiment Based on an Existing Experiment"},{"location":"exptrack/batchexp/#batch-add-experiments-to-tracker","text":"This feature allows you to manually add existing annotated experiments to the Experiment Tracker. You should not generally need to use this feature, but it is included to account for the possibility that an error in the saving process could cause your annotated experiment to be saved as a .txt file but not automatically added to the Experiment Tracker. In this case, you will be able to use the \"Batch add existing experiment(s) to tracker\" option to add these experiment(s) to the appropriate tracker. Ensure that your Experiment Tracker is closed before attempting to batch add experiments. Navigate to the \"Add Experiment\" tab and select \"Batch add existing experiment(s) to tracker\" under \"Advanced.\" Select the experiments that you want to add. It may be easiest to select all existing annotated experiment files when using this feature. The tool will scan the experiment files you select and only add those that are not already included in the Experiment Tracker. Note: These files follow the naming convention \"exp-trk-exp-\" If your files are successfully added to the Experiment Tracker, the User Status Message Box will provide a confirmation message:","title":"Batch Add Experiment(s) to Tracker"},{"location":"exptrack/editexp/","text":"Editing an Experiment \u00b6 If you want to edit an experiment annotation after you have created it, you can do so in the tool using the \"Edit an existing experiment\" feature. Info We encourage you to use the form to edit your experiments rather than entering/editing information manually into the Experiment Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit an existing experiment\" in the \"Add Experiment\" tab. Navigate to your dsc-pkg folder and select the annotated experiment .txt file that you want to edit. For example: The information on your annotated experiment will populate in the \"Annotate Experiment\" window. Make any necessary edits to your experiment file, and then select \"Save experiment.\" When you save your edited experiment, the tool will archive the original version of your experiment annotation (.txt) file in an \"archive\" folder, so there are no issues with duplicate file naming.","title":"Edit an Existing Experiment"},{"location":"exptrack/editexp/#editing-an-experiment","text":"If you want to edit an experiment annotation after you have created it, you can do so in the tool using the \"Edit an existing experiment\" feature. Info We encourage you to use the form to edit your experiments rather than entering/editing information manually into the Experiment Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit an existing experiment\" in the \"Add Experiment\" tab. Navigate to your dsc-pkg folder and select the annotated experiment .txt file that you want to edit. For example: The information on your annotated experiment will populate in the \"Annotate Experiment\" window. Make any necessary edits to your experiment file, and then select \"Save experiment.\" When you save your edited experiment, the tool will archive the original version of your experiment annotation (.txt) file in an \"archive\" folder, so there are no issues with duplicate file naming.","title":"Editing an Experiment"},{"location":"exptrack/exptotrack/","text":"Adding an Experiment to the Experiment Tracker \u00b6 After adding a new experiment, you will need to add it to your study's Experiment Tracker. Close the \"Annotate a new experiment\" window and select \"Add experiment to tracker\" in the \"Add Experiment\" tab. When the File Explorer window pops up, navigate to the dsc-pkg folder and select the text file you want to add to the tracker. For the first experiment added, the file name will be \"exp-trk-exp-1\". Your experiment will be written to the experiment tracker. The User Status Message Box will print a confirmation: Navigate to your dsc-pkg folder in your File Explorer and open your Experiment Tracker file. Confirm your experiment appears in the tracker. This step is not required, but it is recommended you check the tracker output after adding your first experiment to ensure the output looks correct. Viewing the Tracker If you want to review your Experiment Tracker at any point, you can view the current tracker within the tool to identify whether there are errors or changes to be made.","title":"Adding an Experiment to the Experiment Tracker"},{"location":"exptrack/exptotrack/#adding-an-experiment-to-the-experiment-tracker","text":"After adding a new experiment, you will need to add it to your study's Experiment Tracker. Close the \"Annotate a new experiment\" window and select \"Add experiment to tracker\" in the \"Add Experiment\" tab. When the File Explorer window pops up, navigate to the dsc-pkg folder and select the text file you want to add to the tracker. For the first experiment added, the file name will be \"exp-trk-exp-1\". Your experiment will be written to the experiment tracker. The User Status Message Box will print a confirmation: Navigate to your dsc-pkg folder in your File Explorer and open your Experiment Tracker file. Confirm your experiment appears in the tracker. This step is not required, but it is recommended you check the tracker output after adding your first experiment to ensure the output looks correct. Viewing the Tracker If you want to review your Experiment Tracker at any point, you can view the current tracker within the tool to identify whether there are errors or changes to be made.","title":"Adding an Experiment to the Experiment Tracker"},{"location":"exptrack/viewexp/","text":"Viewing the Experiment Tracker \u00b6 If you need to view anything that you have already input into the Experiment Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Experiment Tracker within the application to: Review which experiments you have already annotated and determining which you still need to annotate. Find/confirm the experiment ID for a particular experiment to include in resource annotation or to determine edits that need to be made when there has been a change. Navigate to \"View Tracker\" on the Experiment Tracker tab. Select \"View Experiment Tracker.\" The window below will pop up. Select \"Load Experiment Tracker.\" Your experiment tracker will populate in the window.","title":"View the Experiment Tracker"},{"location":"exptrack/viewexp/#viewing-the-experiment-tracker","text":"If you need to view anything that you have already input into the Experiment Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Experiment Tracker within the application to: Review which experiments you have already annotated and determining which you still need to annotate. Find/confirm the experiment ID for a particular experiment to include in resource annotation or to determine edits that need to be made when there has been a change. Navigate to \"View Tracker\" on the Experiment Tracker tab. Select \"View Experiment Tracker.\" The window below will pop up. Select \"Load Experiment Tracker.\" Your experiment tracker will populate in the window.","title":"Viewing the Experiment Tracker"},{"location":"resotrack/","text":"About the Resource Tracker \u00b6 This tab fills out the Resource Tracker, which provides an annotated inventory of all resources involved in the study. The depth and extent of information included in the Resource Tracker will be determined by how you want to share data and how you want to annotate the data you share. For help in making these decisions, refer to the HEAL data packaging guidance documentation . This guidance will provide information on how you should fill out each tracker based on your chosen annotation approach. You will only have one Resource Tracker for your study, with one entry per data or non-data/supporting file. The Resource Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder.","title":"About the Resource Tracker"},{"location":"resotrack/#about-the-resource-tracker","text":"This tab fills out the Resource Tracker, which provides an annotated inventory of all resources involved in the study. The depth and extent of information included in the Resource Tracker will be determined by how you want to share data and how you want to annotate the data you share. For help in making these decisions, refer to the HEAL data packaging guidance documentation . This guidance will provide information on how you should fill out each tracker based on your chosen annotation approach. You will only have one Resource Tracker for your study, with one entry per data or non-data/supporting file. The Resource Tracker shell that you will fill in was created and saved when you created your dsc-pkg folder.","title":"About the Resource Tracker"},{"location":"resotrack/addresource/","text":"Adding a New Resource \u00b6 Getting Started \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a resource, the tool cannot automatically generate your resource-ID or connect your resource to your data package folder. You will receive the error message below. Navigate to the \"Add Resource\" tab and select \"Add a new resource.\" The tool will look through your set working data package directory to determine whether there are existing annotated resource files saved in the folder and will automatically generate the next sequential Resource ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this: Filling Out the Form Fields \u00b6 Tip For additional information about each form field, please refer to the Resource Tracker schema Hovering over each field in the form will provide additional information about what should be contained in the field. For example, for the Resource Title field: Fill out the Resource File Path and Resource Description . Select a Resource Category . Based on the Resource Category selected, additional fields will appear within the form. Resource Categories (and Sub-Categories) \u00b6 Below is a table of all the resource category and sub-category options for your reference. The table also contains information on which fields will appear when you choose a specific category or sub-category. Resource Category Sub-category Additional Resource Annotation Fields for Category Publication Peer-review manuscript Report White paper Presentation Poster Publication Resource - Sub-Category Associated Results Tracker : provides the path to the Results Tracker associated with this multi-result file; Note that the Associated Files/Dependencies field will no longer appear. Result Multi-panel figure Single-panel figure Table Text Result Resource - Sub-Category Tabular-data Raw data Processed intermediate data Processed final data Resource Row Description : explanation of what one row within the tabular file represents Data Resource - Sub-Category Associated Data Dictionary : file path for the data dictionary associated with the tabular file (should not be put in the Associated Files/Dependencies field) Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Non-tabular-data Raw data Processed intermediate data Processed final data Data Resource - Sub-Category Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Metadata HEAL-formatted data dictionary Other formatted data dictionary Protocol Analysis plan HEAL-formatted results tracker Other Metadata Resource - Sub-Category Note that if you select heal-formatted-results-tracker as the sub-category, the \"Associated Files/Dependencies field will no longer appear. Code No sub-categories No additional Resource Tracker fields Experiment Resource 'Belongs' To \u00b6 This option allows you to associate your resources directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu. To use this option, you will need to enter experiment names when you are documenting your experiments in the Experiment Tracker . If you do not yet have experiments documented with names, you can still annotate your resource. You can just come back and use the edit feature to edit your resource annotation to associate that resource with an experiment later. Associated Files/Dependencies \u00b6 This is where you will list dependencies associated with the resource. How you record dependencies will depend on your annotation approach. For more information about how to decide on your annotation approach, refer to the HEAL data packaging guidance documentation . Regardless of your annotation approach, there are two ways to add \"Associated Files/Dependencies\" in the form. Warning You should only utilize one of the below methods for entering dependencies for a specific resource. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Resource Dependencies\" option, those files may overwrite the files you entered manually. Manually adding Associated Files/Dependencies If you are adding only a few associated files/dependencies, you can add each individually using the \"Associated Files/Dependencies\" arrow button: Batch adding Associated Files/Dependencies If you would like to add many associated files at once, you can use the \"Add Multiple Resource Dependencies\" option, which can be found at the top of the window: Fill in this field with associated files/dependencies using drag and drop. The files you add via drag and drop will automatically appear in the \"Associated Files/Dependencies\" section of the form. Access \u00b6 This specifies the level of access that you will apply to this resource (permanent private, temporary private, restricted access, or public). If you select \"temporary-private,\" you will need to complete two additional fields to specify: 1) the level of access for the resource after the temporary private period and 2) the timepoint of the end of the temporary private period (Access Date). First, add an additional row and select the designated level of access of the resource once the temporary private period ends. Fill in the \"Access Date\" when the temporary private period will end. This can just be a projection; you are not bound by this date. For other access levels, you will not need to complete these additional steps. Software used to produce/read the resource file \u00b6 If specific or proprietary software is required to open or read the resource, you should fill this out. This field is not required. If no special/proprietary software was used to produce/read the resource file, leave this field blank. Resource Note \u00b6 This field should be used for any additional notes that are not already covered in the other fields of the Resource Tracker but that would be important for someone viewing or re-using a resource. Adding Multiple \"Like\" Files \u00b6 If you have multiple \"like\" files with a similar naming convention, you may want to add and annotate them all at once rather than individually. The tool has a special feature that you can utilize to annotate multiple \"like\" files all at once. What are \"like\" files? \u00b6 Examples of \"like\" files may be multiple datasets where each is a run of the same set of experiments or experimental results where each dataset corresponds to one subject's data. \"Like\" files will also have the same file extension. To use this feature in the tool, \"like\" files should follow a common naming convention: For example, multiple data files by subject ID grouped in folders by week would be \"like\" files. The naming convention here is week-#/subject-# Another example: for an experiment testing samples on multiple different dates, files could follow the naming convention sample_1_date_20230818, sample_2_date_20230818, etc. If you have \"like\" files, but they don't follow a common naming convention, you may want to re-name the files (applying a common naming convention) before using this feature. If you have determined that you have a set of 'like' resources that you would like to annotate all at once, follow the steps below. How to add multiple \"like\" files \u00b6 Select \"Add Multiple 'like' Resources\" Drag and drop all \"like\" files you want to annotate together. The first of those files paths will appear in the \"Resource File Path\" field in the form. If your \"like\" files are in \"like\" folders (as in the above example of week-#/subject-# structure), you can drag the folders into the box, and the tool will unpack them for you. Once you add your \"like\" files, a box will pop up asking you to add a naming convention. Enter a naming convention for your like files in the \"Resource File Name Convention\" box shown below: Follow the instructions in the dialog box above as to how to create a naming convention. Specifically, make sure that you use the {} brackets to bound the number, date, or descriptive information that changes from one like file to another. You will specify your naming convention slightly differently depending on whether the common naming convention it is integrated within the directory structure (e.g., multiple data files by subject ID grouped in folders by week) or within the filename (e.g., multiple data files within the same directory that only differ by filename). If your naming convention is within the directory structure : Copy the file path from the Resource File Path field and paste into the Resource File Name Convention box: Change the piece that changes from one like file to another to a descriptive name within {}. Do not remove the file extension from the path (e.g., .txt, .csv, .xlsx). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. You have retained the file extension in the path. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended: If your naming convention is fully contained within the file name : You should only include the file name in the \"Resource File Name Convention\" field (rather than the file path). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended. Saving Your Resource \u00b6 Once you have finished entering the resource information, select \"Save resource.\" Warning Make sure you do not have your Resource Tracker open before trying to save. If you attempt to save a resource but have the Resource Tracker open, the annotated resource file will not save. You will receive this error: To save your resource, you will need to close the Resource Tracker and then press \"save resource\" again. After you select \"Save resource,\" the User Status Message Box should display a message confirming that your resource file saved successfully and that the resource has been written to the Resource Tracker file: This message will also include a note about all the files you listed as associated files/dependencies for your resource. Each of these dependencies will also need to be documented as a resource. To make this process easier, these files will automatically be pulled into a resource list, which you can access via the \"Check Resources to Add\" tab. You will be able to use the \"Check Resources to Add\" tab to directly select and document specific resources from the list. Although the tool will automatically add your resource to the Resource Tracker as part of the \"save\" process, your individual resource annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) directly unless: You need to edit an existing annotated resource There was an error in automatically adding the resource to the Resource Tracker, which would necessitate manually batch adding resources to the tracker Next Steps \u00b6 After you have saved your resource, you can annotate a new resource. If you would like to annotate a new resource, you can select \"Clear form\" at the top of the Annotate Resource window. This will reset your form and generate the next sequential resource ID, so you can start annotating a new resource. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated. Tip If you need to annotate a new resource that is very similar to a previously annotated resource with only some slight changes, you can also use the advanced option \"Add a new resource based on an existing resource.\" This will allow you to copy the information from a previously annotated resource into a new resource, for ease of annotation.","title":"Add a New Resource"},{"location":"resotrack/addresource/#adding-a-new-resource","text":"","title":"Adding a New Resource"},{"location":"resotrack/addresource/#getting-started","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a resource, the tool cannot automatically generate your resource-ID or connect your resource to your data package folder. You will receive the error message below. Navigate to the \"Add Resource\" tab and select \"Add a new resource.\" The tool will look through your set working data package directory to determine whether there are existing annotated resource files saved in the folder and will automatically generate the next sequential Resource ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this:","title":"Getting Started"},{"location":"resotrack/addresource/#filling-out-the-form-fields","text":"Tip For additional information about each form field, please refer to the Resource Tracker schema Hovering over each field in the form will provide additional information about what should be contained in the field. For example, for the Resource Title field: Fill out the Resource File Path and Resource Description . Select a Resource Category . Based on the Resource Category selected, additional fields will appear within the form.","title":"Filling Out the Form Fields"},{"location":"resotrack/addresource/#resource-categories-and-sub-categories","text":"Below is a table of all the resource category and sub-category options for your reference. The table also contains information on which fields will appear when you choose a specific category or sub-category. Resource Category Sub-category Additional Resource Annotation Fields for Category Publication Peer-review manuscript Report White paper Presentation Poster Publication Resource - Sub-Category Associated Results Tracker : provides the path to the Results Tracker associated with this multi-result file; Note that the Associated Files/Dependencies field will no longer appear. Result Multi-panel figure Single-panel figure Table Text Result Resource - Sub-Category Tabular-data Raw data Processed intermediate data Processed final data Resource Row Description : explanation of what one row within the tabular file represents Data Resource - Sub-Category Associated Data Dictionary : file path for the data dictionary associated with the tabular file (should not be put in the Associated Files/Dependencies field) Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Non-tabular-data Raw data Processed intermediate data Processed final data Data Resource - Sub-Category Associated Protocol : file path for the protocol associated with the tabular file (should not be put in the Associated Files/Dependencies field) Metadata HEAL-formatted data dictionary Other formatted data dictionary Protocol Analysis plan HEAL-formatted results tracker Other Metadata Resource - Sub-Category Note that if you select heal-formatted-results-tracker as the sub-category, the \"Associated Files/Dependencies field will no longer appear. Code No sub-categories No additional Resource Tracker fields","title":"Resource Categories (and Sub-Categories)"},{"location":"resotrack/addresource/#experiment-resource-belongs-to","text":"This option allows you to associate your resources directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu. To use this option, you will need to enter experiment names when you are documenting your experiments in the Experiment Tracker . If you do not yet have experiments documented with names, you can still annotate your resource. You can just come back and use the edit feature to edit your resource annotation to associate that resource with an experiment later.","title":"Experiment Resource 'Belongs' To"},{"location":"resotrack/addresource/#associated-filesdependencies","text":"This is where you will list dependencies associated with the resource. How you record dependencies will depend on your annotation approach. For more information about how to decide on your annotation approach, refer to the HEAL data packaging guidance documentation . Regardless of your annotation approach, there are two ways to add \"Associated Files/Dependencies\" in the form. Warning You should only utilize one of the below methods for entering dependencies for a specific resource. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Resource Dependencies\" option, those files may overwrite the files you entered manually. Manually adding Associated Files/Dependencies If you are adding only a few associated files/dependencies, you can add each individually using the \"Associated Files/Dependencies\" arrow button: Batch adding Associated Files/Dependencies If you would like to add many associated files at once, you can use the \"Add Multiple Resource Dependencies\" option, which can be found at the top of the window: Fill in this field with associated files/dependencies using drag and drop. The files you add via drag and drop will automatically appear in the \"Associated Files/Dependencies\" section of the form.","title":"Associated Files/Dependencies"},{"location":"resotrack/addresource/#access","text":"This specifies the level of access that you will apply to this resource (permanent private, temporary private, restricted access, or public). If you select \"temporary-private,\" you will need to complete two additional fields to specify: 1) the level of access for the resource after the temporary private period and 2) the timepoint of the end of the temporary private period (Access Date). First, add an additional row and select the designated level of access of the resource once the temporary private period ends. Fill in the \"Access Date\" when the temporary private period will end. This can just be a projection; you are not bound by this date. For other access levels, you will not need to complete these additional steps.","title":"Access"},{"location":"resotrack/addresource/#software-used-to-produceread-the-resource-file","text":"If specific or proprietary software is required to open or read the resource, you should fill this out. This field is not required. If no special/proprietary software was used to produce/read the resource file, leave this field blank.","title":"Software used to produce/read the resource file"},{"location":"resotrack/addresource/#resource-note","text":"This field should be used for any additional notes that are not already covered in the other fields of the Resource Tracker but that would be important for someone viewing or re-using a resource.","title":"Resource Note"},{"location":"resotrack/addresource/#adding-multiple-like-files","text":"If you have multiple \"like\" files with a similar naming convention, you may want to add and annotate them all at once rather than individually. The tool has a special feature that you can utilize to annotate multiple \"like\" files all at once.","title":"Adding Multiple \"Like\" Files"},{"location":"resotrack/addresource/#what-are-like-files","text":"Examples of \"like\" files may be multiple datasets where each is a run of the same set of experiments or experimental results where each dataset corresponds to one subject's data. \"Like\" files will also have the same file extension. To use this feature in the tool, \"like\" files should follow a common naming convention: For example, multiple data files by subject ID grouped in folders by week would be \"like\" files. The naming convention here is week-#/subject-# Another example: for an experiment testing samples on multiple different dates, files could follow the naming convention sample_1_date_20230818, sample_2_date_20230818, etc. If you have \"like\" files, but they don't follow a common naming convention, you may want to re-name the files (applying a common naming convention) before using this feature. If you have determined that you have a set of 'like' resources that you would like to annotate all at once, follow the steps below.","title":"What are \"like\" files?"},{"location":"resotrack/addresource/#how-to-add-multiple-like-files","text":"Select \"Add Multiple 'like' Resources\" Drag and drop all \"like\" files you want to annotate together. The first of those files paths will appear in the \"Resource File Path\" field in the form. If your \"like\" files are in \"like\" folders (as in the above example of week-#/subject-# structure), you can drag the folders into the box, and the tool will unpack them for you. Once you add your \"like\" files, a box will pop up asking you to add a naming convention. Enter a naming convention for your like files in the \"Resource File Name Convention\" box shown below: Follow the instructions in the dialog box above as to how to create a naming convention. Specifically, make sure that you use the {} brackets to bound the number, date, or descriptive information that changes from one like file to another. You will specify your naming convention slightly differently depending on whether the common naming convention it is integrated within the directory structure (e.g., multiple data files by subject ID grouped in folders by week) or within the filename (e.g., multiple data files within the same directory that only differ by filename). If your naming convention is within the directory structure : Copy the file path from the Resource File Path field and paste into the Resource File Name Convention box: Change the piece that changes from one like file to another to a descriptive name within {}. Do not remove the file extension from the path (e.g., .txt, .csv, .xlsx). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. You have retained the file extension in the path. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended: If your naming convention is fully contained within the file name : You should only include the file name in the \"Resource File Name Convention\" field (rather than the file path). Select \"Apply Name Convention.\" Check the User Status Message Box to confirm that your naming convention was able to be applied. If you receive an error in the User Status Message Box, review your naming convention and ensure that: You have used {} to bound the changing number, date, or information that varies among your like files. Your files are actually \"like\" named. If the User Status Message Box prints a successful result, also refer to the \"Resource File Description\" to confirm that the naming convention was applied how you intended.","title":"How to add multiple \"like\" files"},{"location":"resotrack/addresource/#saving-your-resource","text":"Once you have finished entering the resource information, select \"Save resource.\" Warning Make sure you do not have your Resource Tracker open before trying to save. If you attempt to save a resource but have the Resource Tracker open, the annotated resource file will not save. You will receive this error: To save your resource, you will need to close the Resource Tracker and then press \"save resource\" again. After you select \"Save resource,\" the User Status Message Box should display a message confirming that your resource file saved successfully and that the resource has been written to the Resource Tracker file: This message will also include a note about all the files you listed as associated files/dependencies for your resource. Each of these dependencies will also need to be documented as a resource. To make this process easier, these files will automatically be pulled into a resource list, which you can access via the \"Check Resources to Add\" tab. You will be able to use the \"Check Resources to Add\" tab to directly select and document specific resources from the list. Although the tool will automatically add your resource to the Resource Tracker as part of the \"save\" process, your individual resource annotation file will also be saved as a .txt file within the dsc-pkg folder. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) directly unless: You need to edit an existing annotated resource There was an error in automatically adding the resource to the Resource Tracker, which would necessitate manually batch adding resources to the tracker","title":"Saving Your Resource"},{"location":"resotrack/addresource/#next-steps","text":"After you have saved your resource, you can annotate a new resource. If you would like to annotate a new resource, you can select \"Clear form\" at the top of the Annotate Resource window. This will reset your form and generate the next sequential resource ID, so you can start annotating a new resource. The User Status Message Box will print a message confirming your form was successfully cleared and that the new sequential ID has been generated. Tip If you need to annotate a new resource that is very similar to a previously annotated resource with only some slight changes, you can also use the advanced option \"Add a new resource based on an existing resource.\" This will allow you to copy the information from a previously annotated resource into a new resource, for ease of annotation.","title":"Next Steps"},{"location":"resotrack/batchreso/","text":"Advanced \u00b6 Add a New Resource Based on an Existing Resource \u00b6 If you need to annotate a resource that is very similar to a previously annotated resource, with only small changes, you may want to use the \"Add a new resource based on an existing resource\" option. With this feature, you will select a previously annotated resource, and the tool will copy the information from the chosen resource into a new resource annotation form with a unique resource-ID. You will then only need to edit the information rather than reproduce it. Select \"Add a new resource based on an existing resource.\" Your working data package folder will open automatically. Select the resource on which you want to base your new resource annotation. The annotate resource form will open and populate with the selected resource information with a unique ID. Edit the form to reflect the differences in this new resource. Save the form. Batch Add Resource(s) to Tracker \u00b6 This feature allows you to manually add existing annotated resources to the Resource Tracker. You should not generally need to use this feature, but it is included to account for the possibility that an error in the saving process could cause your annotated resouce to be saved as a .txt file but not automatically added to the Resource Tracker. In this case, you will be able to use the \"Batch add existing resource(s) to tracker\" option to add these resource(s) to the appropriate tracker. Ensure that your Resource Tracker is not open before attempting to batch add resources. Navigate to the \"Add Resource\" tab and select \"Batch add existing resource(s) to tracker\" under \"Advanced.\" Select the resources that you want to add. It may be easiest to select all existing annotated resource files when using this feature. The tool will scan the resource files you select and only add those that are not already included within the Resource Tracker, so selecting a file that has already been included in the Resource Tracker will not produce an error here. Note: Resource annotation txt files follow the naming convention \"resource-trk-resource-\" If your files are successfully added to the Resource Tracker, the User Status Message Box will provide a confirmation message:","title":"Advanced"},{"location":"resotrack/batchreso/#advanced","text":"","title":"Advanced"},{"location":"resotrack/batchreso/#add-a-new-resource-based-on-an-existing-resource","text":"If you need to annotate a resource that is very similar to a previously annotated resource, with only small changes, you may want to use the \"Add a new resource based on an existing resource\" option. With this feature, you will select a previously annotated resource, and the tool will copy the information from the chosen resource into a new resource annotation form with a unique resource-ID. You will then only need to edit the information rather than reproduce it. Select \"Add a new resource based on an existing resource.\" Your working data package folder will open automatically. Select the resource on which you want to base your new resource annotation. The annotate resource form will open and populate with the selected resource information with a unique ID. Edit the form to reflect the differences in this new resource. Save the form.","title":"Add a New Resource Based on an Existing Resource"},{"location":"resotrack/batchreso/#batch-add-resources-to-tracker","text":"This feature allows you to manually add existing annotated resources to the Resource Tracker. You should not generally need to use this feature, but it is included to account for the possibility that an error in the saving process could cause your annotated resouce to be saved as a .txt file but not automatically added to the Resource Tracker. In this case, you will be able to use the \"Batch add existing resource(s) to tracker\" option to add these resource(s) to the appropriate tracker. Ensure that your Resource Tracker is not open before attempting to batch add resources. Navigate to the \"Add Resource\" tab and select \"Batch add existing resource(s) to tracker\" under \"Advanced.\" Select the resources that you want to add. It may be easiest to select all existing annotated resource files when using this feature. The tool will scan the resource files you select and only add those that are not already included within the Resource Tracker, so selecting a file that has already been included in the Resource Tracker will not produce an error here. Note: Resource annotation txt files follow the naming convention \"resource-trk-resource-\" If your files are successfully added to the Resource Tracker, the User Status Message Box will provide a confirmation message:","title":"Batch Add Resource(s) to Tracker"},{"location":"resotrack/checkresource/","text":"Check Resources to Add \u00b6 Purpose \u00b6 As you document each resource, you will enter dependencies. After a file is listed as a dependency, it will need to be documented as a resource. This allows for future investigators to understand what files underlie the results. The \"Check Resources to Add\" tab is designed make this process easier. Whenever you document a resource and add dependencies, the tool will pull any of those dependencies that have not yet been documented into a resource list. When you load the resource list, you will be able to view all resources (that have been added as dependencies) left to annotate. You will also be able to select and annotate remaining resources from this window. If you are using a minimal annotation standard, you will also be able to designate whether you are planning to share each resource within the list. If you are not planning to share a resource, you will be able to complete a \"rapid audit\" for that resource instead of providing full documentation. This will mean even those resources that will not be shared to have at least minimal descriptive information. Loading the Resource List \u00b6 Once you have documented one or more resources and their dependencies in the \"Add Resource\" tab, you will be able to view those dependencies in the Resource List. Navigate to the \"Check Resources to Add\" tab. Select \"Load Resource List.\" Note the user status message box above: Each time you add a resource, you should re-load your resource list using the \"Load Resource List\" push-button . This will remove the resource you have just annotated and add any new dependencies documented. When you open the \"Load Resource List\" window, you will find a list of all resources that have been added as dependencies, including the relative path, the type of dependency, the parent resource, and an option to \"add resource to tracker.\" If you are loading your resource list for the first time: You should start by responding to two questions : 1) how you would like the file paths to be displayed in the resource list and 2) whether you have chosen a minimal annotation standard. Note that after you have selected your preferences for these two questions, the tool will save them, so you will not have to re-select them each time you load your resource list. Question 1 is fairly simple and just a matter of preference as to how you would like to view the file paths as you are using this tab in the tool. You can choose to display file paths as full paths or as relative paths, relative to your working data package directory. Question 2 asks you whether you have chosen a minimal annotation standard due to a low level of resources available to devote to data sharing. If you need a refresher on how to answer this question, please refer to the conceptual best practices guidance documentation . If you select this option, an additional column will appear within the resource list: \"Share resource?\" Since you are following a minimal annotation standard, you will only fully document the files that you are sharing in your shareable data package. Deselect the checkboxes corresponding to resources you will not share publicly in a repository. By default, all resources will be selected for sharing. You must deselect the resources that you are not planning to share. Once a resource is deselected, the option to \"rapidly audit\" the resource will appear. This \"rapid audit\" form will be a modified version of the full resource annotation form, requiring only minimal information be provided. Adding a Resource from the Resource List \u00b6 You can annotate resources directly from the resource list, rather than returning to the Add Resource tab to add them. There are two methods for adding resources, add resource to tracker and rapid audit resource. Which method is used will depend on whether the resource will be shared in a repository. If you are not using a minimal annotation standard : You will only use the \"Add resource to tracker\" option. If you are using a minimal annotation standard : You will use the \"Add resource to tracker\" option for those resources that will be shared in a repository and \"Rapid audit resource\" for those resources that will not be shared in a repository. Add Resource to Tracker \u00b6 You can annotate a resource directly from the resource list, rather than returning to the \"Add Resource\" tab. To annotate a resource within the resource list, select \"Add resource to tracker.\" This will open the same \"Annotate Resource\" window that you would find if you annotated a new resource via the \"Add Resource\" tab. For a refresher on how to fill out this form, refer to the instructions on adding a new resource . For most associated files/dependencies, the tool will pre-fill the resource file path. For certain types of resources, the tool will pre-fill additional information. For example, in the below example the resource being annotated had been added as an associated data dictionary for resource-27. The tool extracted this information and pre-filled some fields in the resource form automatically. Fill in the form as usual, including adding the associated files/dependencies. Save the resource, and close the form. Return to the \"Check Resources to Add\" tab and select \"Load Resource List\" to refresh the list. The resource you have just annotated will be removed from the refreshed list, and any newly added dependencies will appear. In the example, below although the cohort file, raw data, and statistical analysis plan were all added as dependencies for resource-6 (documented above), only the cohort file has been added to the resource list upon refresh. The statistical analysis plan has already been documented, so it does not appear, and the raw data was already listed as a dependency of resource-5. Repeat these steps until you have annotated all resources in the resource list. Rapid Audit Resource \u00b6 If you have chosen a minimal annotation standard due to a low level of resources available to devote to data sharing, ensure that you have selected the checkbox in the optional section in the \"Check Resources to Add\" tab. Review the resource list and deselect any resources that you will not be sharing under \"Share resource?\" You will then be given the option to rapid audit these resources. For resources that you will not share, select the \"Rapid audit resource\" option. You will be presented with a pared down version of the \"Annotate Resource\" form. As in the normal resource annotation form, additional fields may appear based on the \"Resource Category.\" Fill in the form, including any associated files/dependencies. Note that because the resource being annotated here is a tabular file, the associated data dictionary and associated protocol fields have also popped up. Save the resource, and close the form. Return to the \"Check Resources to Add\" tab and select \"Load Resource List\" to refresh the list. The resource you have just annotated will be removed from the refreshed list, and any newly added dependencies will appear. Each new resource added to the list will automatically be assumed to be shared, so it is important to also review the updated resource list and ensure that all resources that will not be shared are deselected under \"Share resource?\" Repeat these steps annotating all resources that will not be shared in a repository using the \"Rapid audit resource\" feature. As a reminder, when documenting resources that will be shared, use the \"Add resource to tracker\" feature detailed above.","title":"Check Resources to Add"},{"location":"resotrack/checkresource/#check-resources-to-add","text":"","title":"Check Resources to Add"},{"location":"resotrack/checkresource/#purpose","text":"As you document each resource, you will enter dependencies. After a file is listed as a dependency, it will need to be documented as a resource. This allows for future investigators to understand what files underlie the results. The \"Check Resources to Add\" tab is designed make this process easier. Whenever you document a resource and add dependencies, the tool will pull any of those dependencies that have not yet been documented into a resource list. When you load the resource list, you will be able to view all resources (that have been added as dependencies) left to annotate. You will also be able to select and annotate remaining resources from this window. If you are using a minimal annotation standard, you will also be able to designate whether you are planning to share each resource within the list. If you are not planning to share a resource, you will be able to complete a \"rapid audit\" for that resource instead of providing full documentation. This will mean even those resources that will not be shared to have at least minimal descriptive information.","title":"Purpose"},{"location":"resotrack/checkresource/#loading-the-resource-list","text":"Once you have documented one or more resources and their dependencies in the \"Add Resource\" tab, you will be able to view those dependencies in the Resource List. Navigate to the \"Check Resources to Add\" tab. Select \"Load Resource List.\" Note the user status message box above: Each time you add a resource, you should re-load your resource list using the \"Load Resource List\" push-button . This will remove the resource you have just annotated and add any new dependencies documented. When you open the \"Load Resource List\" window, you will find a list of all resources that have been added as dependencies, including the relative path, the type of dependency, the parent resource, and an option to \"add resource to tracker.\" If you are loading your resource list for the first time: You should start by responding to two questions : 1) how you would like the file paths to be displayed in the resource list and 2) whether you have chosen a minimal annotation standard. Note that after you have selected your preferences for these two questions, the tool will save them, so you will not have to re-select them each time you load your resource list. Question 1 is fairly simple and just a matter of preference as to how you would like to view the file paths as you are using this tab in the tool. You can choose to display file paths as full paths or as relative paths, relative to your working data package directory. Question 2 asks you whether you have chosen a minimal annotation standard due to a low level of resources available to devote to data sharing. If you need a refresher on how to answer this question, please refer to the conceptual best practices guidance documentation . If you select this option, an additional column will appear within the resource list: \"Share resource?\" Since you are following a minimal annotation standard, you will only fully document the files that you are sharing in your shareable data package. Deselect the checkboxes corresponding to resources you will not share publicly in a repository. By default, all resources will be selected for sharing. You must deselect the resources that you are not planning to share. Once a resource is deselected, the option to \"rapidly audit\" the resource will appear. This \"rapid audit\" form will be a modified version of the full resource annotation form, requiring only minimal information be provided.","title":"Loading the Resource List"},{"location":"resotrack/checkresource/#adding-a-resource-from-the-resource-list","text":"You can annotate resources directly from the resource list, rather than returning to the Add Resource tab to add them. There are two methods for adding resources, add resource to tracker and rapid audit resource. Which method is used will depend on whether the resource will be shared in a repository. If you are not using a minimal annotation standard : You will only use the \"Add resource to tracker\" option. If you are using a minimal annotation standard : You will use the \"Add resource to tracker\" option for those resources that will be shared in a repository and \"Rapid audit resource\" for those resources that will not be shared in a repository.","title":"Adding a Resource from the Resource List"},{"location":"resotrack/checkresource/#add-resource-to-tracker","text":"You can annotate a resource directly from the resource list, rather than returning to the \"Add Resource\" tab. To annotate a resource within the resource list, select \"Add resource to tracker.\" This will open the same \"Annotate Resource\" window that you would find if you annotated a new resource via the \"Add Resource\" tab. For a refresher on how to fill out this form, refer to the instructions on adding a new resource . For most associated files/dependencies, the tool will pre-fill the resource file path. For certain types of resources, the tool will pre-fill additional information. For example, in the below example the resource being annotated had been added as an associated data dictionary for resource-27. The tool extracted this information and pre-filled some fields in the resource form automatically. Fill in the form as usual, including adding the associated files/dependencies. Save the resource, and close the form. Return to the \"Check Resources to Add\" tab and select \"Load Resource List\" to refresh the list. The resource you have just annotated will be removed from the refreshed list, and any newly added dependencies will appear. In the example, below although the cohort file, raw data, and statistical analysis plan were all added as dependencies for resource-6 (documented above), only the cohort file has been added to the resource list upon refresh. The statistical analysis plan has already been documented, so it does not appear, and the raw data was already listed as a dependency of resource-5. Repeat these steps until you have annotated all resources in the resource list.","title":"Add Resource to Tracker"},{"location":"resotrack/checkresource/#rapid-audit-resource","text":"If you have chosen a minimal annotation standard due to a low level of resources available to devote to data sharing, ensure that you have selected the checkbox in the optional section in the \"Check Resources to Add\" tab. Review the resource list and deselect any resources that you will not be sharing under \"Share resource?\" You will then be given the option to rapid audit these resources. For resources that you will not share, select the \"Rapid audit resource\" option. You will be presented with a pared down version of the \"Annotate Resource\" form. As in the normal resource annotation form, additional fields may appear based on the \"Resource Category.\" Fill in the form, including any associated files/dependencies. Note that because the resource being annotated here is a tabular file, the associated data dictionary and associated protocol fields have also popped up. Save the resource, and close the form. Return to the \"Check Resources to Add\" tab and select \"Load Resource List\" to refresh the list. The resource you have just annotated will be removed from the refreshed list, and any newly added dependencies will appear. Each new resource added to the list will automatically be assumed to be shared, so it is important to also review the updated resource list and ensure that all resources that will not be shared are deselected under \"Share resource?\" Repeat these steps annotating all resources that will not be shared in a repository using the \"Rapid audit resource\" feature. As a reminder, when documenting resources that will be shared, use the \"Add resource to tracker\" feature detailed above.","title":"Rapid Audit Resource"},{"location":"resotrack/editresource/","text":"Editing an Existing Resource \u00b6 If you want to edit a resource after you have created it, you can do so in the tool using the \"Edit an existing resource\" feature. Info We encourage you to use the tool to edit your resources rather than entering/editing information manually into the Resource Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing resource\" in the \"Add Resource\" tab. Your dsc-pkg folder will open in File Explorer. Select the anntotated resource .txt file that you want to edit. For example : The information on your annotated resource will population in the \"Annotate Resource\" window. Make any necessary edits to your resource file, and then select \"Save resource.\" When you save your edited resource, the tool will archive the original version of your resource annotation (.txt) file in an \"archive\" folder, so there are no issues with duplicate file naming. Editing Multiple \"Like\" Resources \u00b6 If you have annotated multiple \"like\" files at once using the \"Add Multiple 'like' Resources\" option, you can also edit them as a group using the \"Edit an existing resource\" feature. You cannot edit individual resources that were added as a set of multiple \"like\" files. If you would like to edit a multi-like file resource, select the resource txt file that is first in the series of annotated multiple-like file resources. For example, if you annotated 3 files as multiple 'like' resources, and the corresponding resource txt files created were the three files in the image below, you would want to select to edit resource-trk-resource-29. If you select a resource that is not the first txt file in that series of annotated multiple 'like' files (in the above example, resource-trk-resource-29), you will receive an error in the User Status Message Box (below) instructing you to return to the edit option and select the first resource in the series. The information on your annotated resource will population in the \"Annotate Resource\" window. Make any necessary edits to your multi 'like' resources, and then select \"Save resource.\" When you save your edited resource, the tool will archive the original versions of your multi 'like' resource annotation (.txt) files in an \"archive\" folder, so there are no issues with duplicate file naming.","title":"Edit an Existing Resource"},{"location":"resotrack/editresource/#editing-an-existing-resource","text":"If you want to edit a resource after you have created it, you can do so in the tool using the \"Edit an existing resource\" feature. Info We encourage you to use the tool to edit your resources rather than entering/editing information manually into the Resource Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing resource\" in the \"Add Resource\" tab. Your dsc-pkg folder will open in File Explorer. Select the anntotated resource .txt file that you want to edit. For example : The information on your annotated resource will population in the \"Annotate Resource\" window. Make any necessary edits to your resource file, and then select \"Save resource.\" When you save your edited resource, the tool will archive the original version of your resource annotation (.txt) file in an \"archive\" folder, so there are no issues with duplicate file naming.","title":"Editing an Existing Resource"},{"location":"resotrack/editresource/#editing-multiple-like-resources","text":"If you have annotated multiple \"like\" files at once using the \"Add Multiple 'like' Resources\" option, you can also edit them as a group using the \"Edit an existing resource\" feature. You cannot edit individual resources that were added as a set of multiple \"like\" files. If you would like to edit a multi-like file resource, select the resource txt file that is first in the series of annotated multiple-like file resources. For example, if you annotated 3 files as multiple 'like' resources, and the corresponding resource txt files created were the three files in the image below, you would want to select to edit resource-trk-resource-29. If you select a resource that is not the first txt file in that series of annotated multiple 'like' files (in the above example, resource-trk-resource-29), you will receive an error in the User Status Message Box (below) instructing you to return to the edit option and select the first resource in the series. The information on your annotated resource will population in the \"Annotate Resource\" window. Make any necessary edits to your multi 'like' resources, and then select \"Save resource.\" When you save your edited resource, the tool will archive the original versions of your multi 'like' resource annotation (.txt) files in an \"archive\" folder, so there are no issues with duplicate file naming.","title":"Editing Multiple \"Like\" Resources"},{"location":"resotrack/viewresource/","text":"Viewing the Resource Tracker \u00b6 If you need to view anything that you have already input into the Resource Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Resource Tracker within the application to: Review which individual resources you have already annotated and determine which you still need to annotate. Find/confirm the resource ID for a particular resource to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Resource Tracker tab. Select \"View Resource Tracker.\" The window below will pop up. Select \"Load Resource Tracker.\" Your Resource Tracker will populate in the window.","title":"View the Resource Tracker"},{"location":"resotrack/viewresource/#viewing-the-resource-tracker","text":"If you need to view anything that you have already input into the Resource Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Resource Tracker within the application to: Review which individual resources you have already annotated and determine which you still need to annotate. Find/confirm the resource ID for a particular resource to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Resource Tracker tab. Select \"View Resource Tracker.\" The window below will pop up. Select \"Load Resource Tracker.\" Your Resource Tracker will populate in the window.","title":"Viewing the Resource Tracker"},{"location":"resulttrack/","text":"About the Results Tracker \u00b6 This tab will help you create and fill out the Results Tracker(s). Each Results Tracker provides an annotated inventory of all results included in a publication. The depth and extent of information included in a Results Tracker will be determined by the approach you have chosen for annotation of your data. You will have one Results Tracker for each publication (e.g., manuscript, poster, etc.) that you share. If you only have one publication that you are planning to share, you will only have one Results Tracker. However, if you have multiple publications, you will have a Results Tracker for each publication. In addition to the publication-specific Results Trackers, you will have one overall Results Tracker, which is a compilation of all individual results you have annotated within the tool, including results that are not yet associated with a publication. This tracker is called heal-csv-results-tracker-collect-all. A Note on the Results Tracker Unlike the Experiment Tracker, Resource Tracker, and Results Tracker \"collect-all\" shells, which automatically appeared in your dsc-pkg directory when it was created, you will create the publication-specific Results Tracker(s) through the process of adding individual results. Example of a Results Tracker with multiple individual results annotated:","title":"About the Results Tracker"},{"location":"resulttrack/#about-the-results-tracker","text":"This tab will help you create and fill out the Results Tracker(s). Each Results Tracker provides an annotated inventory of all results included in a publication. The depth and extent of information included in a Results Tracker will be determined by the approach you have chosen for annotation of your data. You will have one Results Tracker for each publication (e.g., manuscript, poster, etc.) that you share. If you only have one publication that you are planning to share, you will only have one Results Tracker. However, if you have multiple publications, you will have a Results Tracker for each publication. In addition to the publication-specific Results Trackers, you will have one overall Results Tracker, which is a compilation of all individual results you have annotated within the tool, including results that are not yet associated with a publication. This tracker is called heal-csv-results-tracker-collect-all. A Note on the Results Tracker Unlike the Experiment Tracker, Resource Tracker, and Results Tracker \"collect-all\" shells, which automatically appeared in your dsc-pkg directory when it was created, you will create the publication-specific Results Tracker(s) through the process of adding individual results. Example of a Results Tracker with multiple individual results annotated:","title":"About the Results Tracker"},{"location":"resulttrack/addresult/","text":"Adding a New Result \u00b6 Getting Started \u00b6 Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a result, the tool cannot automatically generate your result-ID or connect your result to your data package folder. You will receive the error message below. Navigate to the \"Add Results\" tab and select \"Add a new result.\" The tool will look through your set working data package directory to determine whether there are existing annotated results files saved in the folder and will automatically generate the next sequential Result ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this: Filling Out the Form \u00b6 Tip For additional information about each form field, please refer to the Results Tracker schema . Hovering over each field in the form will provide additional information about what should be contained within the field. For example, for the Result Category field: Fill out a short Result Description. Result Category \u00b6 Based on the Result Category selected, additional questions will appear within the form. Experiment Result 'Belongs' To \u00b6 This option allows you to associate your results directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu. Associated Publication \u00b6 If this figure is already part of a manuscript, poster, or other publication, you will provide the path for that publication here. If your figure is not currently associated with a publication, you can leave this field blank for now. Once this result is included within a publication, you should return to edit the result annotation to fill in the associated publication field for this result. To add an associated publication, select the arrow below the field: If the result is associated with multiple publications , select the arrow again and enter the paths to each of the publication files here. This will allow the tool to create a results tracker for each of those publications in future steps (or add the individual result to the right results trackers), all of which will be associated with this result. Figure Number/Table Number \u00b6 If you selected \"Figure\" or \"Table\" within \"Result Category,\" you will need to provide a corresponding figure/table number for each \"Associated Publication.\" Click on the arrow to insert each figure/table number. Ensure that the figure/table numbers are in the same order as the corresponding publications. You can adjust the order using the green up and down arrows. Associated Files/Dependencies \u00b6 This is where you will list dependencies for the result. How you record dependencies will depend on your annotation approach. For more information about how to decide on your annotation approach, refer to the HEAL data packaging guidance documenation . Regardless of your annotation approach, there are two ways to add \"Associated Files/Dependencies,\" manually or via batch add. See below for descriptions of each. Warning You should only utilize one of the below methods for entering dependencies when adding a specific result. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Results Dependencies\" option, those files may overwrite the files you entered manually. Manually adding Associated Files/Dependencies If you are adding only a few associated files/dependencies, you can add each row individually using the arrow button: Batch adding Associated Files/Dependencies If you would like to add many associated files at once, you can use the \"Add Multiple Results Dependencies\" option, which can be found at the top of the \"Add Results\" window: Fill in this field with associated files/dependencies using drag-and-drop from your file explorer. The files you drag and drop will automatically appear in the \"Associated Files/Dependencies\" section in the form. Result Supports \u00b6 This describes the larger claim that the result is used to support in the publication. This is not required but can be very useful for data reuse and interpretation for future researchers. Saving Your Result \u00b6 When you are done filling out the form, select \"Save result.\" Warning Make sure that you do not have your Results Tracker open before trying to save. If you attempt to save a result but have the corresponding Results Tracker open, the annotated experiment file will not save. You will receive this error: To save your result, you will need to close the Results Tracker and then press \"save result\" again. Each time you save a result, the tool will look for two things: Any existing Results Trackers for the associated publication(s) included in the annotation. If these Results Trackers do not already exist, the tool will create a Results Tracker for each of the associated publication(s). A Results Tracker called \"heal-csv-results-tracker-collect-all.\" This Results Tracker file will include a compilation of every annotated result, regardless of its associated publication. If you annotate a result that is not yet associated with a publication, it will appear only in this tracker until you edit the result annotation to include an associated publication. If your result saves successfully, The User Status Message Box will display this message to indicate your result saved successfully and that the result has been written to the corresponding Results Tracker file(s) as well as the results-tracker-collect-all file. Although the tool will generate the necessary Results Trackers and add your result automatically as part of the \"save\" process, your individual result annotation file will also be saved within your dsc-pkg folder as a .txt file. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated result There is an error in automatically adding results to the Results Tracker, which would necessitate manually batch adding results to the tracker Clear the form. When the form resets, the next sequential Result ID will be generated, so you can start annotating a new result right away. Tip If you need to annotate a new result that is very similar to a previously annotated result with only some slight changes, you can also use the advanced option \"Add a new result based on an existing result.\" This will allow you to copy the information from a previously annotated result into a new result, for ease of annotation.","title":"Add a New Result"},{"location":"resulttrack/addresult/#adding-a-new-result","text":"","title":"Adding a New Result"},{"location":"resulttrack/addresult/#getting-started","text":"Reminder Your first step each time you open the tool should be to set your working data package directory. If you have not yet set your working data package directory this session, do so before attempting to annotate. If you have not set your working package directory before attempting to annotate a result, the tool cannot automatically generate your result-ID or connect your result to your data package folder. You will receive the error message below. Navigate to the \"Add Results\" tab and select \"Add a new result.\" The tool will look through your set working data package directory to determine whether there are existing annotated results files saved in the folder and will automatically generate the next sequential Result ID (e.g., result-1, result-2, etc.). The User Status Message Box will display a message to acknowledge this:","title":"Getting Started"},{"location":"resulttrack/addresult/#filling-out-the-form","text":"Tip For additional information about each form field, please refer to the Results Tracker schema . Hovering over each field in the form will provide additional information about what should be contained within the field. For example, for the Result Category field: Fill out a short Result Description.","title":"Filling Out the Form"},{"location":"resulttrack/addresult/#result-category","text":"Based on the Result Category selected, additional questions will appear within the form.","title":"Result Category"},{"location":"resulttrack/addresult/#experiment-result-belongs-to","text":"This option allows you to associate your results directly with experimental research questions and hypotheses, which can be useful for future researchers trying to understand your experiments and findings. This field pipes in all existing experiment names from the Experiment Tracker into a drop-down menu.","title":"Experiment Result 'Belongs' To"},{"location":"resulttrack/addresult/#associated-publication","text":"If this figure is already part of a manuscript, poster, or other publication, you will provide the path for that publication here. If your figure is not currently associated with a publication, you can leave this field blank for now. Once this result is included within a publication, you should return to edit the result annotation to fill in the associated publication field for this result. To add an associated publication, select the arrow below the field: If the result is associated with multiple publications , select the arrow again and enter the paths to each of the publication files here. This will allow the tool to create a results tracker for each of those publications in future steps (or add the individual result to the right results trackers), all of which will be associated with this result.","title":"Associated Publication"},{"location":"resulttrack/addresult/#figure-numbertable-number","text":"If you selected \"Figure\" or \"Table\" within \"Result Category,\" you will need to provide a corresponding figure/table number for each \"Associated Publication.\" Click on the arrow to insert each figure/table number. Ensure that the figure/table numbers are in the same order as the corresponding publications. You can adjust the order using the green up and down arrows.","title":"Figure Number/Table Number"},{"location":"resulttrack/addresult/#associated-filesdependencies","text":"This is where you will list dependencies for the result. How you record dependencies will depend on your annotation approach. For more information about how to decide on your annotation approach, refer to the HEAL data packaging guidance documenation . Regardless of your annotation approach, there are two ways to add \"Associated Files/Dependencies,\" manually or via batch add. See below for descriptions of each. Warning You should only utilize one of the below methods for entering dependencies when adding a specific result. If you add some files as associated files/dependencies manually and then utilize the \"Add Multiple Results Dependencies\" option, those files may overwrite the files you entered manually. Manually adding Associated Files/Dependencies If you are adding only a few associated files/dependencies, you can add each row individually using the arrow button: Batch adding Associated Files/Dependencies If you would like to add many associated files at once, you can use the \"Add Multiple Results Dependencies\" option, which can be found at the top of the \"Add Results\" window: Fill in this field with associated files/dependencies using drag-and-drop from your file explorer. The files you drag and drop will automatically appear in the \"Associated Files/Dependencies\" section in the form.","title":"Associated Files/Dependencies"},{"location":"resulttrack/addresult/#result-supports","text":"This describes the larger claim that the result is used to support in the publication. This is not required but can be very useful for data reuse and interpretation for future researchers.","title":"Result Supports"},{"location":"resulttrack/addresult/#saving-your-result","text":"When you are done filling out the form, select \"Save result.\" Warning Make sure that you do not have your Results Tracker open before trying to save. If you attempt to save a result but have the corresponding Results Tracker open, the annotated experiment file will not save. You will receive this error: To save your result, you will need to close the Results Tracker and then press \"save result\" again. Each time you save a result, the tool will look for two things: Any existing Results Trackers for the associated publication(s) included in the annotation. If these Results Trackers do not already exist, the tool will create a Results Tracker for each of the associated publication(s). A Results Tracker called \"heal-csv-results-tracker-collect-all.\" This Results Tracker file will include a compilation of every annotated result, regardless of its associated publication. If you annotate a result that is not yet associated with a publication, it will appear only in this tracker until you edit the result annotation to include an associated publication. If your result saves successfully, The User Status Message Box will display this message to indicate your result saved successfully and that the result has been written to the corresponding Results Tracker file(s) as well as the results-tracker-collect-all file. Although the tool will generate the necessary Results Trackers and add your result automatically as part of the \"save\" process, your individual result annotation file will also be saved within your dsc-pkg folder as a .txt file. Note Once you have created them, you will not generally need to interact with the annotation files (.txt files) unless: You need to edit an existing annotated result There is an error in automatically adding results to the Results Tracker, which would necessitate manually batch adding results to the tracker Clear the form. When the form resets, the next sequential Result ID will be generated, so you can start annotating a new result right away. Tip If you need to annotate a new result that is very similar to a previously annotated result with only some slight changes, you can also use the advanced option \"Add a new result based on an existing result.\" This will allow you to copy the information from a previously annotated result into a new result, for ease of annotation.","title":"Saving Your Result"},{"location":"resulttrack/batchresult/","text":"Advanced \u00b6 Add a New Result Based on an Existing Result \u00b6 If you need to annotate a result that is very similar to a previously annotated result, with only small changes, you may want to use the \"Add a new result based on an existing result\" option. With this feature, you will select a previously annotated result, and the tool will copy the information from the chosen result into a new result annotation form with a unique result-ID. You will then only need to edit the information rather than reproduce it. Select \"Add a new result based on an existing result.\" Your working data package folder will open automatically. Select the result upon which you want to base your new result annotation. The annotate result form will open and populate with the selected result information with a unique ID. Edit the form to reflect the differences in this new result. Save the form. Batch Add Result(s) to Tracker \u00b6 This feature allows you to manually add existing annotated results to the appropriate Result Tracker. You should not generally need to use this feature, but it is included to account for the possibility that an error in the saving process could cause your annotated result to be saved as a .txt file but not automatically added to the appropriate Result Tracker. In this case, you will be able to use the \"Batch add existing result(s) to tracker\" option to add these result(s) to the appropriate tracker. Ensure that none of your Results Trackers are open before attempting to batch add results. Navigate to the \"Add Result\" tab and select \"Batch add existing result(s) to tracker\" under \"Advanced.\" Select the results that you want to add. It may be easiest to select all existing annotated result files when using this feature. The tool will scan the result files you select and only add those that are not already included in within the Results Tracker, so selecting a file that has already been included in the Results Tracker will not produce an error here. Note: These files follow the naming convention \"result-trk-result-\" If your files are successfully added to the appropriate Results Trackers, the User Status Message Box will provide a confirmation message:","title":"Advanced"},{"location":"resulttrack/batchresult/#advanced","text":"","title":"Advanced"},{"location":"resulttrack/batchresult/#add-a-new-result-based-on-an-existing-result","text":"If you need to annotate a result that is very similar to a previously annotated result, with only small changes, you may want to use the \"Add a new result based on an existing result\" option. With this feature, you will select a previously annotated result, and the tool will copy the information from the chosen result into a new result annotation form with a unique result-ID. You will then only need to edit the information rather than reproduce it. Select \"Add a new result based on an existing result.\" Your working data package folder will open automatically. Select the result upon which you want to base your new result annotation. The annotate result form will open and populate with the selected result information with a unique ID. Edit the form to reflect the differences in this new result. Save the form.","title":"Add a New Result Based on an Existing Result"},{"location":"resulttrack/batchresult/#batch-add-results-to-tracker","text":"This feature allows you to manually add existing annotated results to the appropriate Result Tracker. You should not generally need to use this feature, but it is included to account for the possibility that an error in the saving process could cause your annotated result to be saved as a .txt file but not automatically added to the appropriate Result Tracker. In this case, you will be able to use the \"Batch add existing result(s) to tracker\" option to add these result(s) to the appropriate tracker. Ensure that none of your Results Trackers are open before attempting to batch add results. Navigate to the \"Add Result\" tab and select \"Batch add existing result(s) to tracker\" under \"Advanced.\" Select the results that you want to add. It may be easiest to select all existing annotated result files when using this feature. The tool will scan the result files you select and only add those that are not already included in within the Results Tracker, so selecting a file that has already been included in the Results Tracker will not produce an error here. Note: These files follow the naming convention \"result-trk-result-\" If your files are successfully added to the appropriate Results Trackers, the User Status Message Box will provide a confirmation message:","title":"Batch Add Result(s) to Tracker"},{"location":"resulttrack/editresult/","text":"Editing an Existing Result \u00b6 If you want to edit a result after you have created it, you can do so in the tool using the \"Edit an existing result\" feature. Info We encourage you to use the form to edit your results rather than entering/editing information manually into the Results Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing result\" in the \"Add Result\" tab. Navigate to your dsc-pkg folder and select the annotated result .txt file that you want to edit. For example: The information on your annotated result will populate in the \"Annotate Result\" window. Make any necessary edits to your result file, and then select \"Save result.\" When you save your edited result, the tool will archive the original version of your result annotation (.txt) file in an \"archive\" folder, so there are no issues with duplicate file naming.","title":"Edit an Existing Result"},{"location":"resulttrack/editresult/#editing-an-existing-result","text":"If you want to edit a result after you have created it, you can do so in the tool using the \"Edit an existing result\" feature. Info We encourage you to use the form to edit your results rather than entering/editing information manually into the Results Tracker CSV, as the tool will automatically put your information into the correct formatting and structure. Manual edits will not necessarily be in the correct format. Select \"Edit existing result\" in the \"Add Result\" tab. Navigate to your dsc-pkg folder and select the annotated result .txt file that you want to edit. For example: The information on your annotated result will populate in the \"Annotate Result\" window. Make any necessary edits to your result file, and then select \"Save result.\" When you save your edited result, the tool will archive the original version of your result annotation (.txt) file in an \"archive\" folder, so there are no issues with duplicate file naming.","title":"Editing an Existing Result"},{"location":"resulttrack/resulttotrack/","text":"Adding Result(s) to Result Tracker(s) \u00b6 Once you have annotated your results files, close the \"Annotate Result\" window and return to the \"Add Result\" tab. Click on \"Add result to tracker.\" Navigate to the results that you want to add. You can select multiple by holding down \"ctrl\" (\"command\" on a Mac) while selecting your results files. After selecting these files, another window will pop up to select your DSC package directory, which is where your results trackers will generate (this should be the same folder where your results annotation txt files are saved). If you have not already created results trackers, your folder should show no trackers found when you select the dsc-pkg folder: Once you select the folder, you will receive information in the User Status Message Box notifying you that the Results Tracker(s) have been created based on your results file(s). In the example below, results added were associated with two different publications, so two results trackers were created and saved in the dsc-pkg folder. And the individual results were automatically entered into each tracker, as appropriate. Once the Results Trackers have been generated through this step, you can still continue to add results to your existing Results Trackers using the \"Add result to tracker\" option. New results will be added to the corresponding Results Tracker files. Once you have entered a few results, you may want to review your Results Tracker(s) to ensure that your results have been entered correctly. Viewing and Editing the Tracker You can review your Results Tracker at any point using the view feature . If you find there is something you would like to add to an entry or an error that you would like to correct, you can edit any result within the tool .","title":"Adding Result(s) to Result Tracker(s)"},{"location":"resulttrack/resulttotrack/#adding-results-to-result-trackers","text":"Once you have annotated your results files, close the \"Annotate Result\" window and return to the \"Add Result\" tab. Click on \"Add result to tracker.\" Navigate to the results that you want to add. You can select multiple by holding down \"ctrl\" (\"command\" on a Mac) while selecting your results files. After selecting these files, another window will pop up to select your DSC package directory, which is where your results trackers will generate (this should be the same folder where your results annotation txt files are saved). If you have not already created results trackers, your folder should show no trackers found when you select the dsc-pkg folder: Once you select the folder, you will receive information in the User Status Message Box notifying you that the Results Tracker(s) have been created based on your results file(s). In the example below, results added were associated with two different publications, so two results trackers were created and saved in the dsc-pkg folder. And the individual results were automatically entered into each tracker, as appropriate. Once the Results Trackers have been generated through this step, you can still continue to add results to your existing Results Trackers using the \"Add result to tracker\" option. New results will be added to the corresponding Results Tracker files. Once you have entered a few results, you may want to review your Results Tracker(s) to ensure that your results have been entered correctly. Viewing and Editing the Tracker You can review your Results Tracker at any point using the view feature . If you find there is something you would like to add to an entry or an error that you would like to correct, you can edit any result within the tool .","title":"Adding Result(s) to Result Tracker(s)"},{"location":"resulttrack/viewresult/","text":"Viewing the Results Tracker \u00b6 If you need to view anything that you have already input into the Results Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Results Tracker within the application to: Review which individual results associated with a publication that you have already annotated and determining which you still need to annotate. Find/confirm the result ID for a particular result to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Results Tracker tab. Select \"View Results Tracker.\" The window below will pop up. Select \"Load Results Tracker.\" Find and select the results tracker. Your results tracker will populate in the window.","title":"View the Results Tracker"},{"location":"resulttrack/viewresult/#viewing-the-results-tracker","text":"If you need to view anything that you have already input into the Results Tracker, you can use the \"View Tracker\" feature. It may be useful to view your Results Tracker within the application to: Review which individual results associated with a publication that you have already annotated and determining which you still need to annotate. Find/confirm the result ID for a particular result to determine where edits need to be made when there has been a change. Navigate to \"View Tracker\" on the Results Tracker tab. Select \"View Results Tracker.\" The window below will pop up. Select \"Load Results Tracker.\" Find and select the results tracker. Your results tracker will populate in the window.","title":"Viewing the Results Tracker"},{"location":"schemas/","text":"Standard Data Package Metadata Schemas \u00b6 View metadata schemas. Experiment Tracker Resource Tracker Results Tracker Data Dictionary","title":"Standard Data Package Metadata Schemas"},{"location":"schemas/#standard-data-package-metadata-schemas","text":"View metadata schemas. Experiment Tracker Resource Tracker Results Tracker Data Dictionary","title":"Standard Data Package Metadata Schemas"},{"location":"schemas/md_data_dict/","text":"HEAL Data Dictionary \u00b6 version 0.3.1 The aim of this HEAL metadata piece is to track and provide basic information about variables in a tabular data file (i.e. a data file with rows and columns) from your HEAL study. The objective is to list all variables and descriptive information about those variables. This will ensure that potential secondary data users know what data has been collected or calculated and how to use these data. Note that a given study can have multiple tabular data files; You should create a data dictionary for each tabular data file. Thus, a study may have multiple data dictionaries. Highly encouraged Only name and description properties are required. For categorical variables, constraints.enum and enumLabels (where applicable) properties are highly encouraged. For studies using HEAL or other common data elements (CDEs), standardsMappings information is highly encouraged. type and format properties may be particularly useful for some variable types (e.g. date-like variables) Properties (i.e., fields or variables) \u00b6 schemaVersion (string) The version of the schema used in agreed upon convention of major.minor.path (e.g., 1.0.2) NOTE: This is NOT for versioning of each indiviual data dictionary instance. Rather, it is the version of THIS schema document. See version property (below) if specifying the individual data dictionary instance version. If generating a vlmd document as a csv file, include this version in every row/record to indicate this is a schema level property (not applicable for the json version as this property is already at the schema/root level) Examples: 1.0.0 0.2.0 section (string) The section, form, survey instrument, set of measures or other broad category used to group variables. Previously called \"module.\" Examples: Demographics PROMIS Medical History name (string,required) The name of a variable (i.e., field) as it appears in the data. Examples: gender_id title (string) The human-readable title or label of the variable. Examples: Gender identity description (string,required) An extended description of the variable. This could be the definition of a variable or the question text (e.g., if a survey). Examples: The participant's age at the time of study enrollment What is the highest grade or level of school you have completed or the highest degree you have received? type (string) A classification or category of a particular data element or property expected or allowed in the dataset. Must be one of: number , integer , string , any , boolean , date , datetime , time , year , yearmonth , duration , geopoint format (string) Indicates the format of the type specified in the type property. Each format is dependent on the type specified. See here for more information about appropriate format values by variable type . constraints.required (boolean) If this variable is marked as true, then this variable's value must be present (ie not missing; see missingValues). If marked as false or not present, then the variable CAN be missing. constraints.maxLength (integer) Indicates the maximum length of an iterable (e.g., array, string, or object). For example, if 'Hello World' is the longest value of a categorical variable, this would be a maxLength of 11. constraints.enum (string) Constrains possible values to a set of values. Examples: 1|2|3|4|5 Poor|Fair|Good|Very good|Excellent constraints.pattern (string) A regular expression pattern the data MUST conform to. constraints.maximum (integer) Specifies the maximum value of a field (e.g., maximum -- or most recent -- date, maximum integer etc). Note, this is different then maxLength property. constraints.minimum (integer) Specifies the minimum value of a field. enumLabels (string) Variable value encodings provide a way to further annotate any value within a any variable type, making values easier to understand. Many analytic software programs (e.g., SPSS,Stata, and SAS) use numerical encodings and some algorithms only support numerical values. Encodings (and mappings) allow categorical values to be stored as numerical values. Additionally, as another use case, this field provides a way to store categoricals that are stored as \"short\" labels (such as abbreviations). This field is intended to follow this pattern Examples: 1=Poor|2=Fair|3=Good|4=Very good|5=Excellent HW=Hello world|GBW=Good bye world|HM=Hi, Mike enumOrdered (boolean) Indicates whether a categorical variable is ordered. This variable is relevant for variables that have an ordered relationship but not necessarily a numerical relationship (e.g., Strongly disagree < Disagree < Neutral < Agree). This field is intended to follow the ordering aspect of this [this pattern] this pattern missingValues (string) A list of missing values specific to a variable. Examples: Missing|Skipped|No preference Missing trueValues (string) For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values. Examples: required|Yes|Checked required falseValues (string) For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values. Examples: Not required|NOT REQUIRED No custom (string) Additional properties not included a core property. standardsMappings[0].instrument.url (string) A url (e.g., link, address) to a file or other resource containing the instrument, or a set of items which encompass a variable in this variable level metadata document (if at the root level or the document level) or the individual variable (if at the field level). Examples: https://www.heal.nih.gov/files/CDEs/2023-05/adult-demographics-cdes.xlsx standardsMappings[0].instrument.source (string) An abbreviated name/acronym from a controlled vocabulary referencing the resource (e.g., program or repository) containing the instrument, or a set of items which encompass a variable in this variable level metadata document (if at the root level or the document level) or the individual variable (if at the field level). Must be one of: heal-cde standardsMappings[0].instrument.title (string) Examples: Adult demographics adult-demographics standardsMappings[0].instrument.id (string) A code or other string that identifies the instrument within the source. This should always be from the source's formal, standardized identification system Examples: 5141 standardsMappings[0].item.url (string) The url that links out to the published, standardized mapping of a variable (e.g., common data element) Examples: https://evs.nci.nih.gov/ftp1/CDISC/SDTM/SDTM%20Terminology.html#CL.C74457.RACE standardsMappings[0].item.source (string) The source of the standardized variable. Note, this property is required if an id is specified. Examples: CDISC standardsMappings[0].item.id (string) The id locating the individual mapping within the given source. Note, the standardsMappings[0].source property is required if this property is specified. Examples: C74457 relatedConcepts[0].url (string) The url that links out to the published, related concept. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: https://www.ebi.ac.uk/chebi/chebiOntology.do?chebiId=CHEBI:27808 http://purl.bioontology.org/ontology/RXNORM/3304 relatedConcepts[0].title (string) A human-readable title (ie label) to a concept related to the given field. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: Heroin Molecular Structure Heroin Ontology relatedConcepts[0].source (string) The source (e.g., a dictionary or vocabulary set) to a concept related to the given field. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: CHEBI RXNORM relatedConcepts[0].id (string) The id locating the individual concept within the source of the given field. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: 27808 3304 End of schema - Additional Property information \u00b6 type enum definitions: number (A numeric value with optional decimal places. (e.g., 3.14)) integer (A whole number without decimal places. (e.g., 42)) string (A sequence of characters. (e.g., \\\"test\\\")) any (Any type of data is allowed. (e.g., true)) boolean (A binary value representing true or false. (e.g., true)) date (A specific calendar date. (e.g., \\\"2023-05-25\\\")) datetime (A specific date and time, including timezone information. (e.g., \\\"2023-05-25T10:30:00Z\\\")) time (A specific time of day. (e.g., \\\"10:30:00\\\")) year (A specific year. (e.g., 2023) yearmonth (A specific year and month. (e.g., \\\"2023-05\\\")) duration (A length of time. (e.g., \\\"PT1H\\\") geopoint (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278])) format examples/definitions of patterns and possible values: Examples of date time pattern formats %Y-%m-%d (for date, e.g., 2023-05-25) %Y%-%d (for date, e.g., 20230525) for date without dashes %Y-%m-%dT%H:%M:%S (for datetime, e.g., 2023-05-25T10:30:45) %Y-%m-%dT%H:%M:%SZ (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z) %Y-%m-%dT%H:%M:%S%z (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300) %Y-%m-%dT%H:%M (for datetime without seconds, e.g., 2023-05-25T10:30) %Y-%m-%dT%H (for datetime without minutes and seconds, e.g., 2023-05-25T10) %H:%M:%S (for time, e.g., 10:30:45) %H:%M:%SZ (for time with UTC timezone, e.g., 10:30:45Z) %H:%M:%S%z (for time with timezone offset, e.g., 10:30:45+0300) Examples of string formats email if valid emails (e.g., test@gmail.com) uri if valid uri addresses (e.g., https://example.com/resource123) binary if a base64 binary encoded string (e.g., authentication token like aGVsbG8gd29ybGQ=) uuid if a universal unique identifier also known as a guid (eg., f47ac10b-58cc-4372-a567-0e02b2c3d479) Examples of geopoint formats The two types of formats for geopoint (describing a geographic point). array (if 'lat,long' (e.g., 36.63,-90.20)) object (if {'lat':36.63,'lon':-90.20}) standardsMappings and relatedConcepts : If you want to add more than one value,adding anoth column with a name containing an added digit in brackets ( [0] --> [1] --> [n] ). Examples: A table with 2 columns (fields) of the same variables: standardsMappings[0].instrument.title standardsMappings[1].instrument.title My first instrument My second instrument A table with 3 columns (fields) of the same variables: relatedConcepts[0].url relatedConcepts[1].url relatedConcepts[2].url fakehttp://my-first-concept-url.org fakehttp://my-second-concept-url.org fakehttp://my-third-concept-url.org","title":"Data Dictionary"},{"location":"schemas/md_data_dict/#heal-data-dictionary","text":"version 0.3.1 The aim of this HEAL metadata piece is to track and provide basic information about variables in a tabular data file (i.e. a data file with rows and columns) from your HEAL study. The objective is to list all variables and descriptive information about those variables. This will ensure that potential secondary data users know what data has been collected or calculated and how to use these data. Note that a given study can have multiple tabular data files; You should create a data dictionary for each tabular data file. Thus, a study may have multiple data dictionaries. Highly encouraged Only name and description properties are required. For categorical variables, constraints.enum and enumLabels (where applicable) properties are highly encouraged. For studies using HEAL or other common data elements (CDEs), standardsMappings information is highly encouraged. type and format properties may be particularly useful for some variable types (e.g. date-like variables)","title":"HEAL Data Dictionary"},{"location":"schemas/md_data_dict/#properties-ie-fields-or-variables","text":"schemaVersion (string) The version of the schema used in agreed upon convention of major.minor.path (e.g., 1.0.2) NOTE: This is NOT for versioning of each indiviual data dictionary instance. Rather, it is the version of THIS schema document. See version property (below) if specifying the individual data dictionary instance version. If generating a vlmd document as a csv file, include this version in every row/record to indicate this is a schema level property (not applicable for the json version as this property is already at the schema/root level) Examples: 1.0.0 0.2.0 section (string) The section, form, survey instrument, set of measures or other broad category used to group variables. Previously called \"module.\" Examples: Demographics PROMIS Medical History name (string,required) The name of a variable (i.e., field) as it appears in the data. Examples: gender_id title (string) The human-readable title or label of the variable. Examples: Gender identity description (string,required) An extended description of the variable. This could be the definition of a variable or the question text (e.g., if a survey). Examples: The participant's age at the time of study enrollment What is the highest grade or level of school you have completed or the highest degree you have received? type (string) A classification or category of a particular data element or property expected or allowed in the dataset. Must be one of: number , integer , string , any , boolean , date , datetime , time , year , yearmonth , duration , geopoint format (string) Indicates the format of the type specified in the type property. Each format is dependent on the type specified. See here for more information about appropriate format values by variable type . constraints.required (boolean) If this variable is marked as true, then this variable's value must be present (ie not missing; see missingValues). If marked as false or not present, then the variable CAN be missing. constraints.maxLength (integer) Indicates the maximum length of an iterable (e.g., array, string, or object). For example, if 'Hello World' is the longest value of a categorical variable, this would be a maxLength of 11. constraints.enum (string) Constrains possible values to a set of values. Examples: 1|2|3|4|5 Poor|Fair|Good|Very good|Excellent constraints.pattern (string) A regular expression pattern the data MUST conform to. constraints.maximum (integer) Specifies the maximum value of a field (e.g., maximum -- or most recent -- date, maximum integer etc). Note, this is different then maxLength property. constraints.minimum (integer) Specifies the minimum value of a field. enumLabels (string) Variable value encodings provide a way to further annotate any value within a any variable type, making values easier to understand. Many analytic software programs (e.g., SPSS,Stata, and SAS) use numerical encodings and some algorithms only support numerical values. Encodings (and mappings) allow categorical values to be stored as numerical values. Additionally, as another use case, this field provides a way to store categoricals that are stored as \"short\" labels (such as abbreviations). This field is intended to follow this pattern Examples: 1=Poor|2=Fair|3=Good|4=Very good|5=Excellent HW=Hello world|GBW=Good bye world|HM=Hi, Mike enumOrdered (boolean) Indicates whether a categorical variable is ordered. This variable is relevant for variables that have an ordered relationship but not necessarily a numerical relationship (e.g., Strongly disagree < Disagree < Neutral < Agree). This field is intended to follow the ordering aspect of this [this pattern] this pattern missingValues (string) A list of missing values specific to a variable. Examples: Missing|Skipped|No preference Missing trueValues (string) For boolean (true) variable (as defined in type field), this field allows a physical string representation to be cast as true (increasing readability of the field). It can include one or more values. Examples: required|Yes|Checked required falseValues (string) For boolean (false) variable (as defined in type field), this field allows a physical string representation to be cast as false (increasing readability of the field) that is not a standard false value. It can include one or more values. Examples: Not required|NOT REQUIRED No custom (string) Additional properties not included a core property. standardsMappings[0].instrument.url (string) A url (e.g., link, address) to a file or other resource containing the instrument, or a set of items which encompass a variable in this variable level metadata document (if at the root level or the document level) or the individual variable (if at the field level). Examples: https://www.heal.nih.gov/files/CDEs/2023-05/adult-demographics-cdes.xlsx standardsMappings[0].instrument.source (string) An abbreviated name/acronym from a controlled vocabulary referencing the resource (e.g., program or repository) containing the instrument, or a set of items which encompass a variable in this variable level metadata document (if at the root level or the document level) or the individual variable (if at the field level). Must be one of: heal-cde standardsMappings[0].instrument.title (string) Examples: Adult demographics adult-demographics standardsMappings[0].instrument.id (string) A code or other string that identifies the instrument within the source. This should always be from the source's formal, standardized identification system Examples: 5141 standardsMappings[0].item.url (string) The url that links out to the published, standardized mapping of a variable (e.g., common data element) Examples: https://evs.nci.nih.gov/ftp1/CDISC/SDTM/SDTM%20Terminology.html#CL.C74457.RACE standardsMappings[0].item.source (string) The source of the standardized variable. Note, this property is required if an id is specified. Examples: CDISC standardsMappings[0].item.id (string) The id locating the individual mapping within the given source. Note, the standardsMappings[0].source property is required if this property is specified. Examples: C74457 relatedConcepts[0].url (string) The url that links out to the published, related concept. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: https://www.ebi.ac.uk/chebi/chebiOntology.do?chebiId=CHEBI:27808 http://purl.bioontology.org/ontology/RXNORM/3304 relatedConcepts[0].title (string) A human-readable title (ie label) to a concept related to the given field. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: Heroin Molecular Structure Heroin Ontology relatedConcepts[0].source (string) The source (e.g., a dictionary or vocabulary set) to a concept related to the given field. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: CHEBI RXNORM relatedConcepts[0].id (string) The id locating the individual concept within the source of the given field. The listed examples could both be attached to any variable related to, for example, heroin use. Examples: 27808 3304","title":"Properties (i.e., fields or variables)"},{"location":"schemas/md_data_dict/#end-of-schema-additional-property-information","text":"type enum definitions: number (A numeric value with optional decimal places. (e.g., 3.14)) integer (A whole number without decimal places. (e.g., 42)) string (A sequence of characters. (e.g., \\\"test\\\")) any (Any type of data is allowed. (e.g., true)) boolean (A binary value representing true or false. (e.g., true)) date (A specific calendar date. (e.g., \\\"2023-05-25\\\")) datetime (A specific date and time, including timezone information. (e.g., \\\"2023-05-25T10:30:00Z\\\")) time (A specific time of day. (e.g., \\\"10:30:00\\\")) year (A specific year. (e.g., 2023) yearmonth (A specific year and month. (e.g., \\\"2023-05\\\")) duration (A length of time. (e.g., \\\"PT1H\\\") geopoint (A pair of latitude and longitude coordinates. (e.g., [51.5074, -0.1278])) format examples/definitions of patterns and possible values: Examples of date time pattern formats %Y-%m-%d (for date, e.g., 2023-05-25) %Y%-%d (for date, e.g., 20230525) for date without dashes %Y-%m-%dT%H:%M:%S (for datetime, e.g., 2023-05-25T10:30:45) %Y-%m-%dT%H:%M:%SZ (for datetime with UTC timezone, e.g., 2023-05-25T10:30:45Z) %Y-%m-%dT%H:%M:%S%z (for datetime with timezone offset, e.g., 2023-05-25T10:30:45+0300) %Y-%m-%dT%H:%M (for datetime without seconds, e.g., 2023-05-25T10:30) %Y-%m-%dT%H (for datetime without minutes and seconds, e.g., 2023-05-25T10) %H:%M:%S (for time, e.g., 10:30:45) %H:%M:%SZ (for time with UTC timezone, e.g., 10:30:45Z) %H:%M:%S%z (for time with timezone offset, e.g., 10:30:45+0300) Examples of string formats email if valid emails (e.g., test@gmail.com) uri if valid uri addresses (e.g., https://example.com/resource123) binary if a base64 binary encoded string (e.g., authentication token like aGVsbG8gd29ybGQ=) uuid if a universal unique identifier also known as a guid (eg., f47ac10b-58cc-4372-a567-0e02b2c3d479) Examples of geopoint formats The two types of formats for geopoint (describing a geographic point). array (if 'lat,long' (e.g., 36.63,-90.20)) object (if {'lat':36.63,'lon':-90.20}) standardsMappings and relatedConcepts : If you want to add more than one value,adding anoth column with a name containing an added digit in brackets ( [0] --> [1] --> [n] ). Examples: A table with 2 columns (fields) of the same variables: standardsMappings[0].instrument.title standardsMappings[1].instrument.title My first instrument My second instrument A table with 3 columns (fields) of the same variables: relatedConcepts[0].url relatedConcepts[1].url relatedConcepts[2].url fakehttp://my-first-concept-url.org fakehttp://my-second-concept-url.org fakehttp://my-third-concept-url.org","title":"End of schema - Additional Property information"},{"location":"schemas/md_experiment_tracker/","text":"HEAL Experiment Tracker \u00b6 HEAL DSC Core Metadata piece to track and provide basic information about experiment(s) you will perform as part of your HEAL study. Clinical studies will often have only one experiment to report, while basic science studies often have several experiments that are grouped together under a single study. Properties \u00b6 schemaVersion (string) : Version of the overall schema (for each entry/row in the tracker) used at time of annotation; auto-populated equal to the value of the version key for the overall schema; should be constant for all rows in tracker. experimentId (string) : ID assigned to each experiment relevant to the data package; prefix is 'exp-' followed by a number starting with 1 for the first experiment, and iterating by 1 for each successive experiment (i.e. exp-1, exp-2, etc.). experimentName (string) : If you may want to link specific study files or study results to a specific single study experiment or activity, it's a good idea to assign a human-recognizable \"experiment name\" to your study experiment or activity here. If you are using the DSC Data Packaging Tool, you will be able to select from a pick list of experiment names to make this link, which will be easier than linking by experiment ID. The Experiment Name should be short and descriptive, and must be unique. It is meant to be an alternative ID assigned to each experiment relevant to the data package that is human readable and recognizable as related to a specific study experiment or activity. In order to make this both human and machine readable, 1) name must start with a lower case letter, 2) name must end with a lower case letter or number, 3) only characters allowed are lower case letters, numbers, and hyphens (use hyphen instead of space), 4) name has a max length of 50, 5) name must be unique (append an iterable number as a suffix to make unique if necessary; e.g. \"-1\", \"-2\"). experimentType (string) : discovery|materials and methods development. Must be one of: [\"\", \"discovery\", \"materials and methods development\"] . experimentDescription (string) : provide a brief description of the experiment; this is NOT a protocol. experimentQuestion (array) : what question(s) does the experimentalist hope to address with this experiment? be as specific as possible. Items (string) experimentHypothesis (array) : for each question the experimentalist hopes to address with this experiment, what does the experimentalist hypothesize will be the result(s) of the experiment? Be as specific as possible. Items (string) annotationCreateDateTime (string) : Date time at which the experiment annotation file for the experiment was created; auto-inferred. annotationModDateTime (string) : Date time at which the experiment annotation file for the experiment was last modified; auto-inferred. experimentIdNumber (integer) : Numeric part of the ID; autogenerated from ID; used for easy sorting by ID file. annotationModTimeStamp (number) : Date time at which the experiment annotation was last modified, converted to timestamp for easy sorting by datetime; auto-inferred.","title":"Experiment Tracker"},{"location":"schemas/md_experiment_tracker/#heal-experiment-tracker","text":"HEAL DSC Core Metadata piece to track and provide basic information about experiment(s) you will perform as part of your HEAL study. Clinical studies will often have only one experiment to report, while basic science studies often have several experiments that are grouped together under a single study.","title":"HEAL Experiment Tracker"},{"location":"schemas/md_experiment_tracker/#properties","text":"schemaVersion (string) : Version of the overall schema (for each entry/row in the tracker) used at time of annotation; auto-populated equal to the value of the version key for the overall schema; should be constant for all rows in tracker. experimentId (string) : ID assigned to each experiment relevant to the data package; prefix is 'exp-' followed by a number starting with 1 for the first experiment, and iterating by 1 for each successive experiment (i.e. exp-1, exp-2, etc.). experimentName (string) : If you may want to link specific study files or study results to a specific single study experiment or activity, it's a good idea to assign a human-recognizable \"experiment name\" to your study experiment or activity here. If you are using the DSC Data Packaging Tool, you will be able to select from a pick list of experiment names to make this link, which will be easier than linking by experiment ID. The Experiment Name should be short and descriptive, and must be unique. It is meant to be an alternative ID assigned to each experiment relevant to the data package that is human readable and recognizable as related to a specific study experiment or activity. In order to make this both human and machine readable, 1) name must start with a lower case letter, 2) name must end with a lower case letter or number, 3) only characters allowed are lower case letters, numbers, and hyphens (use hyphen instead of space), 4) name has a max length of 50, 5) name must be unique (append an iterable number as a suffix to make unique if necessary; e.g. \"-1\", \"-2\"). experimentType (string) : discovery|materials and methods development. Must be one of: [\"\", \"discovery\", \"materials and methods development\"] . experimentDescription (string) : provide a brief description of the experiment; this is NOT a protocol. experimentQuestion (array) : what question(s) does the experimentalist hope to address with this experiment? be as specific as possible. Items (string) experimentHypothesis (array) : for each question the experimentalist hopes to address with this experiment, what does the experimentalist hypothesize will be the result(s) of the experiment? Be as specific as possible. Items (string) annotationCreateDateTime (string) : Date time at which the experiment annotation file for the experiment was created; auto-inferred. annotationModDateTime (string) : Date time at which the experiment annotation file for the experiment was last modified; auto-inferred. experimentIdNumber (integer) : Numeric part of the ID; autogenerated from ID; used for easy sorting by ID file. annotationModTimeStamp (number) : Date time at which the experiment annotation was last modified, converted to timestamp for easy sorting by datetime; auto-inferred.","title":"Properties"},{"location":"schemas/md_resource_tracker/","text":"HEAL Resource Tracker \u00b6 HEAL DSC Core Metadata piece to track and provide basic information about resource(s)/file(s) that support/are produced by/result from experiments you perform/will perform as part of your HEAL study. The objective is to list at least all files that will be submitted to a data repository in order to describe what each file is, how they relate to each other/how to use them, and how they relate to results/publications shared by the study group. Files may include results files (e.g. publications or draft publications/pieces of publications), processed and raw data files, protocol and analytic plan files, data dictionaries for tabular data files, other metadata as appropriate to data/field type, etc. Properties \u00b6 schemaVersion (string) : Version of the overall schema (for each entry/row in the tracker) used at time of annotation; auto-populated equal to the value of the schemaVersion key for the overall schema. resourceId (string) : Unique ID assigned to each resource file; If using the DSC Data Packaging Tool to annotate your resource(s), these IDs will be auto-assigned based on resources already existing in your working Data Package Directory. Auto-assignment of IDs occurs by searching the directory for any resource annotation files already saved, identifying the resource ID with the highest resource ID number, and adding 1 to that number to get the resource ID number and unique resource ID for the current resource. path (string) : The full file path to your resource file. If you are using the DSC Data Packaging Tool and would like to use a single form to annotate multiple 'like' files, click the 'Add Multiple like Files' button above the form and drag and drop all of the like files you want to annotate together in that box. The file path for the first of the file paths you dropped in the box will be added to this field. description (string) : A description of your resource. For resources that are part of a set of multiple 'like' files, provide a description of the multi-file resource here and use the Resource File Description field to provide any description specific to each/any one specific file in the set. category (string) : Broad category your resource falls into; Generally, these categories are: results, data, metadata, code. However, the actual category options parse the categories just a bit finer (e.g. options for result resources include either 'result' or 'publication'; options for data resources include either 'tabular-data' or 'non-tabular-data'). Must be one of: [\"\", \"publication\", \"result\", \"tabular-data\", \"non-tabular-data\", \"metadata\", \"code\"] . experimentNameBelongsTo (string) : If the resource pertains specifically to one of the study experiments (e.g. this resource may be a protocol for, data collected from, code used to analyze data from, a single study experiment or activity), list the experiment name for that experiment here; If the resource pertains to more than one experiment, or to all experiments/the study as a whole, leave this blank; Use the experiment name as assigned/formatted in your Experiment Tracker file. Must be one of: [\"default-experiment-name\"] . name (string) : File path stem; Auto-inferred from file path. title (string) : Human-readable title/name of resource. descriptionFileNameConvention (string) : For multi-file resource containing multiple files of the same type (multiple 'like' files), provide the naming convention of the files (e.g. for a file set: [subject-01-protocol-A-day-2020-06-05.csv, subject-02-protocol-A-day-2020-06-05.csv, subject-02-protocol-B-day-2020-12-05.csv], you would specify the naming convention as: subject-{subject ID}-protocol-{protocol ID}-day-{date of measurment in YYYY-MM-DD}). If you are using the DSC Data Packaging Tool, you can use the Apply Name Convention button above the form to validate your name convention format and use a valid file name convention to generate a minimal 'Resource File Description' that is a minimal description specific to each file in the multi-file resource set. descriptionFile (string) : For a multi-file resource containing multiple files of the same type (multiple 'like' files), a description specific to the specific current file that is a component of that multi-file set. descriptionRow (string) : For a tabular data resource, a description of what one row in the tabular data resource represents; e.g. one row per subject per timepoint. categorySubMetadata (string) : Sub-category for a metadata resource. Must be one of: [\"\", \"heal-formatted-data-dictionary\", \"other-formatted-data-dictionary\", \"protocol\", \"analysis-plan\", \"heal-formatted-results-tracker\", \"other\"] . categorySubMetadataOther (string) : If you selected \"other\" as your metadata type/sub-category, please tell us what kind of metadata this is. categorySubData (string) : Sub-category for a data resource. Must be one of: [\"\", \"raw\", \"processed-intermediate\", \"processed-final\"] . categorySubResult (string) : Sub-category for a result resource. Must be one of: [\"\", \"single-panel-figure\", \"multi-panel-figure\", \"table\", \"text\"] . categorySubPublication (string) : Sub-category for a publication resource. Must be one of: [\"\", \"peer-review-manuscript\", \"report\", \"white-paper\", \"presentation\", \"poster\"] . associatedFileDataDict (array) : For a tabular data file resources, a reference/file path to associated data dictionary file(s) - preferably in heal csv data dictionary format. Items (string) associatedFileProtocol (array) : For a data file resource, a reference/file path to associated protocol file(s). Items (string) associatedFileResultsTracker (array) : For a publication resource, a reference/file path to the associated HEAL-formatted Results Tracker file - HEAL-formatted Results Tracker is a file that inventories each result in a publication (e.g. a peer-review-manuscript, report, presentation, poster, etc.), along with the data and other supporting files that underly/support each result. If you are using the DSC Data Packaging Desktop Tool, you can head to the Results Tracker tab of the tool to create a HEAL-formatted Results Tracker for your publication(s). Items (string) associatedFileDependsOn (array) : For all resource files, if the current resource file has dependencies/if other files are necessary to make this file (e.g. raw data file necessary to make processed data file), or to interpret/understand this file (e.g. protocol, analysis plan, etc.), list them here; only list dependencies one layer deep; dependencies can be data, code, protocol, etc.; if already listed under a more specialized fields such as associatedFileDataDict, associatedFileProtocol, no need to repeat here. Items (string) associatedFileResultsDependOn (array) : If the current resource file is a heal formatted result tracker (an file that inventories each of the results in a publication), use this field to list each result in the tracker along with its corresponding dependencies (i.e. files the result depends on, or are necessary to make/reach/interpret the result); for each result, only list dependencies one layer deep; dependencies can be data, code, protocol, etc. Items (object) resultId (string) resultIdDependsOn (array) associatedFileMultiLikeFiles (array) : If the current resource file is annotating a resource that is one of multiple 'like' files, this field will list the file paths of all files that are part of the set of multiple 'like' file resources. Items (string) associatedFileMultiLikeFilesIds (array) : If the current resource file is annotating a resource that is one of multiple 'like' files, this field will list the resource IDs for all files that are part of the set of multiple 'like' file resources. Items (string) access (array) : What is the current/final access level anticipated for this resource? Options are permanent-private (current and final access level is private), temporary-private (current access level is private but final access level will be either managed-access or open-access), managed-access (current, final, or current AND final access level will allow request of data with barriers/restrictions to access), open-access (current, final, or current AND final access level will allow largely unrestricted request of/access to data); Many investigators will designate data as currently temporary-private, with a final access level of either managed-access or open-access: In this case choose both temporary-private AND either 1) managed-access or 2) open-access, then add the date at which you expect to transition from temporary-private to either managed-access or open-access in the Access Date field below; Private means members of the public cannot request access; Restricted access means they can request access but there is gate-keeping; Open access means they can often access the data without requesting access from a gate-keeper, and with minimal barriers to access. Items (string) : Must be one of: [\"\", \"permanent-private\", \"temporary-private\", \"managed-access\", \"open-access\"] . accessDate (string) : If the resource file is currently being held as temporary-private access level and will transition to either managed-access or open-access access level at some point, please provide an anticipated date at which this transition will occur - Best guesses are appreciated, however you will NOT be held to this date and may update this date at any time. format (string) : auto inferred; e.g. csv. softwareUsed (string) : If the file format of the resource file is proprietary and requires specific software to open/interpret, provide the software name and version used by the study group to produce/work with the file; e.g. Origin 11.0, CorelDraw 5.6. note (string) : Any important notes for someone viewing or re-using a resource not covered in more structured fields of the Resource Tracker. For example, in a complex file such as an Excel Workbook, or a PRISM file, specify where the data is, where the analysis is, where the figure(s) is/are, describe what is in each sheet of an Excel Workbook. For example, brief protocol data relevant to a resource may be specified here especially if a free-standing protocol document does not exist; Also may specify directions as to where in a larger free-standing protocol document (which the user has added as a dependency of the resource) the user may find specific protocol information that pertains to this resource. For example, for a tabular data file where a heal formatted data dictionary is not appropriate (e.g. raw/normalized counts from RNAseq experiment), specify the format of a metadata file that has been added as a dependency for the resource and/or add essential metadata directly in the note (e.g. reference genome). profile (string) : auto inferred; e.g. tabular-data-resource. mediatype (string) : auto inferred; e.g. text/csv. encoding (string) : auto inferred; e.g. utf-8. schema (string) : auto inferred; for tabular resource, schema of fields contained in tabular resource; might replace this with ref to either heal csv dd or heal json dd. resourceCreateDateTime (string) : Date time of resource creation; auto-inferred. resourceModDateTime (string) : Date time at which the resource was last modified; auto-inferred. annotationCreateDateTime (string) : Date time at which the resource annotation was created; auto-inferred. annotationModDateTime (string) : Date time at which the resource annotation was last modified; auto-inferred. resourceIdNumber (integer) : Numeric part of the ID; autogenerated from ID; used for easy sorting by ID file. resourceModTimeStamp (number) : Date time at which the resource was last modified, converted to timestamp for easy sorting on datetime; auto-inferred. annotationModTimeStamp (number) : Date time at which the resource annotation was last modified, converted to timestamp for easy sorting by datetime; auto-inferred. removed (integer) : True if user has removed the resource from the scope of the data package. Must be one of: [0, 1] .","title":"Resource Tracker"},{"location":"schemas/md_resource_tracker/#heal-resource-tracker","text":"HEAL DSC Core Metadata piece to track and provide basic information about resource(s)/file(s) that support/are produced by/result from experiments you perform/will perform as part of your HEAL study. The objective is to list at least all files that will be submitted to a data repository in order to describe what each file is, how they relate to each other/how to use them, and how they relate to results/publications shared by the study group. Files may include results files (e.g. publications or draft publications/pieces of publications), processed and raw data files, protocol and analytic plan files, data dictionaries for tabular data files, other metadata as appropriate to data/field type, etc.","title":"HEAL Resource Tracker"},{"location":"schemas/md_resource_tracker/#properties","text":"schemaVersion (string) : Version of the overall schema (for each entry/row in the tracker) used at time of annotation; auto-populated equal to the value of the schemaVersion key for the overall schema. resourceId (string) : Unique ID assigned to each resource file; If using the DSC Data Packaging Tool to annotate your resource(s), these IDs will be auto-assigned based on resources already existing in your working Data Package Directory. Auto-assignment of IDs occurs by searching the directory for any resource annotation files already saved, identifying the resource ID with the highest resource ID number, and adding 1 to that number to get the resource ID number and unique resource ID for the current resource. path (string) : The full file path to your resource file. If you are using the DSC Data Packaging Tool and would like to use a single form to annotate multiple 'like' files, click the 'Add Multiple like Files' button above the form and drag and drop all of the like files you want to annotate together in that box. The file path for the first of the file paths you dropped in the box will be added to this field. description (string) : A description of your resource. For resources that are part of a set of multiple 'like' files, provide a description of the multi-file resource here and use the Resource File Description field to provide any description specific to each/any one specific file in the set. category (string) : Broad category your resource falls into; Generally, these categories are: results, data, metadata, code. However, the actual category options parse the categories just a bit finer (e.g. options for result resources include either 'result' or 'publication'; options for data resources include either 'tabular-data' or 'non-tabular-data'). Must be one of: [\"\", \"publication\", \"result\", \"tabular-data\", \"non-tabular-data\", \"metadata\", \"code\"] . experimentNameBelongsTo (string) : If the resource pertains specifically to one of the study experiments (e.g. this resource may be a protocol for, data collected from, code used to analyze data from, a single study experiment or activity), list the experiment name for that experiment here; If the resource pertains to more than one experiment, or to all experiments/the study as a whole, leave this blank; Use the experiment name as assigned/formatted in your Experiment Tracker file. Must be one of: [\"default-experiment-name\"] . name (string) : File path stem; Auto-inferred from file path. title (string) : Human-readable title/name of resource. descriptionFileNameConvention (string) : For multi-file resource containing multiple files of the same type (multiple 'like' files), provide the naming convention of the files (e.g. for a file set: [subject-01-protocol-A-day-2020-06-05.csv, subject-02-protocol-A-day-2020-06-05.csv, subject-02-protocol-B-day-2020-12-05.csv], you would specify the naming convention as: subject-{subject ID}-protocol-{protocol ID}-day-{date of measurment in YYYY-MM-DD}). If you are using the DSC Data Packaging Tool, you can use the Apply Name Convention button above the form to validate your name convention format and use a valid file name convention to generate a minimal 'Resource File Description' that is a minimal description specific to each file in the multi-file resource set. descriptionFile (string) : For a multi-file resource containing multiple files of the same type (multiple 'like' files), a description specific to the specific current file that is a component of that multi-file set. descriptionRow (string) : For a tabular data resource, a description of what one row in the tabular data resource represents; e.g. one row per subject per timepoint. categorySubMetadata (string) : Sub-category for a metadata resource. Must be one of: [\"\", \"heal-formatted-data-dictionary\", \"other-formatted-data-dictionary\", \"protocol\", \"analysis-plan\", \"heal-formatted-results-tracker\", \"other\"] . categorySubMetadataOther (string) : If you selected \"other\" as your metadata type/sub-category, please tell us what kind of metadata this is. categorySubData (string) : Sub-category for a data resource. Must be one of: [\"\", \"raw\", \"processed-intermediate\", \"processed-final\"] . categorySubResult (string) : Sub-category for a result resource. Must be one of: [\"\", \"single-panel-figure\", \"multi-panel-figure\", \"table\", \"text\"] . categorySubPublication (string) : Sub-category for a publication resource. Must be one of: [\"\", \"peer-review-manuscript\", \"report\", \"white-paper\", \"presentation\", \"poster\"] . associatedFileDataDict (array) : For a tabular data file resources, a reference/file path to associated data dictionary file(s) - preferably in heal csv data dictionary format. Items (string) associatedFileProtocol (array) : For a data file resource, a reference/file path to associated protocol file(s). Items (string) associatedFileResultsTracker (array) : For a publication resource, a reference/file path to the associated HEAL-formatted Results Tracker file - HEAL-formatted Results Tracker is a file that inventories each result in a publication (e.g. a peer-review-manuscript, report, presentation, poster, etc.), along with the data and other supporting files that underly/support each result. If you are using the DSC Data Packaging Desktop Tool, you can head to the Results Tracker tab of the tool to create a HEAL-formatted Results Tracker for your publication(s). Items (string) associatedFileDependsOn (array) : For all resource files, if the current resource file has dependencies/if other files are necessary to make this file (e.g. raw data file necessary to make processed data file), or to interpret/understand this file (e.g. protocol, analysis plan, etc.), list them here; only list dependencies one layer deep; dependencies can be data, code, protocol, etc.; if already listed under a more specialized fields such as associatedFileDataDict, associatedFileProtocol, no need to repeat here. Items (string) associatedFileResultsDependOn (array) : If the current resource file is a heal formatted result tracker (an file that inventories each of the results in a publication), use this field to list each result in the tracker along with its corresponding dependencies (i.e. files the result depends on, or are necessary to make/reach/interpret the result); for each result, only list dependencies one layer deep; dependencies can be data, code, protocol, etc. Items (object) resultId (string) resultIdDependsOn (array) associatedFileMultiLikeFiles (array) : If the current resource file is annotating a resource that is one of multiple 'like' files, this field will list the file paths of all files that are part of the set of multiple 'like' file resources. Items (string) associatedFileMultiLikeFilesIds (array) : If the current resource file is annotating a resource that is one of multiple 'like' files, this field will list the resource IDs for all files that are part of the set of multiple 'like' file resources. Items (string) access (array) : What is the current/final access level anticipated for this resource? Options are permanent-private (current and final access level is private), temporary-private (current access level is private but final access level will be either managed-access or open-access), managed-access (current, final, or current AND final access level will allow request of data with barriers/restrictions to access), open-access (current, final, or current AND final access level will allow largely unrestricted request of/access to data); Many investigators will designate data as currently temporary-private, with a final access level of either managed-access or open-access: In this case choose both temporary-private AND either 1) managed-access or 2) open-access, then add the date at which you expect to transition from temporary-private to either managed-access or open-access in the Access Date field below; Private means members of the public cannot request access; Restricted access means they can request access but there is gate-keeping; Open access means they can often access the data without requesting access from a gate-keeper, and with minimal barriers to access. Items (string) : Must be one of: [\"\", \"permanent-private\", \"temporary-private\", \"managed-access\", \"open-access\"] . accessDate (string) : If the resource file is currently being held as temporary-private access level and will transition to either managed-access or open-access access level at some point, please provide an anticipated date at which this transition will occur - Best guesses are appreciated, however you will NOT be held to this date and may update this date at any time. format (string) : auto inferred; e.g. csv. softwareUsed (string) : If the file format of the resource file is proprietary and requires specific software to open/interpret, provide the software name and version used by the study group to produce/work with the file; e.g. Origin 11.0, CorelDraw 5.6. note (string) : Any important notes for someone viewing or re-using a resource not covered in more structured fields of the Resource Tracker. For example, in a complex file such as an Excel Workbook, or a PRISM file, specify where the data is, where the analysis is, where the figure(s) is/are, describe what is in each sheet of an Excel Workbook. For example, brief protocol data relevant to a resource may be specified here especially if a free-standing protocol document does not exist; Also may specify directions as to where in a larger free-standing protocol document (which the user has added as a dependency of the resource) the user may find specific protocol information that pertains to this resource. For example, for a tabular data file where a heal formatted data dictionary is not appropriate (e.g. raw/normalized counts from RNAseq experiment), specify the format of a metadata file that has been added as a dependency for the resource and/or add essential metadata directly in the note (e.g. reference genome). profile (string) : auto inferred; e.g. tabular-data-resource. mediatype (string) : auto inferred; e.g. text/csv. encoding (string) : auto inferred; e.g. utf-8. schema (string) : auto inferred; for tabular resource, schema of fields contained in tabular resource; might replace this with ref to either heal csv dd or heal json dd. resourceCreateDateTime (string) : Date time of resource creation; auto-inferred. resourceModDateTime (string) : Date time at which the resource was last modified; auto-inferred. annotationCreateDateTime (string) : Date time at which the resource annotation was created; auto-inferred. annotationModDateTime (string) : Date time at which the resource annotation was last modified; auto-inferred. resourceIdNumber (integer) : Numeric part of the ID; autogenerated from ID; used for easy sorting by ID file. resourceModTimeStamp (number) : Date time at which the resource was last modified, converted to timestamp for easy sorting on datetime; auto-inferred. annotationModTimeStamp (number) : Date time at which the resource annotation was last modified, converted to timestamp for easy sorting by datetime; auto-inferred. removed (integer) : True if user has removed the resource from the scope of the data package. Must be one of: [0, 1] .","title":"Properties"},{"location":"schemas/md_results_tracker/","text":"HEAL Results Tracker \u00b6 HEAL DSC Core Metadata piece to track and provide basic information about results statements or figures in a publication (e.g. a peer review manuscript, report, presentation, poster, etc.) that presents results from your HEAL study. Objective is to list at least all results that have been/will be published in order to describe each result, the data/non-data files each result depends on, and how to use these data/non-data files to reproduce published results. Properties \u00b6 schemaVersion (string) : Version of the overall schema (for each entry/row in the tracker) used at time of annotation; auto-populated equal to the value of the version key for the overall schema; should be constant for all rows in tracker. resultId (string) : Unique ID assigned to each result; If using the DSC Data Packaging Tool to annotate your result(s), these IDs will be auto-assigned when you use the Add Result Tracker function. Auto-assignment of IDs occurs by searching you working Data Package Directory for any result annotation files already saved, identifying the result ID with the highest result ID number, and adding 1 to that number to get the result ID number and unique result ID for the current result. description (string) : A description of your result. For figure results this may be the figure caption. For text results, it is recommended that this text be identical or very similar to the text of result as shared in text of the multi-result file that is published or provided as part of the data package. category (string) : Broad category your result falls into; Generally, these categories are: figure, or text. Must be one of: [\"\", \"single-panel-figure\", \"figure-panel\", \"table\", \"text\"] . experimentNameBelongsTo (string) : If the result pertains specifically to one of the study experiments (i.e. all data/observations/activities that underly this result came from a single study experiment or activity), list the experiment name for that experiment here; If the result pertains to more than one experiment, or to all experiments/the study as a whole, leave this blank; Use the experiment name as assigned/formatted in your Experiment Tracker file. Must be one of: [\"default-experiment-name\"] . associatedFilePublication (array) : The publication(s) in which this result has been shared. Items (string) figureNumber (array) : If the result is a figure result, provide the number of the figure as it appears in the corresponding publication; For example, enter '1' for Figure Number if the result is being shared in a single panel figure called 'Figure 1'; Enter '1A' if the result is being shared in panel 'A' of a multi-panel figure called 'Figure 1'. If the result is included in more than one publication (e.g. the same figure may be shared in both a presentation and a peer-review manuscript), use the Associated Publication(s) field above to specify all publication files in which the result appears, and add the figure number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; figure-number-in-file-1, figure-number-in-file-2). Items (string) tableNumber (array) : If the result is a table result, provide the number of the table as it appears in the corresponding publication; For example, enter '1' for Table Number if the result is being shared in a table called 'Table 1'. If the result is included in more than one publication (e.g. the same table may be shared in both a presentation and a peer-review manuscript), use the Associated Publication(s) field above to specify all publication files in which the result appears, and add the table number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; table-number-in-file-1, table-number-in-file-2). Items (string) associatedFileDependsOn (array) : Data and/or non-data supporting files the result depends upon (e.g. data, analysis plan/code, etc.). If you are using the DSC Data Packaging Tool and have many result dependencies to add, you can use the Add Multiple Result Dependencies button above the form to reveal an interface where you can drag and drop many files at once. Only list dependencies one layer deep; dependencies can be data, code, figure creation software files, etc. Items (string) resultSupports (array) : Describe a larger claim(s) that is/will be made in a publication that this result is used to support; This may be more relevant to basic science studies - An example: A study uses both a chemical inhibition and a siRNA knockdown approach to test the hypothesis that inhibiting the activity of a protein leads to decreased chronic pain phenotype. They share the results of these two experiments in a multi-panel figure labeled 'Figure 1' in a peer-review manuscript. They add these two results to a Results Tracker for this publication. The first result is entered with Figure Number '1A' and with description 'chemical inhibition of protein X with inhibitor Y leads to decreased chronic pain phenotype Z'. The second result is entered as Figure Number '1B' and the description is 'knockdown of protein X with siRNA Y leads to decreased chronic pain phenotype Z'; However, both results can be entered with a Result Supports entry of 'Inhibition of protein X leads to decrease chronic pain phenotype'; Other results from this study that perhaps use similar chemical inhibition or siRNA knockdown of protein X but a different chronic pain phenotype readout could similarly be shared with a Result Support entry identical to the first two results, as all of these experiments are supporting this larger claim that inhibiting protein X reduces chronic pain phenotype. Items (string) annotationCreateDateTime (string) : Date time at which the result annotation was created; auto-inferred. annotationModDateTime (string) : Date time at which the result annotation was last modified; auto-inferred. resultIdNumber (integer) : Numeric part of the ID; autogenerated from ID; used for easy sorting by ID file. annotationModTimeStamp (number) : Date time at which the result annotation was last modified, converted to timestamp for easy sorting by datetime; auto-inferred.","title":"Results Tracker"},{"location":"schemas/md_results_tracker/#heal-results-tracker","text":"HEAL DSC Core Metadata piece to track and provide basic information about results statements or figures in a publication (e.g. a peer review manuscript, report, presentation, poster, etc.) that presents results from your HEAL study. Objective is to list at least all results that have been/will be published in order to describe each result, the data/non-data files each result depends on, and how to use these data/non-data files to reproduce published results.","title":"HEAL Results Tracker"},{"location":"schemas/md_results_tracker/#properties","text":"schemaVersion (string) : Version of the overall schema (for each entry/row in the tracker) used at time of annotation; auto-populated equal to the value of the version key for the overall schema; should be constant for all rows in tracker. resultId (string) : Unique ID assigned to each result; If using the DSC Data Packaging Tool to annotate your result(s), these IDs will be auto-assigned when you use the Add Result Tracker function. Auto-assignment of IDs occurs by searching you working Data Package Directory for any result annotation files already saved, identifying the result ID with the highest result ID number, and adding 1 to that number to get the result ID number and unique result ID for the current result. description (string) : A description of your result. For figure results this may be the figure caption. For text results, it is recommended that this text be identical or very similar to the text of result as shared in text of the multi-result file that is published or provided as part of the data package. category (string) : Broad category your result falls into; Generally, these categories are: figure, or text. Must be one of: [\"\", \"single-panel-figure\", \"figure-panel\", \"table\", \"text\"] . experimentNameBelongsTo (string) : If the result pertains specifically to one of the study experiments (i.e. all data/observations/activities that underly this result came from a single study experiment or activity), list the experiment name for that experiment here; If the result pertains to more than one experiment, or to all experiments/the study as a whole, leave this blank; Use the experiment name as assigned/formatted in your Experiment Tracker file. Must be one of: [\"default-experiment-name\"] . associatedFilePublication (array) : The publication(s) in which this result has been shared. Items (string) figureNumber (array) : If the result is a figure result, provide the number of the figure as it appears in the corresponding publication; For example, enter '1' for Figure Number if the result is being shared in a single panel figure called 'Figure 1'; Enter '1A' if the result is being shared in panel 'A' of a multi-panel figure called 'Figure 1'. If the result is included in more than one publication (e.g. the same figure may be shared in both a presentation and a peer-review manuscript), use the Associated Publication(s) field above to specify all publication files in which the result appears, and add the figure number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; figure-number-in-file-1, figure-number-in-file-2). Items (string) tableNumber (array) : If the result is a table result, provide the number of the table as it appears in the corresponding publication; For example, enter '1' for Table Number if the result is being shared in a table called 'Table 1'. If the result is included in more than one publication (e.g. the same table may be shared in both a presentation and a peer-review manuscript), use the Associated Publication(s) field above to specify all publication files in which the result appears, and add the table number at which the result appears in each of those files in this field, using the same order (e.g. file-1, file-2; table-number-in-file-1, table-number-in-file-2). Items (string) associatedFileDependsOn (array) : Data and/or non-data supporting files the result depends upon (e.g. data, analysis plan/code, etc.). If you are using the DSC Data Packaging Tool and have many result dependencies to add, you can use the Add Multiple Result Dependencies button above the form to reveal an interface where you can drag and drop many files at once. Only list dependencies one layer deep; dependencies can be data, code, figure creation software files, etc. Items (string) resultSupports (array) : Describe a larger claim(s) that is/will be made in a publication that this result is used to support; This may be more relevant to basic science studies - An example: A study uses both a chemical inhibition and a siRNA knockdown approach to test the hypothesis that inhibiting the activity of a protein leads to decreased chronic pain phenotype. They share the results of these two experiments in a multi-panel figure labeled 'Figure 1' in a peer-review manuscript. They add these two results to a Results Tracker for this publication. The first result is entered with Figure Number '1A' and with description 'chemical inhibition of protein X with inhibitor Y leads to decreased chronic pain phenotype Z'. The second result is entered as Figure Number '1B' and the description is 'knockdown of protein X with siRNA Y leads to decreased chronic pain phenotype Z'; However, both results can be entered with a Result Supports entry of 'Inhibition of protein X leads to decrease chronic pain phenotype'; Other results from this study that perhaps use similar chemical inhibition or siRNA knockdown of protein X but a different chronic pain phenotype readout could similarly be shared with a Result Support entry identical to the first two results, as all of these experiments are supporting this larger claim that inhibiting protein X reduces chronic pain phenotype. Items (string) annotationCreateDateTime (string) : Date time at which the result annotation was created; auto-inferred. annotationModDateTime (string) : Date time at which the result annotation was last modified; auto-inferred. resultIdNumber (integer) : Numeric part of the ID; autogenerated from ID; used for easy sorting by ID file. annotationModTimeStamp (number) : Date time at which the result annotation was last modified, converted to timestamp for easy sorting by datetime; auto-inferred.","title":"Properties"}]}